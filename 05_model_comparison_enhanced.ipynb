{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWJuRfPOOYBU",
        "outputId": "c5bdc252-3870-4427-99d9-4dfd85947142"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "FIXED MODEL COMPARISON FRAMEWORK\n",
            "Agreement-Based Analysis Without Manual Validation\n",
            "======================================================================\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Fixed model comparison for banks: JPM, HSBC\n",
            "Models to compare: 4 models\n"
          ]
        }
      ],
      "source": [
        "# 05_model_comparison_fixed.ipynb\n",
        "# Purpose: Fixed model comparison framework for 4 models across JP Morgan and HSBC\n",
        "# Banks: JP Morgan (JPM) and HSBC\n",
        "# Models: FinBERT (yiyanghkust), FinBERT (ProsusAI), DistilRoBERTa, CardiffNLP (Twitter-RoBERTa)\n",
        "# Input: Enhanced sentiment results (agreement-based analysis since manual validation doesn't match)\n",
        "# Output: Comprehensive model comparison with agreement metrics and financial context insights\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"FIXED MODEL COMPARISON FRAMEWORK\")\n",
        "print(\"Agreement-Based Analysis Without Manual Validation\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "## Import Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Enhanced statistical analysis\n",
        "from scipy import stats\n",
        "from scipy.stats import pearsonr, spearmanr, wilcoxon, mannwhitneyu, chi2_contingency\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, cohen_kappa_score,\n",
        "    accuracy_score, precision_recall_fscore_support, roc_auc_score,\n",
        "    balanced_accuracy_score\n",
        ")\n",
        "import itertools\n",
        "\n",
        "# Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# Load enhanced configuration\n",
        "config_path = Path(\"/content/drive/MyDrive/CAM_DS_AI_Project_Enhanced/configs/enhanced_config.json\")\n",
        "with open(config_path, \"r\") as f:\n",
        "    enhanced_config = json.load(f)\n",
        "\n",
        "SEED = enhanced_config[\"SEED\"]\n",
        "BANKS = enhanced_config[\"BANKS\"]\n",
        "QUARTERS = enhanced_config[\"QUARTERS\"]\n",
        "MODELS = enhanced_config[\"MODELS\"]\n",
        "drive_base = Path(enhanced_config[\"drive_base\"])\n",
        "colab_base = Path(enhanced_config[\"colab_base\"])\n",
        "\n",
        "print(f\"Fixed model comparison for banks: {', '.join([bank.upper() for bank in BANKS])}\")\n",
        "print(f\"Models to compare: {len(MODELS)} models\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Define Enhanced Paths\n",
        "\n",
        "comparison_paths = {}\n",
        "for bank in BANKS:\n",
        "    comparison_paths[bank] = {\n",
        "        \"results_sentiment\": drive_base / f\"results/sentiment/{bank}\",\n",
        "        \"results_finetuning\": drive_base / f\"results/finetuning/{bank}\",\n",
        "        \"results_comparison\": drive_base / f\"results/comparison/{bank}\",\n",
        "        \"manual_validation\": drive_base / f\"data/manual_validation/{bank}\"\n",
        "    }\n",
        "\n",
        "    # Ensure comparison results directory exists\n",
        "    comparison_paths[bank][\"results_comparison\"].mkdir(parents=True, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "iXNLa2WHSeT2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Enhanced Data Loading\n",
        "\n",
        "def load_enhanced_sentiment_results():\n",
        "    \"\"\"Load enhanced sentiment analysis results for all banks.\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"LOADING ENHANCED SENTIMENT RESULTS\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    sentiment_results = {}\n",
        "\n",
        "    for bank in BANKS:\n",
        "        print(f\"\\nüìÇ Loading {bank.upper()} sentiment results...\")\n",
        "        sentiment_results[bank] = {}\n",
        "\n",
        "        # Load sentence-level results (primary for comparison)\n",
        "        result_files = [\n",
        "            f\"enhanced_4model_sentiment_{bank}_q1_2025_sentence.csv\",\n",
        "            f\"enhanced_4model_sentiment_{bank}_q2_2025_sentence.csv\",\n",
        "            f\"enhanced_4model_sentiment_{bank}_combined_sentence.csv\"\n",
        "        ]\n",
        "\n",
        "        for filename in result_files:\n",
        "            file_path = comparison_paths[bank][\"results_sentiment\"] / filename\n",
        "\n",
        "            if file_path.exists():\n",
        "                try:\n",
        "                    df = pd.read_csv(file_path)\n",
        "\n",
        "                    # Determine dataset type\n",
        "                    if \"q1_2025\" in filename:\n",
        "                        dataset_key = \"q1_2025\"\n",
        "                    elif \"q2_2025\" in filename:\n",
        "                        dataset_key = \"q2_2025\"\n",
        "                    else:\n",
        "                        dataset_key = \"combined\"\n",
        "\n",
        "                    sentiment_results[bank][dataset_key] = df\n",
        "                    print(f\"  ‚úÖ {dataset_key}: {df.shape}\")\n",
        "\n",
        "                    # Check available model columns\n",
        "                    model_columns = [col for col in df.columns if any(model in col for model in MODELS.keys())]\n",
        "                    label_columns = [col for col in df.columns if col.endswith('_label')]\n",
        "                    print(f\"    Total model columns: {len(model_columns)}\")\n",
        "                    print(f\"    Label columns: {len(label_columns)} - {label_columns}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"  ‚ùå Error loading {filename}: {str(e)}\")\n",
        "            else:\n",
        "                print(f\"  ‚ö†Ô∏è File not found: {filename}\")\n",
        "\n",
        "    return sentiment_results\n",
        "\n",
        "def load_finetuning_results():\n",
        "    \"\"\"Load fine-tuning results for comparison analysis.\"\"\"\n",
        "    print(f\"\\nüìã Loading fine-tuning results...\")\n",
        "\n",
        "    finetuning_results = {}\n",
        "\n",
        "    for bank in BANKS:\n",
        "        result_path = comparison_paths[bank][\"results_finetuning\"] / f\"enhanced_finetuning_results_{bank}.json\"\n",
        "\n",
        "        if result_path.exists():\n",
        "            try:\n",
        "                with open(result_path, 'r') as f:\n",
        "                    results = json.load(f)\n",
        "                finetuning_results[bank] = results\n",
        "                print(f\"  ‚úÖ {bank.upper()} fine-tuning results loaded\")\n",
        "            except Exception as e:\n",
        "                print(f\"  ‚ùå Error loading {bank.upper()} fine-tuning results: {e}\")\n",
        "        else:\n",
        "            print(f\"  ‚ö†Ô∏è No fine-tuning results found for {bank.upper()}\")\n",
        "\n",
        "    return finetuning_results\n",
        "\n",
        "# Load all data\n",
        "sentiment_results = load_enhanced_sentiment_results()\n",
        "finetuning_results = load_finetuning_results()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOGfAqL-h2R5",
        "outputId": "6279bc27-ffdd-4351-fc48-a0fade12ab5a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "LOADING ENHANCED SENTIMENT RESULTS\n",
            "============================================================\n",
            "\n",
            "üìÇ Loading JPM sentiment results...\n",
            "  ‚úÖ q1_2025: (313, 78)\n",
            "    Total model columns: 44\n",
            "    Label columns: 4 - ['finbert_yiyanghkust_label', 'finbert_prosusai_label', 'distilroberta_label', 'cardiffnlp_roberta_label']\n",
            "  ‚úÖ q2_2025: (440, 74)\n",
            "    Total model columns: 40\n",
            "    Label columns: 4 - ['finbert_yiyanghkust_label', 'finbert_prosusai_label', 'distilroberta_label', 'cardiffnlp_roberta_label']\n",
            "  ‚úÖ combined: (752, 78)\n",
            "    Total model columns: 44\n",
            "    Label columns: 4 - ['finbert_yiyanghkust_label', 'finbert_prosusai_label', 'distilroberta_label', 'cardiffnlp_roberta_label']\n",
            "\n",
            "üìÇ Loading HSBC sentiment results...\n",
            "  ‚úÖ q1_2025: (300, 74)\n",
            "    Total model columns: 40\n",
            "    Label columns: 4 - ['finbert_yiyanghkust_label', 'finbert_prosusai_label', 'distilroberta_label', 'cardiffnlp_roberta_label']\n",
            "  ‚úÖ q2_2025: (340, 78)\n",
            "    Total model columns: 44\n",
            "    Label columns: 4 - ['finbert_yiyanghkust_label', 'finbert_prosusai_label', 'distilroberta_label', 'cardiffnlp_roberta_label']\n",
            "  ‚úÖ combined: (640, 78)\n",
            "    Total model columns: 44\n",
            "    Label columns: 4 - ['finbert_yiyanghkust_label', 'finbert_prosusai_label', 'distilroberta_label', 'cardiffnlp_roberta_label']\n",
            "\n",
            "üìã Loading fine-tuning results...\n",
            "  ‚úÖ JPM fine-tuning results loaded\n",
            "  ‚úÖ HSBC fine-tuning results loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Fixed Model Comparison Framework\n",
        "\n",
        "class FixedModelComparator:\n",
        "    \"\"\"Fixed model comparison framework that works with available sentiment data.\"\"\"\n",
        "\n",
        "    def __init__(self, sentiment_results: Dict, finetuning_results: Dict):\n",
        "        self.sentiment_results = sentiment_results\n",
        "        self.finetuning_results = finetuning_results\n",
        "        self.models = list(MODELS.keys())\n",
        "        self.banks = BANKS\n",
        "        self.comparison_results = {}\n",
        "\n",
        "        print(f\"Fixed comparator initialized:\")\n",
        "        print(f\"  Banks: {len(self.banks)}\")\n",
        "        print(f\"  Models: {len(self.models)}\")\n",
        "        print(f\"  Datasets per bank: {len(sentiment_results.get(BANKS[0], {})) if BANKS else 0}\")\n",
        "\n",
        "    def identify_available_models(self, df: pd.DataFrame) -> List[str]:\n",
        "        \"\"\"Identify available model predictions in dataset.\"\"\"\n",
        "        available_models = []\n",
        "\n",
        "        for model_key in self.models:\n",
        "            label_col = f'{model_key}_label'\n",
        "            if label_col in df.columns:\n",
        "                # Check if column has actual predictions\n",
        "                non_null_count = df[label_col].notna().sum()\n",
        "                if non_null_count > 0:\n",
        "                    available_models.append(model_key)\n",
        "\n",
        "        return available_models\n",
        "\n",
        "    def calculate_comprehensive_agreement_metrics(self) -> Dict:\n",
        "        \"\"\"Calculate comprehensive agreement metrics between all model pairs across banks.\"\"\"\n",
        "        print(\"\\nü§ù Calculating comprehensive agreement metrics...\")\n",
        "\n",
        "        agreement_results = {}\n",
        "\n",
        "        for bank in self.banks:\n",
        "            bank_agreements = {}\n",
        "\n",
        "            if bank in self.sentiment_results:\n",
        "                for dataset_type, df in self.sentiment_results[bank].items():\n",
        "                    if df is None or len(df) == 0:\n",
        "                        continue\n",
        "\n",
        "                    available_models = self.identify_available_models(df)\n",
        "                    print(f\"  [{bank.upper()}] {dataset_type}: {len(available_models)} models available\")\n",
        "\n",
        "                    if len(available_models) < 2:\n",
        "                        continue\n",
        "\n",
        "                    dataset_agreements = {}\n",
        "\n",
        "                    # Pairwise model comparisons\n",
        "                    for model1, model2 in itertools.combinations(available_models, 2):\n",
        "                        pair_name = f\"{model1}_vs_{model2}\"\n",
        "\n",
        "                        label_col1 = f\"{model1}_label\"\n",
        "                        label_col2 = f\"{model2}_label\"\n",
        "\n",
        "                        # Filter valid predictions\n",
        "                        valid_mask = (\n",
        "                            df[label_col1].notna() &\n",
        "                            df[label_col2].notna()\n",
        "                        )\n",
        "                        valid_df = df[valid_mask]\n",
        "\n",
        "                        if len(valid_df) == 0:\n",
        "                            continue\n",
        "\n",
        "                        labels1 = valid_df[label_col1].values\n",
        "                        labels2 = valid_df[label_col2].values\n",
        "\n",
        "                        # Basic agreement\n",
        "                        agreement_rate = (labels1 == labels2).mean()\n",
        "\n",
        "                        # Cohen's Kappa\n",
        "                        try:\n",
        "                            kappa = cohen_kappa_score(labels1, labels2)\n",
        "                        except:\n",
        "                            kappa = 0.0\n",
        "\n",
        "                        # Confidence correlation if available\n",
        "                        score_col1 = f\"{model1}_confidence\"\n",
        "                        score_col2 = f\"{model2}_confidence\"\n",
        "\n",
        "                        confidence_correlation = None\n",
        "                        if score_col1 in valid_df.columns and score_col2 in valid_df.columns:\n",
        "                            scores1 = valid_df[score_col1].fillna(0.5)\n",
        "                            scores2 = valid_df[score_col2].fillna(0.5)\n",
        "\n",
        "                            try:\n",
        "                                pearson_r, pearson_p = pearsonr(scores1, scores2)\n",
        "                                confidence_correlation = {\n",
        "                                    'pearson_r': pearson_r,\n",
        "                                    'pearson_p': pearson_p\n",
        "                                }\n",
        "                            except:\n",
        "                                confidence_correlation = None\n",
        "\n",
        "                        # Class-wise agreement\n",
        "                        class_agreement = {}\n",
        "                        unique_labels = set(labels1) | set(labels2)\n",
        "                        for label in unique_labels:\n",
        "                            mask = (labels1 == label) | (labels2 == label)\n",
        "                            if mask.sum() > 0:\n",
        "                                class_agreement[label] = (labels1[mask] == labels2[mask]).mean()\n",
        "\n",
        "                        # Statistical significance test\n",
        "                        try:\n",
        "                            contingency_table = confusion_matrix(labels1, labels2)\n",
        "                            chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
        "                            statistical_test = {\n",
        "                                'chi2': chi2,\n",
        "                                'p_value': p_value,\n",
        "                                'significant': p_value < 0.05\n",
        "                            }\n",
        "                        except:\n",
        "                            statistical_test = None\n",
        "\n",
        "                        dataset_agreements[pair_name] = {\n",
        "                            'sample_size': len(valid_df),\n",
        "                            'agreement_rate': agreement_rate,\n",
        "                            'cohen_kappa': kappa,\n",
        "                            'confidence_correlation': confidence_correlation,\n",
        "                            'class_agreement': class_agreement,\n",
        "                            'statistical_test': statistical_test\n",
        "                        }\n",
        "\n",
        "                        print(f\"    {pair_name}: {agreement_rate:.3f} agreement, Œ∫={kappa:.3f}\")\n",
        "\n",
        "                    bank_agreements[dataset_type] = dataset_agreements\n",
        "\n",
        "            agreement_results[bank] = bank_agreements\n",
        "\n",
        "        return agreement_results\n",
        "\n",
        "    def analyze_financial_context_performance(self) -> Dict:\n",
        "        \"\"\"Analyze model performance in financial context.\"\"\"\n",
        "        print(\"\\nüí∞ Analyzing financial context performance...\")\n",
        "\n",
        "        financial_context_results = {}\n",
        "\n",
        "        # Enhanced financial indicators\n",
        "        financial_indicators = {\n",
        "            'bullish_indicators': [\n",
        "                'growth', 'profit', 'increase', 'strong', 'improved', 'positive',\n",
        "                'beat', 'exceed', 'outperform', 'robust', 'solid', 'gains', 'higher',\n",
        "                'expansion', 'successful', 'achieving', 'strength'\n",
        "            ],\n",
        "            'bearish_indicators': [\n",
        "                'loss', 'decline', 'decrease', 'weak', 'poor', 'negative',\n",
        "                'miss', 'underperform', 'below', 'concern', 'risk', 'lower',\n",
        "                'challenges', 'pressure', 'difficult', 'disappointing'\n",
        "            ],\n",
        "            'neutral_indicators': [\n",
        "                'stable', 'maintain', 'steady', 'consistent', 'unchanged', 'flat',\n",
        "                'comparable', 'similar', 'continuation', 'ongoing'\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        for bank in self.banks:\n",
        "            bank_financial_results = {}\n",
        "\n",
        "            if bank not in self.sentiment_results:\n",
        "                continue\n",
        "\n",
        "            for dataset_type, df in self.sentiment_results[bank].items():\n",
        "                if df is None or 'text' not in df.columns:\n",
        "                    continue\n",
        "\n",
        "                print(f\"  [{bank.upper()}] {dataset_type}: Financial context analysis\")\n",
        "\n",
        "                # Calculate financial sentiment scores\n",
        "                df_analysis = df.copy()\n",
        "\n",
        "                for indicator_type, keywords in financial_indicators.items():\n",
        "                    pattern = '|'.join([f'\\\\b{kw}\\\\b' for kw in keywords])\n",
        "                    df_analysis[f'{indicator_type}_count'] = df_analysis['text'].str.lower().str.count(pattern)\n",
        "\n",
        "                # Create expected sentiment based on financial indicators\n",
        "                df_analysis['financial_sentiment_score'] = (\n",
        "                    df_analysis['bullish_indicators_count'] * 1 +\n",
        "                    df_analysis['neutral_indicators_count'] * 0 +\n",
        "                    df_analysis['bearish_indicators_count'] * (-1)\n",
        "                )\n",
        "\n",
        "                # Categorize expected sentiment\n",
        "                df_analysis['expected_financial_sentiment'] = 'neutral'\n",
        "                df_analysis.loc[df_analysis['financial_sentiment_score'] > 0, 'expected_financial_sentiment'] = 'positive'\n",
        "                df_analysis.loc[df_analysis['financial_sentiment_score'] < 0, 'expected_financial_sentiment'] = 'negative'\n",
        "\n",
        "                # Analyze model alignment with financial context\n",
        "                dataset_financial_results = {}\n",
        "                available_models = self.identify_available_models(df_analysis)\n",
        "\n",
        "                for model_key in available_models:\n",
        "                    label_col = f\"{model_key}_label\"\n",
        "\n",
        "                    valid_mask = (\n",
        "                        df_analysis[label_col].notna() &\n",
        "                        df_analysis['expected_financial_sentiment'].notna()\n",
        "                    )\n",
        "                    valid_df = df_analysis[valid_mask]\n",
        "\n",
        "                    if len(valid_df) == 0:\n",
        "                        continue\n",
        "\n",
        "                    # Calculate alignment with financial context\n",
        "                    financial_alignment = (\n",
        "                        valid_df[label_col] == valid_df['expected_financial_sentiment']\n",
        "                    ).mean()\n",
        "\n",
        "                    # Strong signal alignment\n",
        "                    strong_signals_mask = np.abs(valid_df['financial_sentiment_score']) >= 2\n",
        "                    strong_signal_alignment = None\n",
        "                    if strong_signals_mask.sum() > 0:\n",
        "                        strong_signal_alignment = (\n",
        "                            valid_df.loc[strong_signals_mask, label_col] ==\n",
        "                            valid_df.loc[strong_signals_mask, 'expected_financial_sentiment']\n",
        "                        ).mean()\n",
        "\n",
        "                    dataset_financial_results[model_key] = {\n",
        "                        'overall_financial_alignment': financial_alignment,\n",
        "                        'strong_signal_alignment': strong_signal_alignment,\n",
        "                        'sample_size': len(valid_df),\n",
        "                        'strong_signals_count': strong_signals_mask.sum()\n",
        "                    }\n",
        "\n",
        "                    print(f\"    {model_key}: {financial_alignment:.3f} financial alignment\")\n",
        "\n",
        "                bank_financial_results[dataset_type] = dataset_financial_results\n",
        "\n",
        "            financial_context_results[bank] = bank_financial_results\n",
        "\n",
        "        return financial_context_results\n",
        "\n",
        "    def create_agreement_based_rankings(self, agreement_results: Dict, financial_results: Dict) -> Dict:\n",
        "        \"\"\"Create model rankings based on agreement metrics and financial alignment.\"\"\"\n",
        "        print(\"\\nüèÜ Ranking models based on agreement and financial alignment...\")\n",
        "\n",
        "        model_scores = {}\n",
        "\n",
        "        # Initialize scores for each model\n",
        "        for model in self.models:\n",
        "            model_scores[model] = {\n",
        "                'agreement_scores': [],\n",
        "                'financial_alignment_scores': [],\n",
        "                'kappa_scores': [],\n",
        "                'confidence_correlations': []\n",
        "            }\n",
        "\n",
        "        # Collect agreement scores\n",
        "        for bank, bank_data in agreement_results.items():\n",
        "            for dataset, dataset_data in bank_data.items():\n",
        "                for pair_name, metrics in dataset_data.items():\n",
        "                    # Extract model names from pair\n",
        "                    if '_vs_' in pair_name:\n",
        "                        model1, model2 = pair_name.split('_vs_')\n",
        "                        agreement_rate = metrics.get('agreement_rate', 0)\n",
        "                        kappa = metrics.get('cohen_kappa', 0)\n",
        "\n",
        "                        # Add scores to both models\n",
        "                        model_scores[model1]['agreement_scores'].append(agreement_rate)\n",
        "                        model_scores[model1]['kappa_scores'].append(kappa)\n",
        "                        model_scores[model2]['agreement_scores'].append(agreement_rate)\n",
        "                        model_scores[model2]['kappa_scores'].append(kappa)\n",
        "\n",
        "                        # Confidence correlation if available\n",
        "                        conf_corr = metrics.get('confidence_correlation')\n",
        "                        if conf_corr and 'pearson_r' in conf_corr:\n",
        "                            model_scores[model1]['confidence_correlations'].append(abs(conf_corr['pearson_r']))\n",
        "                            model_scores[model2]['confidence_correlations'].append(abs(conf_corr['pearson_r']))\n",
        "\n",
        "        # Collect financial alignment scores\n",
        "        for bank, bank_data in financial_results.items():\n",
        "            for dataset, dataset_data in bank_data.items():\n",
        "                for model, metrics in dataset_data.items():\n",
        "                    alignment = metrics.get('overall_financial_alignment', 0)\n",
        "                    model_scores[model]['financial_alignment_scores'].append(alignment)\n",
        "\n",
        "        # Calculate final rankings\n",
        "        final_rankings = {}\n",
        "\n",
        "        for model, scores in model_scores.items():\n",
        "            # Calculate averages\n",
        "            avg_agreement = np.mean(scores['agreement_scores']) if scores['agreement_scores'] else 0\n",
        "            avg_kappa = np.mean(scores['kappa_scores']) if scores['kappa_scores'] else 0\n",
        "            avg_financial = np.mean(scores['financial_alignment_scores']) if scores['financial_alignment_scores'] else 0\n",
        "            avg_conf_corr = np.mean(scores['confidence_correlations']) if scores['confidence_correlations'] else 0\n",
        "\n",
        "            # Create composite score (adjusted weights)\n",
        "            composite_score = (\n",
        "                avg_agreement * 0.35 +      # Inter-model agreement\n",
        "                avg_kappa * 0.25 +          # Statistical agreement quality\n",
        "                avg_financial * 0.30 +      # Financial context alignment\n",
        "                avg_conf_corr * 0.10        # Confidence correlation\n",
        "            )\n",
        "\n",
        "            final_rankings[model] = {\n",
        "                'average_agreement': avg_agreement,\n",
        "                'average_kappa': avg_kappa,\n",
        "                'average_financial_alignment': avg_financial,\n",
        "                'average_confidence_correlation': avg_conf_corr,\n",
        "                'composite_score': composite_score,\n",
        "                'sample_counts': {\n",
        "                    'agreement_pairs': len(scores['agreement_scores']),\n",
        "                    'financial_datasets': len(scores['financial_alignment_scores']),\n",
        "                    'confidence_pairs': len(scores['confidence_correlations'])\n",
        "                }\n",
        "            }\n",
        "\n",
        "        # Sort by composite score\n",
        "        sorted_rankings = sorted(final_rankings.items(), key=lambda x: x[1]['composite_score'], reverse=True)\n",
        "\n",
        "        print(\"Rankings by composite score:\")\n",
        "        for i, (model, metrics) in enumerate(sorted_rankings):\n",
        "            print(f\"  {i+1}. {model}:\")\n",
        "            print(f\"     Composite Score: {metrics['composite_score']:.3f}\")\n",
        "            print(f\"     Agreement: {metrics['average_agreement']:.3f}\")\n",
        "            print(f\"     Kappa: {metrics['average_kappa']:.3f}\")\n",
        "            print(f\"     Financial Alignment: {metrics['average_financial_alignment']:.3f}\")\n",
        "            print(f\"     Confidence Correlation: {metrics['average_confidence_correlation']:.3f}\")\n",
        "\n",
        "        return {\n",
        "            'rankings_by_composite': sorted_rankings,\n",
        "            'detailed_scores': final_rankings,\n",
        "            'best_model': sorted_rankings[0][0] if sorted_rankings else None\n",
        "        }\n",
        "\n",
        "    def analyze_cross_bank_consistency(self, agreement_results: Dict, financial_results: Dict) -> Dict:\n",
        "        \"\"\"Analyze model consistency across banks.\"\"\"\n",
        "        print(\"\\nüè¶ Analyzing cross-bank consistency...\")\n",
        "\n",
        "        cross_bank_results = {}\n",
        "\n",
        "        # Analyze agreement consistency\n",
        "        model_bank_agreement = {}\n",
        "        for bank, bank_data in agreement_results.items():\n",
        "            for dataset, dataset_data in bank_data.items():\n",
        "                for pair_name, metrics in dataset_data.items():\n",
        "                    if '_vs_' in pair_name:\n",
        "                        models = pair_name.split('_vs_')\n",
        "                        agreement = metrics.get('agreement_rate', 0)\n",
        "                        for model in models:\n",
        "                            if model not in model_bank_agreement:\n",
        "                                model_bank_agreement[model] = {}\n",
        "                            if bank not in model_bank_agreement[model]:\n",
        "                                model_bank_agreement[model][bank] = []\n",
        "                            model_bank_agreement[model][bank].append(agreement)\n",
        "\n",
        "        # Analyze financial alignment consistency\n",
        "        model_bank_financial = {}\n",
        "        for bank, bank_data in financial_results.items():\n",
        "            for dataset, dataset_data in bank_data.items():\n",
        "                for model, metrics in dataset_data.items():\n",
        "                    alignment = metrics.get('overall_financial_alignment', 0)\n",
        "                    if model not in model_bank_financial:\n",
        "                        model_bank_financial[model] = {}\n",
        "                    if bank not in model_bank_financial[model]:\n",
        "                        model_bank_financial[model][bank] = []\n",
        "                    model_bank_financial[model][bank].append(alignment)\n",
        "\n",
        "        # Calculate consistency scores\n",
        "        for model in self.models:\n",
        "            agreement_scores = []\n",
        "            financial_scores = []\n",
        "\n",
        "            # Collect scores across banks\n",
        "            if model in model_bank_agreement:\n",
        "                for bank_scores in model_bank_agreement[model].values():\n",
        "                    agreement_scores.extend(bank_scores)\n",
        "\n",
        "            if model in model_bank_financial:\n",
        "                for bank_scores in model_bank_financial[model].values():\n",
        "                    financial_scores.extend(bank_scores)\n",
        "\n",
        "            # Calculate consistency (1 - coefficient of variation)\n",
        "            agreement_consistency = 1 - (np.std(agreement_scores) / (np.mean(agreement_scores) + 1e-8)) if agreement_scores else 0\n",
        "            financial_consistency = 1 - (np.std(financial_scores) / (np.mean(financial_scores) + 1e-8)) if financial_scores else 0\n",
        "\n",
        "            cross_bank_results[model] = {\n",
        "                'agreement_consistency': max(0, agreement_consistency),  # Ensure non-negative\n",
        "                'financial_consistency': max(0, financial_consistency),\n",
        "                'agreement_scores_count': len(agreement_scores),\n",
        "                'financial_scores_count': len(financial_scores),\n",
        "                'avg_agreement': np.mean(agreement_scores) if agreement_scores else 0,\n",
        "                'avg_financial': np.mean(financial_scores) if financial_scores else 0\n",
        "            }\n",
        "\n",
        "            print(f\"  {model}: Agreement consistency={agreement_consistency:.3f}, Financial consistency={financial_consistency:.3f}\")\n",
        "\n",
        "        return cross_bank_results\n",
        "\n",
        "    def run_fixed_comparison(self) -> Dict:\n",
        "        \"\"\"Run fixed model comparison analysis.\"\"\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(\"RUNNING FIXED MODEL COMPARISON\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        # Calculate metrics that work with available data\n",
        "        agreement_metrics = self.calculate_comprehensive_agreement_metrics()\n",
        "        financial_context_analysis = self.analyze_financial_context_performance()\n",
        "\n",
        "        # Create rankings based on available metrics\n",
        "        model_rankings = self.create_agreement_based_rankings(agreement_metrics, financial_context_analysis)\n",
        "\n",
        "        # Analyze cross-bank consistency\n",
        "        cross_bank_analysis = self.analyze_cross_bank_consistency(agreement_metrics, financial_context_analysis)\n",
        "\n",
        "        self.comparison_results = {\n",
        "            'agreement_metrics': agreement_metrics,\n",
        "            'financial_context_analysis': financial_context_analysis,\n",
        "            'model_rankings': model_rankings,\n",
        "            'cross_bank_analysis': cross_bank_analysis\n",
        "        }\n",
        "\n",
        "        return self.comparison_results\n",
        "\n",
        "# Initialize fixed comparator\n",
        "comparator = FixedModelComparator(sentiment_results, finetuning_results)\n",
        "\n",
        "# Run fixed comparison\n",
        "comparison_results = comparator.run_fixed_comparison()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Xq3rrMuiDQO",
        "outputId": "08418508-fe70-43a6-a7ca-30a70be98a56"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fixed comparator initialized:\n",
            "  Banks: 2\n",
            "  Models: 4\n",
            "  Datasets per bank: 3\n",
            "\n",
            "============================================================\n",
            "RUNNING FIXED MODEL COMPARISON\n",
            "============================================================\n",
            "\n",
            "ü§ù Calculating comprehensive agreement metrics...\n",
            "  [JPM] q1_2025: 4 models available\n",
            "    finbert_yiyanghkust_vs_finbert_prosusai: 0.789 agreement, Œ∫=0.406\n",
            "    finbert_yiyanghkust_vs_distilroberta: 0.636 agreement, Œ∫=0.050\n",
            "    finbert_yiyanghkust_vs_cardiffnlp_roberta: 0.671 agreement, Œ∫=0.309\n",
            "    finbert_prosusai_vs_distilroberta: 0.741 agreement, Œ∫=0.050\n",
            "    finbert_prosusai_vs_cardiffnlp_roberta: 0.709 agreement, Œ∫=0.292\n",
            "    distilroberta_vs_cardiffnlp_roberta: 0.591 agreement, Œ∫=0.076\n",
            "  [JPM] q2_2025: 4 models available\n",
            "    finbert_yiyanghkust_vs_finbert_prosusai: 0.782 agreement, Œ∫=0.423\n",
            "    finbert_yiyanghkust_vs_distilroberta: 0.666 agreement, Œ∫=0.106\n",
            "    finbert_yiyanghkust_vs_cardiffnlp_roberta: 0.693 agreement, Œ∫=0.361\n",
            "    finbert_prosusai_vs_distilroberta: 0.741 agreement, Œ∫=0.117\n",
            "    finbert_prosusai_vs_cardiffnlp_roberta: 0.686 agreement, Œ∫=0.284\n",
            "    distilroberta_vs_cardiffnlp_roberta: 0.593 agreement, Œ∫=0.093\n",
            "  [JPM] combined: 4 models available\n",
            "    finbert_yiyanghkust_vs_finbert_prosusai: 0.785 agreement, Œ∫=0.418\n",
            "    finbert_yiyanghkust_vs_distilroberta: 0.653 agreement, Œ∫=0.082\n",
            "    finbert_yiyanghkust_vs_cardiffnlp_roberta: 0.685 agreement, Œ∫=0.342\n",
            "    finbert_prosusai_vs_distilroberta: 0.741 agreement, Œ∫=0.090\n",
            "    finbert_prosusai_vs_cardiffnlp_roberta: 0.697 agreement, Œ∫=0.290\n",
            "    distilroberta_vs_cardiffnlp_roberta: 0.593 agreement, Œ∫=0.086\n",
            "  [HSBC] q1_2025: 4 models available\n",
            "    finbert_yiyanghkust_vs_finbert_prosusai: 0.777 agreement, Œ∫=0.584\n",
            "    finbert_yiyanghkust_vs_distilroberta: 0.550 agreement, Œ∫=0.080\n",
            "    finbert_yiyanghkust_vs_cardiffnlp_roberta: 0.730 agreement, Œ∫=0.494\n",
            "    finbert_prosusai_vs_distilroberta: 0.517 agreement, Œ∫=0.073\n",
            "    finbert_prosusai_vs_cardiffnlp_roberta: 0.753 agreement, Œ∫=0.541\n",
            "    distilroberta_vs_cardiffnlp_roberta: 0.540 agreement, Œ∫=0.132\n",
            "  [HSBC] q2_2025: 4 models available\n",
            "    finbert_yiyanghkust_vs_finbert_prosusai: 0.815 agreement, Œ∫=0.655\n",
            "    finbert_yiyanghkust_vs_distilroberta: 0.571 agreement, Œ∫=0.041\n",
            "    finbert_yiyanghkust_vs_cardiffnlp_roberta: 0.806 agreement, Œ∫=0.622\n",
            "    finbert_prosusai_vs_distilroberta: 0.544 agreement, Œ∫=0.017\n",
            "    finbert_prosusai_vs_cardiffnlp_roberta: 0.762 agreement, Œ∫=0.542\n",
            "    distilroberta_vs_cardiffnlp_roberta: 0.618 agreement, Œ∫=0.097\n",
            "  [HSBC] combined: 4 models available\n",
            "    finbert_yiyanghkust_vs_finbert_prosusai: 0.798 agreement, Œ∫=0.622\n",
            "    finbert_yiyanghkust_vs_distilroberta: 0.569 agreement, Œ∫=0.065\n",
            "    finbert_yiyanghkust_vs_cardiffnlp_roberta: 0.778 agreement, Œ∫=0.572\n",
            "    finbert_prosusai_vs_distilroberta: 0.537 agreement, Œ∫=0.051\n",
            "    finbert_prosusai_vs_cardiffnlp_roberta: 0.764 agreement, Œ∫=0.550\n",
            "    distilroberta_vs_cardiffnlp_roberta: 0.588 agreement, Œ∫=0.119\n",
            "\n",
            "üí∞ Analyzing financial context performance...\n",
            "  [JPM] q1_2025: Financial context analysis\n",
            "    finbert_yiyanghkust: 0.703 financial alignment\n",
            "    finbert_prosusai: 0.767 financial alignment\n",
            "    distilroberta: 0.706 financial alignment\n",
            "    cardiffnlp_roberta: 0.550 financial alignment\n",
            "  [JPM] q2_2025: Financial context analysis\n",
            "    finbert_yiyanghkust: 0.718 financial alignment\n",
            "    finbert_prosusai: 0.786 financial alignment\n",
            "    distilroberta: 0.761 financial alignment\n",
            "    cardiffnlp_roberta: 0.609 financial alignment\n",
            "  [JPM] combined: Financial context analysis\n",
            "    finbert_yiyanghkust: 0.711 financial alignment\n",
            "    finbert_prosusai: 0.778 financial alignment\n",
            "    distilroberta: 0.738 financial alignment\n",
            "    cardiffnlp_roberta: 0.585 financial alignment\n",
            "  [HSBC] q1_2025: Financial context analysis\n",
            "    finbert_yiyanghkust: 0.693 financial alignment\n",
            "    finbert_prosusai: 0.653 financial alignment\n",
            "    distilroberta: 0.653 financial alignment\n",
            "    cardiffnlp_roberta: 0.607 financial alignment\n",
            "  [HSBC] q2_2025: Financial context analysis\n",
            "    finbert_yiyanghkust: 0.674 financial alignment\n",
            "    finbert_prosusai: 0.668 financial alignment\n",
            "    distilroberta: 0.718 financial alignment\n",
            "    cardiffnlp_roberta: 0.665 financial alignment\n",
            "  [HSBC] combined: Financial context analysis\n",
            "    finbert_yiyanghkust: 0.680 financial alignment\n",
            "    finbert_prosusai: 0.658 financial alignment\n",
            "    distilroberta: 0.689 financial alignment\n",
            "    cardiffnlp_roberta: 0.637 financial alignment\n",
            "\n",
            "üèÜ Ranking models based on agreement and financial alignment...\n",
            "Rankings by composite score:\n",
            "  1. finbert_prosusai:\n",
            "     Composite Score: 0.582\n",
            "     Agreement: 0.719\n",
            "     Kappa: 0.334\n",
            "     Financial Alignment: 0.718\n",
            "     Confidence Correlation: 0.313\n",
            "  2. finbert_yiyanghkust:\n",
            "     Composite Score: 0.577\n",
            "     Agreement: 0.708\n",
            "     Kappa: 0.346\n",
            "     Financial Alignment: 0.697\n",
            "     Confidence Correlation: 0.335\n",
            "  3. cardiffnlp_roberta:\n",
            "     Composite Score: 0.526\n",
            "     Agreement: 0.681\n",
            "     Kappa: 0.322\n",
            "     Financial Alignment: 0.609\n",
            "     Confidence Correlation: 0.240\n",
            "  4. distilroberta:\n",
            "     Composite Score: 0.472\n",
            "     Agreement: 0.610\n",
            "     Kappa: 0.079\n",
            "     Financial Alignment: 0.711\n",
            "     Confidence Correlation: 0.253\n",
            "\n",
            "üè¶ Analyzing cross-bank consistency...\n",
            "  finbert_yiyanghkust: Agreement consistency=0.879, Financial consistency=0.977\n",
            "  finbert_prosusai: Agreement consistency=0.875, Financial consistency=0.918\n",
            "  distilroberta: Agreement consistency=0.885, Financial consistency=0.951\n",
            "  cardiffnlp_roberta: Agreement consistency=0.889, Financial consistency=0.940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Enhanced Research Questions Analysis\n",
        "\n",
        "def analyze_research_questions() -> Dict:\n",
        "    \"\"\"Analyze research questions with available data.\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"RESEARCH QUESTIONS ANALYSIS\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    research_results = {}\n",
        "\n",
        "    # Question 1: Do bankers and analysts show diverging sentiment?\n",
        "    print(\"\\n1. üìä Banker vs Analyst Sentiment Divergence\")\n",
        "\n",
        "    speaker_analysis = {}\n",
        "    for bank in BANKS:\n",
        "        if bank in sentiment_results:\n",
        "            for dataset_type, df in sentiment_results[bank].items():\n",
        "                if df is None or 'speaker_role' not in df.columns:\n",
        "                    continue\n",
        "\n",
        "                print(f\"  [{bank.upper()}] {dataset_type}:\")\n",
        "\n",
        "                available_models = comparator.identify_available_models(df)\n",
        "                for model_key in available_models:\n",
        "                    label_col = f'{model_key}_label'\n",
        "\n",
        "                    # Filter to analysts and executives\n",
        "                    speaker_mask = df['speaker_role'].isin(['analyst', 'executive', 'ceo', 'cfo'])\n",
        "                    speaker_df = df[speaker_mask]\n",
        "\n",
        "                    if len(speaker_df) == 0:\n",
        "                        continue\n",
        "\n",
        "                    # Calculate sentiment distributions\n",
        "                    try:\n",
        "                        speaker_sentiment = speaker_df.groupby('speaker_role')[label_col].value_counts(normalize=True).unstack(fill_value=0)\n",
        "\n",
        "                        if len(speaker_sentiment) >= 2:\n",
        "                            # Statistical test for difference\n",
        "                            contingency_table = speaker_df.groupby(['speaker_role', label_col]).size().unstack(fill_value=0)\n",
        "                            chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "                            print(f\"    {model_key}: œá¬≤={chi2:.3f}, p={p_value:.3f}\")\n",
        "\n",
        "                            speaker_analysis[f\"{bank}_{dataset_type}_{model_key}\"] = {\n",
        "                                'speaker_distributions': speaker_sentiment.to_dict(),\n",
        "                                'chi2_statistic': chi2,\n",
        "                                'p_value': p_value,\n",
        "                                'significant_divergence': p_value < 0.05\n",
        "                            }\n",
        "                    except Exception as e:\n",
        "                        print(f\"    {model_key}: Analysis failed - {e}\")\n",
        "\n",
        "    research_results['speaker_divergence'] = speaker_analysis\n",
        "\n",
        "    # Question 2: Has tone shifted over time?\n",
        "    print(\"\\n2. ‚è∞ Temporal Tone Analysis\")\n",
        "\n",
        "    temporal_analysis = {}\n",
        "    for bank in BANKS:\n",
        "        if bank in sentiment_results:\n",
        "            # Compare Q1 vs Q2 if both available\n",
        "            if 'q1_2025' in sentiment_results[bank] and 'q2_2025' in sentiment_results[bank]:\n",
        "                q1_df = sentiment_results[bank]['q1_2025']\n",
        "                q2_df = sentiment_results[bank]['q2_2025']\n",
        "\n",
        "                if q1_df is not None and q2_df is not None:\n",
        "                    print(f\"  [{bank.upper()}] Q1 vs Q2 comparison:\")\n",
        "\n",
        "                    available_models = set(comparator.identify_available_models(q1_df)) & set(comparator.identify_available_models(q2_df))\n",
        "\n",
        "                    for model_key in available_models:\n",
        "                        label_col = f'{model_key}_label'\n",
        "\n",
        "                        q1_sentiment = q1_df[label_col].value_counts(normalize=True)\n",
        "                        q2_sentiment = q2_df[label_col].value_counts(normalize=True)\n",
        "\n",
        "                        # Calculate sentiment shift\n",
        "                        sentiment_shift = {}\n",
        "                        for label in ['positive', 'neutral', 'negative']:\n",
        "                            q1_pct = q1_sentiment.get(label, 0)\n",
        "                            q2_pct = q2_sentiment.get(label, 0)\n",
        "                            sentiment_shift[label] = q2_pct - q1_pct\n",
        "\n",
        "                        # Total variation distance\n",
        "                        tvd = 0.5 * sum(abs(sentiment_shift[label]) for label in sentiment_shift)\n",
        "\n",
        "                        print(f\"    {model_key}: TVD={tvd:.3f}\")\n",
        "\n",
        "                        temporal_analysis[f\"{bank}_{model_key}\"] = {\n",
        "                            'q1_distribution': q1_sentiment.to_dict(),\n",
        "                            'q2_distribution': q2_sentiment.to_dict(),\n",
        "                            'sentiment_shift': sentiment_shift,\n",
        "                            'total_variation_distance': tvd\n",
        "                        }\n",
        "\n",
        "    research_results['temporal_shifts'] = temporal_analysis\n",
        "\n",
        "    # Question 3: Cross-bank tone comparison\n",
        "    print(\"\\n3. üè¶ Cross-Bank Tone Comparison\")\n",
        "\n",
        "    cross_bank_comparison = {}\n",
        "    if len(BANKS) >= 2:\n",
        "        # Compare sentiment distributions across banks\n",
        "        for model_key in MODELS.keys():\n",
        "            bank_distributions = {}\n",
        "\n",
        "            for bank in BANKS:\n",
        "                if bank in sentiment_results and 'combined' in sentiment_results[bank]:\n",
        "                    df = sentiment_results[bank]['combined']\n",
        "                    if df is not None:\n",
        "                        label_col = f'{model_key}_label'\n",
        "                        if label_col in df.columns:\n",
        "                            sentiment_dist = df[label_col].value_counts(normalize=True)\n",
        "                            bank_distributions[bank] = sentiment_dist.to_dict()\n",
        "\n",
        "            if len(bank_distributions) >= 2:\n",
        "                # Calculate pairwise differences\n",
        "                bank_pairs = list(itertools.combinations(bank_distributions.keys(), 2))\n",
        "\n",
        "                pairwise_comparisons = {}\n",
        "                for bank1, bank2 in bank_pairs:\n",
        "                    dist1 = bank_distributions[bank1]\n",
        "                    dist2 = bank_distributions[bank2]\n",
        "\n",
        "                    # Total variation distance\n",
        "                    labels = set(dist1.keys()) | set(dist2.keys())\n",
        "                    tvd = 0.5 * sum(abs(dist1.get(label, 0) - dist2.get(label, 0)) for label in labels)\n",
        "\n",
        "                    pairwise_comparisons[f\"{bank1}_vs_{bank2}\"] = {\n",
        "                        'bank1_distribution': dist1,\n",
        "                        'bank2_distribution': dist2,\n",
        "                        'total_variation_distance': tvd\n",
        "                    }\n",
        "\n",
        "                    print(f\"  {model_key} - {bank1.upper()} vs {bank2.upper()}: TVD={tvd:.3f}\")\n",
        "\n",
        "                cross_bank_comparison[model_key] = {\n",
        "                    'bank_distributions': bank_distributions,\n",
        "                    'pairwise_comparisons': pairwise_comparisons\n",
        "                }\n",
        "\n",
        "    research_results['cross_bank_comparison'] = cross_bank_comparison\n",
        "\n",
        "    return research_results\n",
        "\n",
        "# Run research questions analysis\n",
        "research_questions_results = analyze_research_questions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVG3BririO4I",
        "outputId": "227e0393-020e-4f5b-e923-6a7ad5a1bc3d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "RESEARCH QUESTIONS ANALYSIS\n",
            "============================================================\n",
            "\n",
            "1. üìä Banker vs Analyst Sentiment Divergence\n",
            "  [JPM] q1_2025:\n",
            "  [JPM] q2_2025:\n",
            "  [JPM] combined:\n",
            "  [HSBC] q1_2025:\n",
            "  [HSBC] q2_2025:\n",
            "  [HSBC] combined:\n",
            "\n",
            "2. ‚è∞ Temporal Tone Analysis\n",
            "  [JPM] Q1 vs Q2 comparison:\n",
            "    finbert_yiyanghkust: TVD=0.069\n",
            "    cardiffnlp_roberta: TVD=0.047\n",
            "    finbert_prosusai: TVD=0.065\n",
            "    distilroberta: TVD=0.008\n",
            "  [HSBC] Q1 vs Q2 comparison:\n",
            "    finbert_yiyanghkust: TVD=0.044\n",
            "    cardiffnlp_roberta: TVD=0.053\n",
            "    finbert_prosusai: TVD=0.002\n",
            "    distilroberta: TVD=0.050\n",
            "\n",
            "3. üè¶ Cross-Bank Tone Comparison\n",
            "  finbert_yiyanghkust - JPM vs HSBC: TVD=0.143\n",
            "  finbert_prosusai - JPM vs HSBC: TVD=0.249\n",
            "  distilroberta - JPM vs HSBC: TVD=0.051\n",
            "  cardiffnlp_roberta - JPM vs HSBC: TVD=0.108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Model Characteristics Analysis\n",
        "\n",
        "def analyze_model_characteristics():\n",
        "    \"\"\"Analyze what each model is good at based on available data.\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"MODEL CHARACTERISTICS ANALYSIS\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Best for inter-model agreement\n",
        "    print(\"\\nü§ù Model Agreement Rankings:\")\n",
        "    agreement_scores = {}\n",
        "    for bank, bank_data in comparison_results['agreement_metrics'].items():\n",
        "        for dataset, dataset_data in bank_data.items():\n",
        "            for pair_name, metrics in dataset_data.items():\n",
        "                if '_vs_' in pair_name:\n",
        "                    models = pair_name.split('_vs_')\n",
        "                    agreement = metrics.get('agreement_rate', 0)\n",
        "                    for model in models:\n",
        "                        if model not in agreement_scores:\n",
        "                            agreement_scores[model] = []\n",
        "                        agreement_scores[model].append(agreement)\n",
        "\n",
        "    for model, scores in sorted(agreement_scores.items(), key=lambda x: np.mean(x[1]), reverse=True):\n",
        "        print(f\"  {model}: {np.mean(scores):.3f} avg agreement\")\n",
        "\n",
        "    # Best for financial context\n",
        "    print(\"\\nüí∞ Financial Context Rankings:\")\n",
        "    financial_scores = {}\n",
        "    for bank, bank_data in comparison_results['financial_context_analysis'].items():\n",
        "        for dataset, dataset_data in bank_data.items():\n",
        "            for model, metrics in dataset_data.items():\n",
        "                alignment = metrics.get('overall_financial_alignment', 0)\n",
        "                if model not in financial_scores:\n",
        "                    financial_scores[model] = []\n",
        "                financial_scores[model].append(alignment)\n",
        "\n",
        "    for model, scores in sorted(financial_scores.items(), key=lambda x: np.mean(x[1]), reverse=True):\n",
        "        print(f\"  {model}: {np.mean(scores):.3f} avg financial alignment\")\n",
        "\n",
        "    # Model pairing analysis\n",
        "    print(\"\\nüîó Best Model Pairs (Highest Agreement):\")\n",
        "    all_pairs = []\n",
        "    for bank, bank_data in comparison_results['agreement_metrics'].items():\n",
        "        for dataset, dataset_data in bank_data.items():\n",
        "            for pair_name, metrics in dataset_data.items():\n",
        "                if '_vs_' in pair_name:\n",
        "                    agreement = metrics.get('agreement_rate', 0)\n",
        "                    kappa = metrics.get('cohen_kappa', 0)\n",
        "                    all_pairs.append((pair_name, agreement, kappa))\n",
        "\n",
        "    # Sort by agreement rate\n",
        "    top_pairs = sorted(all_pairs, key=lambda x: x[1], reverse=True)[:5]\n",
        "    for pair, agreement, kappa in top_pairs:\n",
        "        print(f\"  {pair}: {agreement:.3f} agreement, Œ∫={kappa:.3f}\")\n",
        "\n",
        "    # Cross-bank consistency\n",
        "    print(\"\\nüè¶ Cross-Bank Consistency:\")\n",
        "    for model, metrics in comparison_results['cross_bank_analysis'].items():\n",
        "        agreement_consistency = metrics.get('agreement_consistency', 0)\n",
        "        financial_consistency = metrics.get('financial_consistency', 0)\n",
        "        print(f\"  {model}: Agreement={agreement_consistency:.3f}, Financial={financial_consistency:.3f}\")\n",
        "\n",
        "analyze_model_characteristics()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKuDBoE3if9Y",
        "outputId": "23256d5a-1cc7-457a-bb9e-21f79e5daf6a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "MODEL CHARACTERISTICS ANALYSIS\n",
            "============================================================\n",
            "\n",
            "ü§ù Model Agreement Rankings:\n",
            "  finbert_prosusai: 0.719 avg agreement\n",
            "  finbert_yiyanghkust: 0.708 avg agreement\n",
            "  cardiffnlp_roberta: 0.681 avg agreement\n",
            "  distilroberta: 0.610 avg agreement\n",
            "\n",
            "üí∞ Financial Context Rankings:\n",
            "  finbert_prosusai: 0.718 avg financial alignment\n",
            "  distilroberta: 0.711 avg financial alignment\n",
            "  finbert_yiyanghkust: 0.697 avg financial alignment\n",
            "  cardiffnlp_roberta: 0.609 avg financial alignment\n",
            "\n",
            "üîó Best Model Pairs (Highest Agreement):\n",
            "  finbert_yiyanghkust_vs_finbert_prosusai: 0.815 agreement, Œ∫=0.655\n",
            "  finbert_yiyanghkust_vs_cardiffnlp_roberta: 0.806 agreement, Œ∫=0.622\n",
            "  finbert_yiyanghkust_vs_finbert_prosusai: 0.798 agreement, Œ∫=0.622\n",
            "  finbert_yiyanghkust_vs_finbert_prosusai: 0.789 agreement, Œ∫=0.406\n",
            "  finbert_yiyanghkust_vs_finbert_prosusai: 0.785 agreement, Œ∫=0.418\n",
            "\n",
            "üè¶ Cross-Bank Consistency:\n",
            "  finbert_yiyanghkust: Agreement=0.879, Financial=0.977\n",
            "  finbert_prosusai: Agreement=0.875, Financial=0.918\n",
            "  distilroberta: Agreement=0.885, Financial=0.951\n",
            "  cardiffnlp_roberta: Agreement=0.889, Financial=0.940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Save Enhanced Comparison Results\n",
        "\n",
        "def save_enhanced_comparison_results():\n",
        "    \"\"\"Save all enhanced comparison results.\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"SAVING ENHANCED COMPARISON RESULTS\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Compile comprehensive results\n",
        "    comprehensive_results = {\n",
        "        'timestamp': pd.Timestamp.now().isoformat(),\n",
        "        'banks_analyzed': BANKS,\n",
        "        'models_compared': list(MODELS.keys()),\n",
        "        'analysis_type': 'agreement_based_without_manual_validation',\n",
        "        'analysis_components': {\n",
        "            'model_comparison': comparison_results,\n",
        "            'research_questions': research_questions_results,\n",
        "            'finetuning_integration': finetuning_results\n",
        "        },\n",
        "        'summary_statistics': {\n",
        "            'total_models_compared': len(MODELS),\n",
        "            'total_banks_analyzed': len(BANKS),\n",
        "            'best_model': comparison_results.get('model_rankings', {}).get('best_model'),\n",
        "            'analysis_timestamp': pd.Timestamp.now().isoformat()\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Save main results for each bank\n",
        "    for bank in BANKS:\n",
        "        results_file = comparison_paths[bank][\"results_comparison\"] / f\"fixed_model_comparison_{bank}.json\"\n",
        "        try:\n",
        "            with open(results_file, 'w') as f:\n",
        "                json.dump(comprehensive_results, f, indent=2, default=str)\n",
        "            print(f\"  ‚úÖ {bank.upper()} comparison results: {results_file}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ùå Failed to save {bank.upper()} results: {e}\")\n",
        "\n",
        "    # Save consolidated multi-bank results\n",
        "    consolidated_file = drive_base / \"results\" / \"fixed_multi_bank_model_comparison.json\"\n",
        "    consolidated_file.parent.mkdir(parents=True, exist_ok=True)\n",
        "    try:\n",
        "        with open(consolidated_file, 'w') as f:\n",
        "            json.dump(comprehensive_results, f, indent=2, default=str)\n",
        "        print(f\"  ‚úÖ Consolidated comparison: {consolidated_file}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ùå Failed to save consolidated results: {e}\")\n",
        "\n",
        "    return comprehensive_results\n",
        "\n",
        "# Save enhanced comparison results\n",
        "saved_comparison_results = save_enhanced_comparison_results()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUCsGFq5iw6r",
        "outputId": "aa25f3cb-916c-4087-c2b1-dbb4d9b23a36"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "SAVING ENHANCED COMPARISON RESULTS\n",
            "============================================================\n",
            "  ‚úÖ JPM comparison results: /content/drive/MyDrive/CAM_DS_AI_Project_Enhanced/results/comparison/jpm/fixed_model_comparison_jpm.json\n",
            "  ‚úÖ HSBC comparison results: /content/drive/MyDrive/CAM_DS_AI_Project_Enhanced/results/comparison/hsbc/fixed_model_comparison_hsbc.json\n",
            "  ‚úÖ Consolidated comparison: /content/drive/MyDrive/CAM_DS_AI_Project_Enhanced/results/fixed_multi_bank_model_comparison.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Final Summary\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"FIXED MODEL COMPARISON COMPLETE\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# Performance summary\n",
        "if 'model_rankings' in comparison_results and 'best_model' in comparison_results['model_rankings']:\n",
        "    best_model = comparison_results['model_rankings']['best_model']\n",
        "    print(f\"\\nüèÜ Best Performing Model: {best_model}\")\n",
        "\n",
        "    # Show rankings\n",
        "    rankings = comparison_results['model_rankings']['rankings_by_composite']\n",
        "    print(f\"\\nFinal Rankings:\")\n",
        "    for i, (model, metrics) in enumerate(rankings):\n",
        "        print(f\"  {i+1}. {model}: {metrics['composite_score']:.3f} composite score\")\n",
        "\n",
        "# Model agreement summary\n",
        "if 'agreement_metrics' in comparison_results:\n",
        "    print(f\"\\nü§ù Model Agreement Summary:\")\n",
        "    all_agreements = []\n",
        "\n",
        "    for bank, bank_data in comparison_results['agreement_metrics'].items():\n",
        "        for dataset_type, dataset_data in bank_data.items():\n",
        "            for pair, metrics in dataset_data.items():\n",
        "                agreement_rate = metrics.get('agreement_rate', 0)\n",
        "                all_agreements.append(agreement_rate)\n",
        "\n",
        "    if all_agreements:\n",
        "        avg_agreement = np.mean(all_agreements)\n",
        "        print(f\"  Average inter-model agreement: {avg_agreement:.3f}\")\n",
        "\n",
        "# Research questions summary\n",
        "print(f\"\\nüìã Research Questions Summary:\")\n",
        "\n",
        "if 'speaker_divergence' in research_questions_results:\n",
        "    significant_divergences = sum(\n",
        "        1 for analysis in research_questions_results['speaker_divergence'].values()\n",
        "        if analysis.get('significant_divergence', False)\n",
        "    )\n",
        "    total_tests = len(research_questions_results['speaker_divergence'])\n",
        "    if total_tests > 0:\n",
        "        print(f\"  Banker vs Analyst divergence: {significant_divergences}/{total_tests} tests show significant differences\")\n",
        "\n",
        "if 'temporal_shifts' in research_questions_results:\n",
        "    temporal_shifts = research_questions_results['temporal_shifts'].values()\n",
        "    if temporal_shifts:\n",
        "        avg_temporal_shift = np.mean([\n",
        "            analysis.get('total_variation_distance', 0)\n",
        "            for analysis in temporal_shifts\n",
        "        ])\n",
        "        print(f\"  Average temporal shift (TVD): {avg_temporal_shift:.3f}\")\n",
        "\n",
        "if 'cross_bank_comparison' in research_questions_results:\n",
        "    cross_bank_diffs = []\n",
        "    for model_data in research_questions_results['cross_bank_comparison'].values():\n",
        "        for pair_data in model_data.get('pairwise_comparisons', {}).values():\n",
        "            cross_bank_diffs.append(pair_data.get('total_variation_distance', 0))\n",
        "\n",
        "    if cross_bank_diffs:\n",
        "        avg_cross_bank_diff = np.mean(cross_bank_diffs)\n",
        "        print(f\"  Average cross-bank difference (TVD): {avg_cross_bank_diff:.3f}\")\n",
        "\n",
        "# File summary\n",
        "print(f\"\\nüìÅ Files Generated:\")\n",
        "print(f\"  Fixed comparison results: Saved for all {len(BANKS)} banks\")\n",
        "print(f\"  Agreement-based analysis: Complete\")\n",
        "print(f\"  Research analysis: Statistical testing complete\")\n",
        "\n",
        "print(f\"\\nüöÄ Fixed model comparison framework complete!\")\n",
        "print(f\"   Analysis based on inter-model agreement and financial context\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dC2qPTwOi2f2",
        "outputId": "47ae7b0a-595a-4b7c-e95e-ec4e377d333a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "FIXED MODEL COMPARISON COMPLETE\n",
            "============================================================\n",
            "\n",
            "üèÜ Best Performing Model: finbert_prosusai\n",
            "\n",
            "Final Rankings:\n",
            "  1. finbert_prosusai: 0.582 composite score\n",
            "  2. finbert_yiyanghkust: 0.577 composite score\n",
            "  3. cardiffnlp_roberta: 0.526 composite score\n",
            "  4. distilroberta: 0.472 composite score\n",
            "\n",
            "ü§ù Model Agreement Summary:\n",
            "  Average inter-model agreement: 0.680\n",
            "\n",
            "üìã Research Questions Summary:\n",
            "  Average temporal shift (TVD): 0.042\n",
            "  Average cross-bank difference (TVD): 0.138\n",
            "\n",
            "üìÅ Files Generated:\n",
            "  Fixed comparison results: Saved for all 2 banks\n",
            "  Agreement-based analysis: Complete\n",
            "  Research analysis: Statistical testing complete\n",
            "\n",
            "üöÄ Fixed model comparison framework complete!\n",
            "   Analysis based on inter-model agreement and financial context\n"
          ]
        }
      ]
    }
  ]
}