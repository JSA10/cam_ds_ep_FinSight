{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "805017bd",
   "metadata": {},
   "source": [
    "# PRA Risk Summaries & Evasiveness Detector — **Lazy-Load + Cache-Warm**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6437df4c",
   "metadata": {},
   "source": [
    "Optimised for Apple Silicon (M3/MPS). Generates PRA risk-aligned summaries and flags banker evasiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92251fd1",
   "metadata": {},
   "source": [
    "\n",
    "## Install (uv) quickstart\n",
    "```bash\n",
    "cat > requirements-fast.txt << 'EOF'\n",
    "--only-binary=:all:\n",
    "pip>=24\n",
    "setuptools>=70\n",
    "wheel>=0.43\n",
    "torch==2.4.*\n",
    "transformers==4.44.*\n",
    "tokenizers==0.19.*\n",
    "sentence-transformers==3.0.1\n",
    "accelerate\n",
    "huggingface_hub[cli]\n",
    "hf-transfer\n",
    "numpy\n",
    "pandas\n",
    "matplotlib\n",
    "textstat\n",
    "EOF\n",
    "\n",
    "uv pip install -r requirements-fast.txt\n",
    "export TRANSFORMERS_NO_TF=1\n",
    "export TRANSFORMERS_NO_FLAX=1\n",
    "export TOKENIZERS_PARALLELISM=false\n",
    "export HF_HUB_ENABLE_HF_TRANSFER=1\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a09587",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Light env & system check\n",
    "import os, sys, platform, warnings, re\n",
    "from pathlib import Path\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.environ.setdefault(\"TRANSFORMERS_NO_TF\", \"1\")\n",
    "os.environ.setdefault(\"TRANSFORMERS_NO_FLAX\", \"1\")\n",
    "os.environ.setdefault(\"TOKENIZERS_PARALLELISM\", \"false\")\n",
    "os.environ.setdefault(\"HF_HUB_ENABLE_HF_TRANSFER\", \"1\")\n",
    "os.environ.setdefault(\"HF_HUB_DISABLE_TELEMETRY\", \"1\")\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0], \"| OS:\", platform.platform(), \"| Arch:\", platform.machine())\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    print(\"Torch:\", torch.__version__, \"| MPS built:\", torch.backends.mps.is_built(), \"| MPS avail:\", torch.backends.mps.is_available())\n",
    "    DEVICE = \"mps\" if torch.backends.mps.is_available() and torch.backends.mps.is_built() else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "except Exception as e:\n",
    "    print(\"Torch not available:\", e); DEVICE=\"cpu\"\n",
    "\n",
    "SEED=42; np.random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513de5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Config\n",
    "DATA_DIR = Path(\"../data/processed\")\n",
    "JPM_PATH = DATA_DIR / \"jpm\" / \"all_jpm_2023_2025.csv\"\n",
    "HSBC_PATH = DATA_DIR / \"hsbc\" / \"all_hsbc_2023_2025.csv\"\n",
    "PRA_PATHS = [DATA_DIR / \"PRA Risk Categories.csv\", DATA_DIR / \"PRA Risk Categories - Sheet1.csv\"]\n",
    "\n",
    "EMBED_MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "SUMM_MODEL_ID  = \"sshleifer/distilbart-cnn-12-6\"\n",
    "\n",
    "SIMILARITY_LOW = 0.38\n",
    "HEDGE_MIN_COUNT = 2\n",
    "VERBOSITY_RATIO_HIGH = 6.0\n",
    "READABILITY_SIMPLE = 8.0\n",
    "EVASION_SCORE_FLAG = 0.65\n",
    "\n",
    "SUMMARY_TARGET_WORDS = 120\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fbb45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Warm model cache\n",
    "from huggingface_hub import snapshot_download\n",
    "def warm_cache(model_id: str):\n",
    "    path = snapshot_download(repo_id=model_id, local_files_only=False)\n",
    "    print(f\"Cached -> {path}\")\n",
    "try:\n",
    "    warm_cache(EMBED_MODEL_ID); warm_cache(SUMM_MODEL_ID)\n",
    "except Exception as e:\n",
    "    print(\"Cache warm skipped:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900ccaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Helpers\n",
    "HEDGE_PHRASES = [\n",
    "    \"i think\",\"we think\",\"i believe\",\"we believe\",\"we feel\",\"i feel\",\n",
    "    \"sort of\",\"kind of\",\"a bit\",\"a little\",\"roughly\",\"approximately\",\"around\",\"more or less\",\"to some extent\",\"somewhat\",\n",
    "    \"we don't break out\",\"we do not break out\",\"we don't disclose\",\"we do not disclose\",\n",
    "    \"we won't comment\",\"we will not comment\",\"not going to comment\",\n",
    "    \"too early to say\",\"too soon to say\",\"too soon to tell\",\n",
    "    \"we'll have to see\",\"we will have to see\",\"we'll come back\",\"we will come back\",\n",
    "    \"as we've said before\",\"as we said before\",\"as previously mentioned\",\"as mentioned\",\n",
    "    \"let me step back\",\"take a step back\",\"the way i would frame\",\"i would frame it\",\n",
    "    \"i'm not sure\",\"we're not sure\",\"it's complicated\",\"it's complex\",\"moving parts\",\n",
    "    \"as you know\",\"as you can appreciate\",\"that's a great question\",\"good question\",\n",
    "    \"let me answer a different\",\"let me start somewhere else\"\n",
    "]\n",
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", (s or \"\")).strip()\n",
    "\n",
    "def count_hedges(text: str) -> int:\n",
    "    t = \" \" + (text or \"\").lower() + \" \"\n",
    "    return sum(1 for p in HEDGE_PHRASES if f\" {p} \" in t)\n",
    "\n",
    "def fk_grade(text: str) -> float:\n",
    "    try:\n",
    "        import textstat\n",
    "        return textstat.flesch_kincaid_grade(text or \"\")\n",
    "    except Exception:\n",
    "        import math; return math.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776e1717",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lazy loaders\n",
    "import functools\n",
    "def _best_device():\n",
    "    try:\n",
    "        import torch\n",
    "        if torch.backends.mps.is_available() and torch.backends.mps.is_built(): return \"mps\"\n",
    "        if torch.cuda.is_available(): return \"cuda\"\n",
    "    except Exception: pass\n",
    "    return \"cpu\"\n",
    "\n",
    "@functools.lru_cache(maxsize=1)\n",
    "def get_embedder(model_id=EMBED_MODEL_ID):\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    dev = _best_device()\n",
    "    return SentenceTransformer(model_id, device=dev), dev\n",
    "\n",
    "@functools.lru_cache(maxsize=1)\n",
    "def get_summarizer(model_id=SUMM_MODEL_ID):\n",
    "    from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "    import torch\n",
    "    tok = AutoTokenizer.from_pretrained(model_id)\n",
    "    mod = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
    "    dev = _best_device()\n",
    "    try: mod = mod.to(dev)\n",
    "    except Exception: pass\n",
    "    return tok, mod, dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdd4cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LoaderAgent\n",
    "class LoaderAgent:\n",
    "    def __init__(self, jpm_path: Path, hsbc_path: Path):\n",
    "        self.jpm_path = jpm_path; self.hsbc_path = hsbc_path\n",
    "    def load_df(self) -> pd.DataFrame:\n",
    "        frames = []\n",
    "        if self.jpm_path.exists(): j = pd.read_csv(self.jpm_path); j[\"bank\"]=\"JPM\"; frames.append(j)\n",
    "        if self.hsbc_path.exists(): h = pd.read_csv(self.hsbc_path); h[\"bank\"]=\"HSBC\"; frames.append(h)\n",
    "        assert frames, \"No input CSVs found.\"\n",
    "        df = pd.concat(frames, ignore_index=True)\n",
    "        for c in [\"content\",\"speaker_name\",\"role\",\"company\",\"section\",\"source_pdf\"]:\n",
    "            if c in df.columns: df[c] = df[c].astype(str).map(normalize_text)\n",
    "        if \"year\" in df.columns: df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\")\n",
    "        if \"quarter\" in df.columns:\n",
    "            df[\"quarter\"] = df[\"quarter\"].astype(str).str.upper().str.replace(\" \", \"\", regex=False)\n",
    "            df[\"quarter\"] = df[\"quarter\"].str.replace(\"Q0\",\"Q4\", regex=False)\n",
    "        if \"section\" in df.columns:\n",
    "            df = df[df[\"section\"].str.contains(\"QUESTION|Q&A\", case=False, na=False) | (df[\"answer_number\"].notna())]\n",
    "        if \"is_pleasantry\" in df.columns: df = df[df[\"is_pleasantry\"] != True]\n",
    "        return df.dropna(subset=[\"content\"]).reset_index(drop=True)\n",
    "\n",
    "qa_df = LoaderAgent(JPM_PATH, HSBC_PATH).load_df()\n",
    "print(\"Loaded rows:\", len(qa_df)); qa_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e1013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PRA categories & mapper\n",
    "def load_pra_categories(paths):\n",
    "    for p in paths:\n",
    "        if p.exists():\n",
    "            cat = pd.read_csv(p)\n",
    "            cols = {c.lower().strip(): c for c in cat.columns}\n",
    "            cat = cat.rename(columns={cols.get(\"category\", cat.columns[0]): \"category\"})\n",
    "            if \"description\" not in [c.lower() for c in cat.columns]: cat[\"description\"]=\"\"\n",
    "            return cat[[\"category\",\"description\"]].dropna().reset_index(drop=True)\n",
    "    raise FileNotFoundError(\"PRA categories file not found.\")\n",
    "\n",
    "pra_df = load_pra_categories(PRA_PATHS)\n",
    "embedder, EMBED_DEV = get_embedder()\n",
    "from sentence_transformers import util as st_util\n",
    "pra_texts = (pra_df[\"category\"] + \". \" + pra_df[\"description\"].fillna(\"\")).tolist()\n",
    "pra_embs = embedder.encode(pra_texts, convert_to_tensor=True, normalize_embeddings=True)\n",
    "\n",
    "KEYWORDS = {\n",
    "    \"Credit risk\": [\"credit\",\"NPL\",\"non-performing\",\"loan loss\",\"default\",\"provision\",\"counterparty\"],\n",
    "    \"Market risk\": [\"trading\",\"VaR\",\"volatility\",\"rates\",\"FX\",\"equities\",\"derivatives\",\"market risk\"],\n",
    "    \"Liquidity risk\": [\"liquidity\",\"LCR\",\"NSFR\",\"funding\",\"deposits\",\"outflows\",\"liquidity coverage\"],\n",
    "    \"Capital risk\": [\"capital\",\"CET1\",\"RWA\",\"leverage ratio\",\"buffers\",\"Pillar 2\",\"dividends\",\"buybacks\"],\n",
    "    \"Operational risk\": [\"operational\",\"ops\",\"cyber\",\"fraud\",\"conduct\",\"model risk\",\"technology\"],\n",
    "    \"IRRBB\": [\"interest rate risk in the banking book\",\"IRRBB\",\"ALM\",\"duration\",\"asset-liability\"],\n",
    "    \"Climate & ESG\": [\"climate\",\"ESG\",\"sustainability\",\"transition risk\",\"physical risk\",\"emissions\"],\n",
    "    \"Model risk\": [\"model risk\",\"validation\",\"challenge\",\"backtesting\",\"stress test\"],\n",
    "    \"Conduct risk\": [\"conduct\",\"mis-selling\",\"complaints\",\"whistleblowing\",\"FCA\"]\n",
    "}\n",
    "kw2cat = {kw.lower(): cat for cat, kws in KEYWORDS.items() for kw in kws}\n",
    "\n",
    "def map_to_pra_categories(text: str, top_k: int = 2):\n",
    "    text_norm = (text or \"\").lower()\n",
    "    hits = {kw2cat[kw] for kw in kw2cat if f\" {kw} \" in f\" {text_norm} \"}\n",
    "    q_emb = embedder.encode([text or \"\"], convert_to_tensor=True, normalize_embeddings=True)\n",
    "    sims = st_util.cos_sim(q_emb, pra_embs).cpu().numpy().ravel()\n",
    "    nn_idx = sims.argsort()[::-1][:top_k]\n",
    "    nn_cats = [pra_df.iloc[i][\"category\"] for i in nn_idx]\n",
    "    cats = list(dict.fromkeys(list(hits) + nn_cats))\n",
    "    return cats, float(sims[nn_idx[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb4e6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build Q/A pairs\n",
    "def build_pairs(df: pd.DataFrame):\n",
    "    def is_analyst(role, speaker):\n",
    "        role = (role or \"\").lower(); speaker = (speaker or \"\").lower()\n",
    "        return (\"analyst\" in role) or (\"analyst\" in speaker)\n",
    "    def is_banker(role, speaker):\n",
    "        role = (role or \"\").lower(); speaker = (speaker or \"\").lower()\n",
    "        mgmt = [\"chief\",\"ceo\",\"cfo\",\"coo\",\"treasurer\",\"head\",\"president\",\"vice\",\"managing director\"]\n",
    "        return any(m in role for m in mgmt) or (\"jpmorgan\" in speaker) or (\"hsbc\" in speaker) or (\"executive\" in role)\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"is_analyst_row\"] = df.apply(lambda r: is_analyst(r.get(\"role\",\"\"), r.get(\"speaker_name\",\"\")), axis=1)\n",
    "    df[\"is_banker_row\"]  = df.apply(lambda r: is_banker(r.get(\"role\",\"\"), r.get(\"speaker_name\",\"\")), axis=1)\n",
    "\n",
    "    if \"question_number\" not in df.columns:\n",
    "        df[\"question_number\"] = df.groupby([\"bank\",\"year\",\"quarter\"]).cumcount()+1\n",
    "\n",
    "    pairs = []\n",
    "    gcols = [\"bank\",\"year\",\"quarter\",\"question_number\"]\n",
    "    for key, g in df.groupby(gcols, dropna=False):\n",
    "        g = g.sort_index()\n",
    "        qtxt = \" \".join(g.loc[g[\"is_analyst_row\"], \"content\"].tolist())\n",
    "        atxt = \" \".join(g.loc[g[\"is_banker_row\"], \"content\"].tolist())\n",
    "        if not qtxt and not atxt: continue\n",
    "        cats, cat_sim = map_to_pra_categories((qtxt or \"\") + \" \" + (atxt or \"\"))\n",
    "        pairs.append({\n",
    "            \"bank\": key[0], \"year\": key[1], \"quarter\": key[2], \"question_number\": key[3],\n",
    "            \"question_text\": normalize_text(qtxt), \"answer_text\": normalize_text(atxt),\n",
    "            \"pra_categories\": cats, \"pra_sim\": cat_sim\n",
    "        })\n",
    "    pairs_df = pd.DataFrame(pairs)\n",
    "    pairs_df = pairs_df[(pairs_df[\"question_text\"].str.len()>0) | (pairs_df[\"answer_text\"].str.len()>0)].reset_index(drop=True)\n",
    "    print(\"Pairs built:\", len(pairs_df))\n",
    "    return pairs_df\n",
    "\n",
    "pairs_df = build_pairs(qa_df); pairs_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbbb45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evasion scoring\n",
    "def compute_evasion(pairs_df: pd.DataFrame):\n",
    "    from sentence_transformers import util as st_util\n",
    "    emb, _ = get_embedder()\n",
    "    q_embs = emb.encode(pairs_df[\"question_text\"].tolist(), convert_to_tensor=True, normalize_embeddings=True)\n",
    "    a_embs = emb.encode(pairs_df[\"answer_text\"].tolist(), convert_to_tensor=True, normalize_embeddings=True)\n",
    "    cos_sims = st_util.cos_sim(q_embs, a_embs).diagonal().cpu().numpy()\n",
    "\n",
    "    def safe_len(x): return 0 if x is None else len(str(x))\n",
    "\n",
    "    def evasion_score(row, sim):\n",
    "        q = row[\"question_text\"]; a = row[\"answer_text\"]\n",
    "        if not a: return 1.0\n",
    "        hedges = count_hedges(a)\n",
    "        ratio = (safe_len(a)+1)/(safe_len(q)+1)\n",
    "        grade = fk_grade(a)\n",
    "        sim_comp   = max(0.0, min(1.0, (SIMILARITY_LOW - sim) / SIMILARITY_LOW))\n",
    "        hedge_comp = min(1.0, hedges / max(HEDGE_MIN_COUNT, 1))\n",
    "        ratio_comp = min(1.0, max(0.0, (ratio - 1.5) / (VERBOSITY_RATIO_HIGH - 1.5)))\n",
    "        grade_comp = min(1.0, max(0.0, (grade - READABILITY_SIMPLE)/10.0))\n",
    "        return float(round(0.45*sim_comp + 0.25*hedge_comp + 0.20*ratio_comp + 0.10*grade_comp, 4))\n",
    "\n",
    "    out = pairs_df.copy()\n",
    "    out[\"qa_similarity\"] = cos_sims\n",
    "    out[\"hedge_count\"] = out[\"answer_text\"].map(count_hedges)\n",
    "    out[\"ans_to_q_len_ratio\"] = (out[\"answer_text\"].str.len()+1)/(out[\"question_text\"].str.len()+1)\n",
    "    out[\"fk_grade_answer\"] = out[\"answer_text\"].map(fk_grade)\n",
    "    out[\"evasion_score\"] = [evasion_score(r, s) for r, s in zip(out.to_dict(\"records\"), cos_sims)]\n",
    "    out[\"evasive_flag\"] = out[\"evasion_score\"] >= EVASION_SCORE_FLAG\n",
    "    return out\n",
    "\n",
    "pairs_df = compute_evasion(pairs_df)\n",
    "pairs_df.sort_values(\"evasion_score\", ascending=False).head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e0118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Summaries\n",
    "def chunk_text(s: str, max_chars=2500):\n",
    "    s = normalize_text(s or \"\")\n",
    "    if len(s) <= max_chars: return [s]\n",
    "    parts = re.split(r'(?<=[\\.!?])\\s+', s); chunks, buf = [], \"\"\n",
    "    for p in parts:\n",
    "        if len(buf) + len(p) + 1 < max_chars: buf += (\" \" if buf else \"\") + p\n",
    "        else: chunks.append(buf); buf = p\n",
    "    if buf: chunks.append(buf); return chunks\n",
    "\n",
    "def summarise_text(text: str, max_new_tokens=200):\n",
    "    import torch\n",
    "    tok, mod, dev = get_summarizer()\n",
    "    outs = []\n",
    "    for ch in chunk_text(text):\n",
    "        inputs = tok(ch, return_tensors=\"pt\", truncation=True, max_length=1024).to(dev)\n",
    "        with torch.no_grad():\n",
    "            out = mod.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=False)\n",
    "        outs.append(tok.decode(out[0], skip_special_tokens=True).strip())\n",
    "    return \" \".join(outs)\n",
    "\n",
    "def build_summaries(pairs: pd.DataFrame, by_cols=(\"bank\",\"year\",\"quarter\")):\n",
    "    rows = []\n",
    "    for key, g in pairs.groupby(list(by_cols)):\n",
    "        gg = g.explode(\"pra_categories\").dropna(subset=[\"pra_categories\"])\n",
    "        for cat, gcat in gg.groupby(\"pra_categories\"):\n",
    "            text = \" \".join(gcat[\"answer_text\"].tolist())\n",
    "            summ = summarise_text(text, max_new_tokens=200) if text.strip() else \"\"\n",
    "            if len(summ.split()) > SUMMARY_TARGET_WORDS*1.5:\n",
    "                summ = summarise_text(summ, max_new_tokens=120)\n",
    "            rows.append({**{c:k for c,k in zip(by_cols,key)},\n",
    "                         \"pra_category\": cat, \"summary\": summ,\n",
    "                         \"n_pairs\": len(gcat),\n",
    "                         \"median_evasion\": float(np.median(gcat[\"evasion_score\"]))})\n",
    "    return pd.DataFrame(rows).sort_values(list(by_cols)+[\"pra_category\"]).reset_index(drop=True)\n",
    "\n",
    "summ_df = build_summaries(pairs_df, by_cols=(\"bank\",\"year\",\"quarter\"))\n",
    "summ_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774a3350",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save & peek\n",
    "from datetime import datetime\n",
    "OUT_DIR = Path(\"./outputs\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ts = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "pairs_path = OUT_DIR / f\"qa_pairs_with_evasion_{ts}.csv\"\n",
    "summ_path  = OUT_DIR / f\"pra_category_summaries_{ts}.csv\"\n",
    "pairs_df.to_csv(pairs_path, index=False); summ_df.to_csv(summ_path, index=False)\n",
    "print(\"Saved:\", pairs_path, \"|\", summ_path)\n",
    "\n",
    "cols = [\"bank\",\"year\",\"quarter\",\"question_number\",\"pra_categories\",\"qa_similarity\",\n",
    "        \"hedge_count\",\"ans_to_q_len_ratio\",\"fk_grade_answer\",\"evasion_score\",\"evasive_flag\",\n",
    "        \"question_text\",\"answer_text\"]\n",
    "pairs_df.sort_values(\"evasion_score\", ascending=False)[cols].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812f5e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visuals\n",
    "gg = pairs_df.explode(\"pra_categories\").dropna(subset=[\"pra_categories\"])\n",
    "if not gg.empty:\n",
    "    med = gg.groupby(\"pra_categories\")[\"evasion_score\"].median().sort_values(ascending=False)\n",
    "    plt.figure(); med.plot(kind=\"barh\"); plt.title(\"Median Evasion Score by PRA Category\"); plt.tight_layout(); plt.show()\n",
    "\n",
    "qmed = pairs_df.groupby([\"bank\",\"year\",\"quarter\"])[\"evasion_score\"].median().reset_index()\n",
    "if not qmed.empty:\n",
    "    qmed[\"q_label\"] = qmed[\"year\"].astype(str) + \" \" + qmed[\"quarter\"].astype(str)\n",
    "    for bank, g in qmed.groupby(\"bank\"):\n",
    "        plt.figure(); plt.plot(g[\"q_label\"], g[\"evasion_score\"], marker=\"o\")\n",
    "        plt.title(f\"Median Evasion Score by Quarter — {bank}\")\n",
    "        plt.xticks(rotation=45, ha=\"right\"); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f0af32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# (Optional) import timing diagnostics\n",
    "import importlib, time\n",
    "t0=time.perf_counter(); importlib.import_module(\"transformers\"); print(\"transformers import:\", f\"{time.perf_counter()-t0:.2f}s\")\n",
    "t0=time.perf_counter(); importlib.import_module(\"sentence_transformers\"); print(\"sentence_transformers import:\", f\"{time.perf_counter()-t0:.2f}s\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}