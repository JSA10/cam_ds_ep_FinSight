{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b820ac6",
   "metadata": {},
   "source": [
    "# **Summarisation & Evasion Notebook (LB)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79cb78c",
   "metadata": {},
   "source": [
    "# **1. Objective**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538b76a8",
   "metadata": {},
   "source": [
    "- Summarise banker answers into short, PRA relevant insights.\n",
    "- Generate an evasion score to tag summaries.\n",
    "- RAG pipeline to bring in relevant external documents (e.g. PRA risk definitions, regulatory news).\n",
    "- Optional extension: validate flagged risks with external/regulatory news."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94670282",
   "metadata": {},
   "source": [
    "# **2. Set up Workspace**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f5f5884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# Core python\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any \n",
    "import csv\n",
    "\n",
    "# NLP & Summarisation\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import nltk\n",
    "import spacy\n",
    "from llama_cpp import Llama \n",
    "\n",
    "# Evaluation\n",
    "from rouge_score import rouge_scorer\n",
    "import evaluate\n",
    "from bert_score import score as bertscore \n",
    "\n",
    "# Retrieval\n",
    "from sentence_transformers import SentenceTransformer \n",
    "import faiss\n",
    "import chromadb\n",
    "import langchain\n",
    "import llama_index\n",
    "\n",
    "# ML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Visualisations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b91bb8c",
   "metadata": {},
   "source": [
    "# **3. Load the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "743f6bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_number</th>\n",
       "      <th>answer_number</th>\n",
       "      <th>speaker_name</th>\n",
       "      <th>role</th>\n",
       "      <th>company</th>\n",
       "      <th>content</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>source_pdf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ken Usdin</td>\n",
       "      <td>analyst</td>\n",
       "      <td>Autonomous Research</td>\n",
       "      <td>Good morning, Jeremy. Wondering if you could s...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q1</td>\n",
       "      <td>data/raw/jpm/jpm-1q25-earnings-call-transcript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Jeremy Barnum</td>\n",
       "      <td>Chief Financial Officer</td>\n",
       "      <td>JPMorganChase</td>\n",
       "      <td>Sure, Ken. So I mean, at a high level, I would...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q1</td>\n",
       "      <td>data/raw/jpm/jpm-1q25-earnings-call-transcript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ken Usdin</td>\n",
       "      <td>analyst</td>\n",
       "      <td>Autonomous Research</td>\n",
       "      <td>Yeah. And just one question on the NII ex. Mar...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q1</td>\n",
       "      <td>data/raw/jpm/jpm-1q25-earnings-call-transcript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Jeremy Barnum</td>\n",
       "      <td>Chief Financial Officer</td>\n",
       "      <td>JPMorganChase</td>\n",
       "      <td>Yeah, that's a good question, Ken. You're righ...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q1</td>\n",
       "      <td>data/raw/jpm/jpm-1q25-earnings-call-transcript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Jamie Dimon</td>\n",
       "      <td>Chairman &amp; Chief Executive Officer</td>\n",
       "      <td>JPMorganChase</td>\n",
       "      <td>In the curve basically.</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q1</td>\n",
       "      <td>data/raw/jpm/jpm-1q25-earnings-call-transcript...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_number  answer_number   speaker_name  \\\n",
       "0                1            NaN      Ken Usdin   \n",
       "1                1            1.0  Jeremy Barnum   \n",
       "2                2            NaN      Ken Usdin   \n",
       "3                2            1.0  Jeremy Barnum   \n",
       "4                2            2.0    Jamie Dimon   \n",
       "\n",
       "                                 role              company  \\\n",
       "0                             analyst  Autonomous Research   \n",
       "1             Chief Financial Officer        JPMorganChase   \n",
       "2                             analyst  Autonomous Research   \n",
       "3             Chief Financial Officer        JPMorganChase   \n",
       "4  Chairman & Chief Executive Officer        JPMorganChase   \n",
       "\n",
       "                                             content  year quarter  \\\n",
       "0  Good morning, Jeremy. Wondering if you could s...  2025      Q1   \n",
       "1  Sure, Ken. So I mean, at a high level, I would...  2025      Q1   \n",
       "2  Yeah. And just one question on the NII ex. Mar...  2025      Q1   \n",
       "3  Yeah, that's a good question, Ken. You're righ...  2025      Q1   \n",
       "4                            In the curve basically.  2025      Q1   \n",
       "\n",
       "                                          source_pdf  \n",
       "0  data/raw/jpm/jpm-1q25-earnings-call-transcript...  \n",
       "1  data/raw/jpm/jpm-1q25-earnings-call-transcript...  \n",
       "2  data/raw/jpm/jpm-1q25-earnings-call-transcript...  \n",
       "3  data/raw/jpm/jpm-1q25-earnings-call-transcript...  \n",
       "4  data/raw/jpm/jpm-1q25-earnings-call-transcript...  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset.\n",
    "jpm_2025_df = pd.read_csv('../data/processed/jpm/all_jpm_2025.csv')\n",
    "\n",
    "# View the data.\n",
    "jpm_2025_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f75628c",
   "metadata": {},
   "source": [
    "# **4. Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bc49b23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['analyst', 'Chief Financial Officer',\n",
       "       'Chairman & Chief Executive Officer',\n",
       "       'And then some. Theres a lot of value added.', 'Okay'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View speaker roles.\n",
    "jpm_2025_df['role'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0ec70c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_number</th>\n",
       "      <th>answer_number</th>\n",
       "      <th>speaker_name</th>\n",
       "      <th>role</th>\n",
       "      <th>company</th>\n",
       "      <th>content</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>source_pdf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Chief Financial Officer, JPMorganChase</td>\n",
       "      <td>And then some. Theres a lot of value added.</td>\n",
       "      <td>JPMorganChase</td>\n",
       "      <td>Yeah. And obviously, I mean, we're not going t...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q2</td>\n",
       "      <td>data/raw/jpm/jpm-2q25-earnings-call-transcript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>36</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Chief Financial Officer, JPMorganChase</td>\n",
       "      <td>Okay</td>\n",
       "      <td>there you have it.</td>\n",
       "      <td>But it's not like I thought it would do badly,...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q2</td>\n",
       "      <td>data/raw/jpm/jpm-2q25-earnings-call-transcript...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     question_number  answer_number                            speaker_name  \\\n",
       "201               35            5.0  Chief Financial Officer, JPMorganChase   \n",
       "205               36            3.0  Chief Financial Officer, JPMorganChase   \n",
       "\n",
       "                                            role             company  \\\n",
       "201  And then some. Theres a lot of value added.       JPMorganChase   \n",
       "205                                         Okay  there you have it.   \n",
       "\n",
       "                                               content  year quarter  \\\n",
       "201  Yeah. And obviously, I mean, we're not going t...  2025      Q2   \n",
       "205  But it's not like I thought it would do badly,...  2025      Q2   \n",
       "\n",
       "                                            source_pdf  \n",
       "201  data/raw/jpm/jpm-2q25-earnings-call-transcript...  \n",
       "205  data/raw/jpm/jpm-2q25-earnings-call-transcript...  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View rows with invalid roles.\n",
    "valid_roles = 'analyst', 'Chief Financial Officer', 'Chairman & Chief Executive Officer'\n",
    "invalid_roles_df = jpm_2025_df[~jpm_2025_df['role'].isin(valid_roles)]\n",
    "\n",
    "# Number of rows with invalid roles.\n",
    "print('Number of rows:', invalid_roles_df.shape[0])\n",
    "\n",
    "# View the rows.\n",
    "invalid_roles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1e31cc18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['analyst', 'Chief Financial Officer',\n",
       "       'Chairman & Chief Executive Officer',\n",
       "       'And then some. Theres a lot of value added.'], dtype=object)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input the correct role information.\n",
    "jpm_2025_df.at[205, 'role'] = 'Chief Financial Officer'\n",
    "jpm_2025_df.at[209, 'role'] = 'Chief Financial Officer'\n",
    "\n",
    "# Verify the roles have been updated.\n",
    "jpm_2025_df['role'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e44043a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define role mapping.\n",
    "role_map = {\n",
    "    'analyst': 'analyst',\n",
    "    'Chief Financial Officer': 'banker',\n",
    "    'Chairman & Chief Executive Officer': 'banker'\n",
    "}\n",
    "\n",
    "# Apply to dataset.\n",
    "jpm_2025_df['role_normalised'] = jpm_2025_df['role'].map(role_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "755f26e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_number</th>\n",
       "      <th>answer_number</th>\n",
       "      <th>speaker_name</th>\n",
       "      <th>role</th>\n",
       "      <th>company</th>\n",
       "      <th>content</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>source_pdf</th>\n",
       "      <th>role_normalised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ken Usdin</td>\n",
       "      <td>analyst</td>\n",
       "      <td>Autonomous Research</td>\n",
       "      <td>Good morning, Jeremy. Wondering if you could s...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q1</td>\n",
       "      <td>data/raw/jpm/jpm-1q25-earnings-call-transcript...</td>\n",
       "      <td>analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Jeremy Barnum</td>\n",
       "      <td>Chief Financial Officer</td>\n",
       "      <td>JPMorganChase</td>\n",
       "      <td>Sure, Ken. So I mean, at a high level, I would...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q1</td>\n",
       "      <td>data/raw/jpm/jpm-1q25-earnings-call-transcript...</td>\n",
       "      <td>banker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ken Usdin</td>\n",
       "      <td>analyst</td>\n",
       "      <td>Autonomous Research</td>\n",
       "      <td>Yeah. And just one question on the NII ex. Mar...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q1</td>\n",
       "      <td>data/raw/jpm/jpm-1q25-earnings-call-transcript...</td>\n",
       "      <td>analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Jeremy Barnum</td>\n",
       "      <td>Chief Financial Officer</td>\n",
       "      <td>JPMorganChase</td>\n",
       "      <td>Yeah, that's a good question, Ken. You're righ...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q1</td>\n",
       "      <td>data/raw/jpm/jpm-1q25-earnings-call-transcript...</td>\n",
       "      <td>banker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Jamie Dimon</td>\n",
       "      <td>Chairman &amp; Chief Executive Officer</td>\n",
       "      <td>JPMorganChase</td>\n",
       "      <td>In the curve basically.</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q1</td>\n",
       "      <td>data/raw/jpm/jpm-1q25-earnings-call-transcript...</td>\n",
       "      <td>banker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_number  answer_number   speaker_name  \\\n",
       "0                1            NaN      Ken Usdin   \n",
       "1                1            1.0  Jeremy Barnum   \n",
       "2                2            NaN      Ken Usdin   \n",
       "3                2            1.0  Jeremy Barnum   \n",
       "4                2            2.0    Jamie Dimon   \n",
       "\n",
       "                                 role              company  \\\n",
       "0                             analyst  Autonomous Research   \n",
       "1             Chief Financial Officer        JPMorganChase   \n",
       "2                             analyst  Autonomous Research   \n",
       "3             Chief Financial Officer        JPMorganChase   \n",
       "4  Chairman & Chief Executive Officer        JPMorganChase   \n",
       "\n",
       "                                             content  year quarter  \\\n",
       "0  Good morning, Jeremy. Wondering if you could s...  2025      Q1   \n",
       "1  Sure, Ken. So I mean, at a high level, I would...  2025      Q1   \n",
       "2  Yeah. And just one question on the NII ex. Mar...  2025      Q1   \n",
       "3  Yeah, that's a good question, Ken. You're righ...  2025      Q1   \n",
       "4                            In the curve basically.  2025      Q1   \n",
       "\n",
       "                                          source_pdf role_normalised  \n",
       "0  data/raw/jpm/jpm-1q25-earnings-call-transcript...         analyst  \n",
       "1  data/raw/jpm/jpm-1q25-earnings-call-transcript...          banker  \n",
       "2  data/raw/jpm/jpm-1q25-earnings-call-transcript...         analyst  \n",
       "3  data/raw/jpm/jpm-1q25-earnings-call-transcript...          banker  \n",
       "4  data/raw/jpm/jpm-1q25-earnings-call-transcript...          banker  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the dataset.\n",
    "jpm_2025_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02cf565",
   "metadata": {},
   "source": [
    "# **5. Summarisation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6401764b",
   "metadata": {},
   "source": [
    "## **5.1 Baseline**\n",
    "- Model = BART (not instruction tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "671f20e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, Ken. So I mean, at a high level, I would say that obviously, some of the salient news flow is quite recent. So, we've done some soundings and some checking both on the consumer side and on the w\n"
     ]
    }
   ],
   "source": [
    "# Filter data to banker answers only.\n",
    "banker_answers = jpm_2025_df[jpm_2025_df['role_normalised'] == 'banker']['content'].tolist()\n",
    "print(banker_answers[0][:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "54559054",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Sure, Ken. So I mean, at a high level, I would say that obviously, some of the salient news flow is quite recent. So, we've done some soundings and some checking both on the consumer side and on the wholesale side. I think on the consumer side, the thing to check is the spending data. And to be honest, the main thing that we see there, what would appear to be a certain amount of frontloading of sp\n",
      "Summary: The main thing that we see there, what would appear to be a certain amount of frontloading of spending ahead of people expecting price increases from tariffs. So ironically, that's actually somewhat supportive, all else equal. In terms of our corporate clients, obviously, they've been reacting to the changes in tariff policy.\n"
     ]
    }
   ],
   "source": [
    "# Summarisation baseline (BART)\n",
    "summariser = pipeline('summarization', model='facebook/bart-large-cnn')\n",
    "\n",
    "sample_text = banker_answers[0]\n",
    "summary = summariser(sample_text, max_length=80, min_length=30, do_sample=False)\n",
    "print('Original:', sample_text[:400])\n",
    "print('Summary:', summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "024bd2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Sure, Ken. So I mean, at a high level, I would say that obviously, some of the salient news flow is quite recent. So, we've done some soundings and some checking both on the consumer side and on the wholesale side. I think on the consumer side, the thing to check is the spending data. And to be honest, the main thing that we see there, what would appear to be a certain amount of frontloading of sp\n",
      "Summary: Corporates are taking a wait-and-see approach to tariff policy. Some sectors are going to be much more exposed than others. Small business and smaller corporates are probably a little more challenged.\n"
     ]
    }
   ],
   "source": [
    "# Prompt conditioning to make PRA relevant.\n",
    "prompt = \"Summarise this answer, focusing on risk, capital and evasion of detail: \" + sample_text\n",
    "summary = summariser(prompt, max_length=80, min_length=30)\n",
    "print('Original:', sample_text[:400])\n",
    "print('Summary:', summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6813acc2",
   "metadata": {},
   "source": [
    "## **5.2 RAG**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739cba37",
   "metadata": {},
   "source": [
    "### **Action point:** test different model to try prompting with PRA context**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8e1b7a",
   "metadata": {},
   "source": [
    "Retrieve PRA risk categories to give greater PRA focus to summaries (local RAG loop).\n",
    "- measure cosine similarity between transcript chunks and PRA risk categories (vectors)\n",
    "- retrieve the top 2-3 most relevant risk categories \n",
    "- prepend them to the summarisation prompt to make summaries PRA-aligned instead of just summarised answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81f2bd1",
   "metadata": {},
   "source": [
    "- Attempting to use BART resulted in prompt echoing.\n",
    "- New attempt using Mistral-7B-Instruct.\n",
    "- Using sentence-BERT vs TF-IDF for vectorisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6b05ed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove whitespace in text.\n",
    "def clean_text(text: str):\n",
    "    return re.sub(r'\\s+', ' ', text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c4f9ee77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split the transcript into smaller chunks.\n",
    "def chunk_text(text: str, max_chars: int = 6000):\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip()) # split into sentences \n",
    "    chunks, current_chunk, current_len = [], [], 0 # list of chunks, sentences collecting for current chunk, character count for current chunk\n",
    "\n",
    "    for s in sentences:\n",
    "        if current_len + len(s) + 1 <= max_chars: # if the characters of current chunk + new sentence is below the limit:\n",
    "            current_chunk.append(s) # add sentence to current chunk \n",
    "            current_len += len(s) + 1 # update running character count \n",
    "        \n",
    "        else: # if the characters is above the limit:\n",
    "            chunks.append(' '.join(current_chunk)) # add the current chunk to the final chunk list\n",
    "            current_chunk, current_len = [s], len(s) # start a new chunk containing the sentence and update current len\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(' '.join(current_chunk)) # add any sentences in current chunk after loop ends \n",
    "\n",
    "    return chunks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "73c5478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load PRA risk categories.\n",
    "# pra_risk_df = pd.read_csv('../data/RAG-resources/PRA_risk_categories.csv')\n",
    "# pra_risk_df['doc'] = pra_risk_df['category'] + ': ' + pra_risk_df['definition']\n",
    "\n",
    "# # View dataframe.\n",
    "# pra_risk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4fe2b709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pra_categories(path: Path):\n",
    "    with open(path, newline='', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        return [\n",
    "            (row.get('category', '').strip(), [row.get('definition', '').strip()])\n",
    "            for row in reader if row.get('category')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "db60595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Sentence-BERT embedding index for PRA categories.\n",
    "def build_embedding_index(pra_categories):\n",
    "    embedder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    pra_risk_embeddings = embedder.encode(pra_risk_df['doc'], batch_size=32, normalize_embeddings=True)\n",
    "\n",
    "    return embedder, np.asarray(pra_risk_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9f02cbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the relevant PRA categories to the transcript chunks.\n",
    "def find_rel_categories(chunk, pra_categories, embedder, pra_risk_embeddings, top_k=2):\n",
    "    query_vec = embedder.encode([chunk], normalize_embeddings=True) # turns chunk into embedding\n",
    "    sims = cosine_similarity(query_vec, pra_risk_embeddings).ravel() # compares the chunk to each category doc \n",
    "    top_indices = np.argsort(-sims)[:top_k] # sorts scores descending and selected top k cateogories \n",
    "\n",
    "    return [pra_categories[i] for i in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a7d85bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json_block(model_output: str) -> str:\n",
    "    \"\"\"If the model adds extra text, grab the first JSON object.\"\"\"\n",
    "    a = model_output.find(\"{\")\n",
    "    b = model_output.rfind(\"}\")\n",
    "    return model_output[a:b+1] if a != -1 and b != -1 and b > a else model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "77206958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to summarise the chunk.\n",
    "def summarise_chunk(model, chunk, relevant_categories, max_evidence=5):\n",
    "    lines = []\n",
    "    for name, definition in relevant_categories:\n",
    "        lines.append(f'- {name}:')\n",
    "        for d in definition:\n",
    "            lines.append(f'- {d}')\n",
    "    notes_block = '\\n'.join(lines)\n",
    "\n",
    "    system_prompt = (\n",
    "        'You are a Data Scientist producing PRA-aligned summaries.'\n",
    "        'Use only the transcript text as evidence. Map content to the PRA categories provided.'\n",
    "    )\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "TRANSCRIPT:\n",
    "{chunk}\n",
    "\n",
    "PRA NOTES:\n",
    "{notes_block}\n",
    "\n",
    "TASK:\n",
    "Return STRICT JSON with keys:\n",
    "- evidence: list of up to {max_evidence} bullet strings\n",
    "- pra categories: list of objects {{ 'name': '...', 'why': '...' }}\n",
    "- summary: 4-6 sentences, neutral tone\n",
    "\n",
    "RULES:\n",
    "- Do not invent facts. If evidence is lacking, use a single bullet 'Insufficient evidence'.\n",
    "- Only choose categories supported by the evidence.\n",
    "- No markdown. Output JSON only.\n",
    "\"\"\"\n",
    "    \n",
    "    response = model.create_chat_completion(\n",
    "        messages=[\n",
    "            {'role': 'system', 'content': system_prompt},\n",
    "            {'role': 'user', 'content': clean_text(user_prompt)}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        max_tokens=512,\n",
    "        repeat_penalty=1.1\n",
    "    ) \n",
    "\n",
    "    text = response['choices'][0]['message']['content'].strip()\n",
    "    try:\n",
    "        return json.loads(exytact_json_block(text))\n",
    "    except Exception:\n",
    "        return {'raw': text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e398a6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables.\n",
    "MODEL_PATH = '/Users/laurenbrixey/Documents/Data Science Career Accelerator/Project Submissions/Course 3/topic_project_4.1/mistral-7b-instruct-v0.1.Q4_K_M.gguf'\n",
    "PRA_NOTES_PATH = '../data/RAG-resources/PRA_risk_categories.csv'\n",
    "TRANSCRIPT_PATH = '../data/processed/jpm/all_jpm_2025.csv'\n",
    "OUTPUT_PATH = \"jpm_mistral_pra_summary.json\"\n",
    "TOP_K = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c7cff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_load_from_file_impl: using device Metal (Apple M3) - 935 MiB free\n",
      "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from /Users/laurenbrixey/Documents/Data Science Career Accelerator/Project Submissions/Course 3/topic_project_4.1/mistral-7b-instruct-v0.1.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.1\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "print_info: file format = GGUF V2\n",
      "print_info: file type   = Q4_K - Medium\n",
      "print_info: file size   = 4.07 GiB (4.83 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 1\n",
      "load: control token:      2 '</s>' is not marked as EOG\n",
      "load: control token:      1 '<s>' is not marked as EOG\n",
      "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "load: printing all EOG tokens:\n",
      "load:   - 2 ('</s>')\n",
      "load: special tokens cache size = 3\n",
      "load: token to piece cache size = 0.1637 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 32768\n",
      "print_info: n_embd           = 4096\n",
      "print_info: n_layer          = 32\n",
      "print_info: n_head           = 32\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: is_swa_any       = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 4\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 14336\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 10000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 32768\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: model type       = 7B\n",
      "print_info: model params     = 7.24 B\n",
      "print_info: general.name     = mistralai_mistral-7b-instruct-v0.1\n",
      "print_info: vocab type       = SPM\n",
      "print_info: n_vocab          = 32000\n",
      "print_info: n_merges         = 0\n",
      "print_info: BOS token        = 1 '<s>'\n",
      "print_info: EOS token        = 2 '</s>'\n",
      "print_info: UNK token        = 0 '<unk>'\n",
      "print_info: LF token         = 13 '<0x0A>'\n",
      "print_info: EOG token        = 2 '</s>'\n",
      "print_info: max token length = 48\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  18 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  19 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  20 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  21 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  22 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  23 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  24 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  25 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  26 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  27 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  28 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  29 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  30 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  31 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  32 assigned to device CPU, is_swa = 0\n",
      "load_tensors: tensor 'token_embd.weight' (q4_K) (and 281 others) cannot be used with preferred buffer type CPU_REPACK, using CPU instead\n",
      "ggml_backend_metal_log_allocated_size: allocated buffer, size =   132.52 MiB, (10119.36 / 10922.67)\n",
      "load_tensors: offloading 1 repeating layers to GPU\n",
      "load_tensors: offloaded 1/33 layers to GPU\n",
      "load_tensors: Metal_Mapped model buffer size =   132.51 MiB\n",
      "load_tensors:   CPU_Mapped model buffer size =  4165.37 MiB\n",
      "...............................................................................................\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_seq_max     = 1\n",
      "llama_context: n_ctx         = 8192\n",
      "llama_context: n_ctx_per_seq = 8192\n",
      "llama_context: n_batch       = 512\n",
      "llama_context: n_ubatch      = 512\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = 0\n",
      "llama_context: kv_unified    = false\n",
      "llama_context: freq_base     = 10000.0\n",
      "llama_context: freq_scale    = 1\n",
      "llama_context: n_ctx_per_seq (8192) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M3\n",
      "ggml_metal_init: picking default device: Apple M3\n",
      "ggml_metal_init: GPU name:   Apple M3\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple9  (1009)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction   = true\n",
      "ggml_metal_init: simdgroup matrix mul. = true\n",
      "ggml_metal_init: has residency sets    = true\n",
      "ggml_metal_init: has bfloat            = true\n",
      "ggml_metal_init: use bfloat            = false\n",
      "ggml_metal_init: hasUnifiedMemory      = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 11453.25 MB\n",
      "ggml_metal_init: loaded kernel_add                                    0x399947f50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_2                             0x3999482b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_3                             0x399948610 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_4                             0x399948b00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_5                             0x149d756e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_6                             0x46d441880 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_7                             0x399948ea0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_8                             0x46d42c120 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4                             0x3eb6cc330 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_2                      0x3eb6ccff0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_3                      0x14ff2bec0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_4                      0x39d0e6d90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_5                      0x399949520 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_6                      0x3999497e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_7                      0x399949aa0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_8                      0x399949df0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub                                    0x39994a1c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub_row_c4                             0x39994a590 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul                                    0x39994a960 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_row_c4                             0x39994ad30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div                                    0x3eb6913b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div_row_c4                             0x39d0aa5f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_id                                 0x14ff2c180 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f32                             0x14ff2c440 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f16                             0x14ff2c700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i32                             0x14ff2c9c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i16                             0x14ff2ccf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale                                  0x3eb667680 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale_4                                0x39d07e440 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_clamp                                  0x39994b090 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_tanh                                   0x46ffc3500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_relu                                   0x39994b7b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sigmoid                                0x14cb56b70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu                                   0x14cb4cf60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_4                                 0x14cb80c60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_erf                               0x46ff78260 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_erf_4                             0x46ff920b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick                             0x325d320c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick_4                           0x39994b3a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu                                   0x14ff2d0c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu_4                                 0x14cbcf220 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_elu                                    0x14ff2d490 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_abs                                    0x14cb0f5f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sgn                                    0x325d32380 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_step                                   0x325d16b40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_hardswish                              0x14ff2d9d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_hardsigmoid                            0x325d16e40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_exp                                    0x14ff2dd90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16                           0x325d40b10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16_4                         0x325d089d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32                           0x14ff2e0e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32_4                         0x39994bea0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf                          0x14ff2e620 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf_8                        0x325d5e2a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f32                           0x325d4fce0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f16                           0x325d18750 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_0                          0x14ff2e8e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_1                          0x325d37530 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_0                          0x39994c3a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_1                          0x39bc29c80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q8_0                          0x14cbe1ef0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_mxfp4                         0x14cb10fb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q2_K                          0x39994c7b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q3_K                          0x14cb32f10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_K                          0x39bc29f40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_K                          0x32a604a00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q6_K                          0x39994ccb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xxs                       0x39994cf70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xs                        0x14cb09b00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_xxs                       0x46f826a70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_s                         0x39994d230 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_s                         0x14cba65c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_s                         0x39994d5b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_m                         0x39d190af0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_nl                        0x14cbf35b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_xs                        0x14cb26a10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_i32                           0x39d190db0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_f32                           0x39994d870 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_f16                           0x39d1062a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_set_rows_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_set_rows_q8_0                          0x39d106560 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_q4_0                          0x39994dc10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_q4_1                          0x14cba0bb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_q5_0                          0x39994e0a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_q5_1                          0x14ff2eca0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_iq4_nl                        0x14ff2f060 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rms_norm                               0x14ff2f400 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rms_norm_mul                           0x39d106820 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rms_norm_mul_add                       0x39d1dae20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_l2_norm                                0x39d1db0e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_group_norm                             0x39d146370 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_norm                                   0x14ff2f7a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_conv_f32                           0x14ff2fb70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_scan_f32                           0x39d128060 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_scan_f32_group                     0x14cb2a5c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rwkv_wkv6_f32                          0x14cbf6680 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rwkv_wkv7_f32                          0x14cbfd330 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f32_f32                         0x14ff1c320 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f32_f32_c4                      0x39d1923f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_c4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32                         0x14cb91650 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_c4                      0x39d1926b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_1row                    0x39d1d4130 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_l4                      0x39d1ebee0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f16                         0x39d1ec1a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_0_f32                        0x14ff1c860 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_1_f32                        0x14ff1cb20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_0_f32                        0x39994e3b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_1_f32                        0x14ff1ce80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q8_0_f32                        0x14ff23cc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_mxfp4_f32                       0x14cb88a90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_2                0x39d1ec460 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_3                0x39d1ec7c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_4                0x14cbdfcf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_5                0x14cb34590 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_2               0x14cb46ab0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_3               0x39d123210 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_4               0x39d123520 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_5               0x14ff24090 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_2               0x39994e700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_3               0x39d16c4f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_4               0x39994eae0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_5               0x39994ef70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_2               0x14ff244f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_3               0x14ff248c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_4               0x14cb6a4b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_5               0x14cb99340 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_2               0x14cbd7c20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_3               0x14cb639a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_4               0x14cb6bb50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_5               0x14cbca300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_2               0x14cb1ea70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_3               0x14cbfaef0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_4               0x14cbac930 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_5               0x14cb4f2b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_mxfp4_f32_r1_2              0x14ff24c90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_mxfp4_f32_r1_3              0x14ff25060 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_mxfp4_f32_r1_4              0x14ff25430 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_mxfp4_f32_r1_5              0x14cbbcd30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_2               0x14cb224e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_3               0x14ff25890 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_4               0x14ff25bf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_5               0x14cb106b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_2               0x14cb38150 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_3               0x14cb506a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_4               0x14cb7fb50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_5               0x14cbe6970 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_2               0x14cbcec00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_3               0x14cbc2a00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_4               0x14cb62d40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_5               0x14cbaaaa0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_2             0x14cbb0fb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_3             0x39994f2d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_4             0x14ff25f90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_5             0x14ff26360 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q2_K_f32                        0x14cb0d8c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q3_K_f32                        0x14cbb3cd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_K_f32                        0x39d18db90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_K_f32                        0x39d18de50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q6_K_f32                        0x14ff267c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xxs_f32                     0x39d11fea0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xs_f32                      0x14cb81480 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_xxs_f32                     0x39d10c810 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_s_f32                       0x39d1d0780 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_s_f32                       0x39d10ef30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_s_f32                       0x14cb1f2b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_m_f32                       0x39d10f1f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_nl_f32                      0x39d1befe0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_xs_f32                      0x39d1bf2a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f32_f32                      0x14cb8b510 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f16_f32                      0x39d13da60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_0_f32                     0x39d18f970 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_1_f32                     0x39d18fc30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_0_f32                     0x39d1f2420 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_1_f32                     0x39d1f26e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q8_0_f32                     0x39d1f29a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_mxfp4_f32                    0x14cbff740 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q2_K_f32                     0x39d1486c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q3_K_f32                     0x14ff26b20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_K_f32                     0x39d148980 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_K_f32                     0x14ccc1280 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q6_K_f32                     0x39d1a3a30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xxs_f32                  0x39994f980 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xs_f32                   0x39994fc40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_xxs_f32                  0x39d160830 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_s_f32                    0x14ff27010 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_s_f32                    0x14ff272d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_s_f32                    0x14cca8240 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_m_f32                    0x39d160af0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_nl_f32                   0x39d1d5520 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_xs_f32                   0x14ff276a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f32_f32                         0x14ff27a70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f16_f32                         0x14cc25c10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_0_f32                        0x39d1d58c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_1_f32                        0x39d105ad0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_0_f32                        0x39d199ed0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_1_f32                        0x39d19a190 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q8_0_f32                        0x14cc62e20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_mxfp4_f32                       0x39d1c8750 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_mxfp4_f32                       0x14cca9bb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q2_K_f32                        0x14ccdbaf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q3_K_f32                        0x14ccd74b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_K_f32                        0x14cc31450 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_K_f32                        0x39d1c8a10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q6_K_f32                        0x14cc5a860 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_xxs_f32                     0x14cc9aa70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_xs_f32                      0x39d1c4c30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq3_xxs_f32                     0x14ff27ed0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq3_s_f32                       0x39d1fdc80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_s_f32                       0x14ff28270 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq1_s_f32                       0x14ccb62f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq1_m_f32                       0x39d1fdf40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq4_nl_f32                      0x39d1fe250 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq4_xs_f32                      0x39d1c6a30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_map0_f16                     0x14cc414f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_map1_f32                     0x39d1c6cf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_f32_f16                      0x39d1c6fb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_f16_f16                      0x14cc0bbc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f16                (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_0_f16                     0x14ff285d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_1_f16                     0x14ff289e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_0_f16                     0x14ff28f20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_1_f16                     0x39994ff00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q8_0_f16                     0x14ff291e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_mxfp4_f16                    0x399950490 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q2_K_f16                     0x399950750 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q3_K_f16                     0x399950aa0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_K_f16                     0x14cc61980 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_K_f16                     0x39d1ffa30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q6_K_f16                     0x14cc669b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_xxs_f16                  0x39d11a3b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_xs_f16                   0x39d182b30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq3_xxs_f16                  0x39d182df0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq3_s_f16                    0x399950dd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_s_f16                    0x3999511a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq1_s_f16                    0x399951500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq1_m_f16                    0x39d174a30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq4_nl_f16                   0x39d174cf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq4_xs_f16                   0x14ff294a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_norm_f32                          0x3999519e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_norm_f16                          0x39d1f6e70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_multi_f32                         0x39d1c5280 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_multi_f16                         0x14ff29940 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_vision_f32                        0x39d1c5540 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_vision_f16                        0x39d1c5800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f32                          0x14cc39480 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f16                          0x399951da0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f16                             0x14cce0470 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f32                             0x14cc52e70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f16                         0x39d185c90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f32                         0x14cc23d20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_conv_transpose_1d_f32_f32              0x399952390 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_conv_transpose_1d_f16_f32              0x14cc23fe0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_upscale_f32                            0x39d1b0310 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pad_f32                                0x399952840 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pad_reflect_1d_f32                     0x399952b00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_timestep_embedding_f32                 0x14cc50cf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_arange_f32                             0x39d17a960 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_asc                    0x399952f10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_desc                   0x14ff29c00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_leaky_relu_f32                         0x3999531d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h64                 0x14ff29ec0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h80                 0x399953490 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h96                 0x14ccf7420 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h112                0x14ff2a220 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h128                0x3999537a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h192                0x399953ae0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_hk192_hv128         0x14ff3aa10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h256                0x14ff3ae10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_hk576_hv512         0x14cc60b30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk576_hv512   (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h64                0x14ff3b210 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h80                0x39d17ac20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h96                0x39d17af50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h112               0x39d17b320 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h128               0x14ccb4b30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h192               0x39d12a990 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_hk192_hv128        0x39d1dcea0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h256               0x39d123d10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_hk576_hv512        0x399954200 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h64                0x3999544c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h80                0x399954780 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h96                0x399954a40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h112               0x14ff3b5e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h128               0x14ff3b9b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h192               0x14ff3bd80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_hk192_hv128        0x14ff3c040 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h256               0x14ff3c4a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_hk576_hv512        0x14ff3c840 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h64                0x14ff3cc10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h80                0x14cca3a40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h96                0x14ccf94c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h112               0x14cce1be0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h128               0x14ff3d070 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h192               0x14ff3d410 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_hk192_hv128        0x14ccf5780 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h256               0x39d19f7b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_hk576_hv512        0x14ccfa2a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h64                0x14ccbbed0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h80                0x39d1706c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h96                0x39d170980 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h112               0x39d177910 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h128               0x39d14ae90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h192               0x14ff3d770 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_hk192_hv128        0x39d14b150 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h256               0x39d14b520 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_hk576_hv512        0x39d114550 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h64                0x39d15b240 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h80                0x39d181720 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h96                0x3999550c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h112               0x39d1819e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h128               0x39d1c09d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h192               0x39d1528c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_hk192_hv128        0x14ccbc190 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h256               0x39d152b80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_hk576_hv512        0x39d167990 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h64             0x39d1251d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h64       (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h64            0x14ff3db70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h64            0x399955520 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h64            0x14ff3df40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h64            0x14ff3e310 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h64            0x399955910 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h96             0x39d1f9800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h96       (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h96            0x39d1f9ac0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h96            0x39d1f9dc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h96            0x14cc10d00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h96            0x399955de0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h96            0x3999560a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h128            0x399956360 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h128           0x39d1af660 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h128           0x14cce8310 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h128           0x39d1b0bd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h128           0x39d1b0e90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h128           0x14ff3e6e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h192            0x39d109640 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h192      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h192           0x14cce85d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h192           0x39d1eb240 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h192           0x14ff3eab0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h192           0x14ff3ee80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h192           0x14cce8890 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_hk192_hv128      0x39d1eb500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk192_hv128 (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_hk192_hv128      0x14cce8b50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_hk192_hv128      0x14cce8e10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_hk192_hv128      0x14cce90d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_hk192_hv128      0x14cce9390 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_hk192_hv128      0x14cce9650 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h256            0x14ff3f2e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h256           0x14ff3f640 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h256           0x14ff3f9e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h256           0x14ff3fdb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h256           0x39d1c2ed0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h256           0x39d141ba0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_hk576_hv512      0x39d141e60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk576_hv512 (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_hk576_hv512      0x14cce9910 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_hk576_hv512      0x14cce9bd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_hk576_hv512      0x14cce9e90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_hk576_hv512      0x14ccea150 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_hk576_hv512      0x14ccea410 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_f32                                0x14ccea6d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_i32                                0x14ccea990 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f32                            0x14ff40210 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f16                            0x14ff40570 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f32                            0x14cceac50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f16                            0x39d1cec50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q8_0                           0x14cceaf10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_0                           0x14cceb1d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_1                           0x14cceb490 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_0                           0x39d121530 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_1                           0x39d1217f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_iq4_nl                         0x39d115d70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_0_f32                           0x14cceb750 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_0_f16                           0x14cceba10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_1_f32                           0x39d116030 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_1_f16                           0x14ff408d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_0_f32                           0x14ccebcd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_0_f16                           0x39d116c20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_1_f32                           0x39d116ee0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_1_f16                           0x39d1171e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q8_0_f32                           0x39d193520 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q8_0_f16                           0x14ff40d30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_concat                                 0x14ff410d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqr                                    0x14ccebf90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqrt                                   0x14ccec250 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sin                                    0x14ccec510 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cos                                    0x14ccec7d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_neg                                    0x399956890 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_reglu                                  0x14cceca90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_geglu                                  0x399956cf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_swiglu                                 0x14ccecd50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_swiglu_oai                             0x14cced010 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_geglu_erf                              0x14ff41430 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_geglu_quick                            0x14cced2d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sum_rows                               0x14cced590 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mean                                   0x14cced850 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argmax                                 0x14ccedb10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_avg_f32                        0x14cceddd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_max_f32                        0x39d1938e0 | th_max = 1024 | th_width =   32\n",
      "set_abort_callback: call\n",
      "llama_context:        CPU  output buffer size =     0.12 MiB\n",
      "create_memory: n_ctx = 8192 (padded)\n",
      "llama_kv_cache_unified: layer   0: dev = CPU\n",
      "llama_kv_cache_unified: layer   1: dev = CPU\n",
      "llama_kv_cache_unified: layer   2: dev = CPU\n",
      "llama_kv_cache_unified: layer   3: dev = CPU\n",
      "llama_kv_cache_unified: layer   4: dev = CPU\n",
      "llama_kv_cache_unified: layer   5: dev = CPU\n",
      "llama_kv_cache_unified: layer   6: dev = CPU\n",
      "llama_kv_cache_unified: layer   7: dev = CPU\n",
      "llama_kv_cache_unified: layer   8: dev = CPU\n",
      "llama_kv_cache_unified: layer   9: dev = CPU\n",
      "llama_kv_cache_unified: layer  10: dev = CPU\n",
      "llama_kv_cache_unified: layer  11: dev = CPU\n",
      "llama_kv_cache_unified: layer  12: dev = CPU\n",
      "llama_kv_cache_unified: layer  13: dev = CPU\n",
      "llama_kv_cache_unified: layer  14: dev = CPU\n",
      "llama_kv_cache_unified: layer  15: dev = CPU\n",
      "llama_kv_cache_unified: layer  16: dev = CPU\n",
      "llama_kv_cache_unified: layer  17: dev = CPU\n",
      "llama_kv_cache_unified: layer  18: dev = CPU\n",
      "llama_kv_cache_unified: layer  19: dev = CPU\n",
      "llama_kv_cache_unified: layer  20: dev = CPU\n",
      "llama_kv_cache_unified: layer  21: dev = CPU\n",
      "llama_kv_cache_unified: layer  22: dev = CPU\n",
      "llama_kv_cache_unified: layer  23: dev = CPU\n",
      "llama_kv_cache_unified: layer  24: dev = CPU\n",
      "llama_kv_cache_unified: layer  25: dev = CPU\n",
      "llama_kv_cache_unified: layer  26: dev = CPU\n",
      "llama_kv_cache_unified: layer  27: dev = CPU\n",
      "llama_kv_cache_unified: layer  28: dev = CPU\n",
      "llama_kv_cache_unified: layer  29: dev = CPU\n",
      "llama_kv_cache_unified: layer  30: dev = CPU\n",
      "llama_kv_cache_unified: layer  31: dev = Metal\n",
      "llama_kv_cache_unified:      Metal KV buffer size =    32.00 MiB\n",
      "llama_kv_cache_unified:        CPU KV buffer size =   992.00 MiB\n",
      "llama_kv_cache_unified: size = 1024.00 MiB (  8192 cells,  32 layers,  1/1 seqs), K (f16):  512.00 MiB, V (f16):  512.00 MiB\n",
      "llama_context: enumerating backends\n",
      "llama_context: backend_ptrs.size() = 3\n",
      "llama_context: max_nodes = 2328\n",
      "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "llama_context:      Metal compute buffer size =   564.01 MiB\n",
      "llama_context:        CPU compute buffer size =   564.01 MiB\n",
      "llama_context: graph nodes  = 1126\n",
      "llama_context: graph splits = 437 (with bs=512), 3 (with bs=1)\n",
      "Metal : EMBED_LIBRARY = 1 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | MATMUL_INT8 = 1 | DOTPROD = 1 | ACCELERATE = 1 | REPACK = 1 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '8', 'llama.context_length': '32768', 'llama.attention.head_count': '32', 'llama.rope.freq_base': '10000.000000', 'llama.rope.dimension_count': '128', 'general.file_type': '15', 'llama.feed_forward_length': '14336', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.name': 'mistralai_mistral-7b-instruct-v0.1'}\n"
     ]
    }
   ],
   "source": [
    "# Runner.\n",
    "pra_categories = load_pra_categories(Path(PRA_NOTES_PATH)) # load pra category file\n",
    "embedder, category_embeddings = build_embedding_index(pra_categories) # embed pra categories\n",
    "\n",
    "transcript_text = Path(TRANSCRIPT_PATH).read_text() # load the transcript text\n",
    "transcript_chunks = chunk_text(transcript_text) # split the transcript into smaller chunks\n",
    "\n",
    "model = Llama(model_path=str(Path(MODEL_PATH).expanduser()), n_ctx=8192, n_gpu_layers=1, chat_format='mistral-instruct')\n",
    "\n",
    "results = []\n",
    "for i, chunk in enumerate(transcript_chunks, 1):\n",
    "    top_categories = find_rel_categories(chunk, pra_categories, embedder, category_embeddings)\n",
    "    summary_result = summarise_chunk(model, chunk, top_categories)\n",
    "    results.append({'chunk': i, 'result': summary_result})\n",
    "\n",
    "combined_summary = ' '.join(r['result'].get('summary', '') for r in results)\n",
    "final_output = {'chunks': results, 'combined_summary': combined_summary.strip()}\n",
    "\n",
    "Path(OUTPUT_PATH).write_text(json.dumps(final_output, indent=2, ensure_ascii=False))\n",
    "print(json.dumps(final_output, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2774dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load PRA categories and descriptions from csv file.\n",
    "# def load_pra_categories(path: Path):\n",
    "#     with open(path, newline='', ecoding='utf-8') as f:\n",
    "#         reader = csv.DictReader(f)\n",
    "        \n",
    "#         return [\n",
    "#             (row.get('category', '').strip(), [row.get('definition', '').strip()])\n",
    "#             for row in reader if row.get('category')\n",
    "#         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e97aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create TF-IDF index for PRA categories.\n",
    "# def build_tfidf_index(pra_categories):\n",
    "#     docs = [f'{name} {' '.join(definition)}'.strip() for name, definition in pra_categories] # create a single document \n",
    "#     vectorizer = TfidfVectorizer(stop_words='english') # create a tf-idf vectoriser, removes stopwords \n",
    "#     tfidf_matrix = vectorizer.fit_transform(docs) # creates tf-idf matrices from docs \n",
    "#     return vectorizer, tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1be35c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# # Create embeddings of each doc (defintion + risk).\n",
    "# embed = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# pra_risk_embeddings = embed.encode(pra_risk_df['doc'].tolist(), normalize_embeddings=True).astype('float32')\n",
    "# index = faiss.IndexFlatIP(pra_risk_embeddings.shape[1])\n",
    "# index.add(pra_risk_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9857e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrieve the most relevant risk categories + defintions \n",
    "# def retrieve_pra_context(query_text: str, k: int = 3) -> pd.DataFrame:\n",
    "#     q = embed.encode([query_text], normalize_embeddings=True).astype('float32')\n",
    "#     scores, idxs = index.search(q, k)\n",
    "#     out = pra_risk_df.iloc[idxs[0]].copy()\n",
    "#     out['score'] = scores[0]\n",
    "#     return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604d861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert retrieved risk doc into a context block to prompt the model.\n",
    "# def make_context_block(retrieved_df: pd.DataFrame) -> str:\n",
    "#     lines = [f\"- {r['category']}: {r['definition']}\" for _, r in retrieved_df.iterrows()]\n",
    "#     return '\\n'.join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7116db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert retrieved risk doc into a pra keyword to prompt the model.\n",
    "# def pra_keywords(retrieved_df: pd.DataFrame, top_n: int = 3) -> str:\n",
    "#     return ', '.join(retrieved_df['category'].head(top_n).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e0e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Chunking the banker's answers to avoid truncation.\n",
    "# def split_into_chunks(text: str, max_chunk_size: int = 1800):\n",
    "\n",
    "#     # split text into sentences\n",
    "#     sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "\n",
    "#     # list to store chunks\n",
    "#     chunks = []\n",
    "#     current_chunk = ''\n",
    "#     for s in sentences:\n",
    "#         if len(current_chunk) + len(sentence) + 1 <= max_chunk_size:\n",
    "#             current_chunk = f'{current_chunk} {sentence}'.strip()\n",
    "#         else:\n",
    "#             if current_chunk:\n",
    "#                 chunks.append(current_chunk)\n",
    "#             current_chunk = sentence \n",
    "    \n",
    "#     if current_chunk: \n",
    "#         chunks.append(current_chunk)\n",
    "\n",
    "#     return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c181c9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "# # Function to create a PRA risk category focused summary.\n",
    "# bart = pipeline('summarization', model = 'facebook/bart-large-cnn')\n",
    "\n",
    "# def bart_pra_focused_summary(answer_text: str, retrieved_df: pd.DataFrame, min_len: int = 40) -> str:\n",
    "#     keywords = pra_keywords(retrieved_df, top_n=3)\n",
    "\n",
    "#     # input: banker answer + PRA keyword hint \n",
    "#     input_text = f\"{answer_text}\\n\\n[PRA focus: {keywords}]\"\n",
    "\n",
    "#     # number of input tokens\n",
    "#     input_ids = bart.tokenizer.encode(input_text, truncation=True)\n",
    "#     input_len = len(input_ids)\n",
    "\n",
    "#     max_new = min(120, max(20, int(input_len * 0.7)))\n",
    "#     min_new = min(60, int(input_len * 0.3))\n",
    "\n",
    "#     # generate summaries\n",
    "#     output = bart(\n",
    "#         input_text,\n",
    "#         max_new_tokens=max_new,\n",
    "#         min_length=min_new,\n",
    "#         do_sample=False,\n",
    "#         num_beams=4,\n",
    "#         no_repeat_ngram_size=3,\n",
    "#         truncation=True\n",
    "#     )\n",
    "    \n",
    "#     return output[0]['summary_text']\n",
    "    \n",
    "    \n",
    "    \n",
    "#     # top = retrieve_pra_context(answer_text, k=k)\n",
    "#     # context = make_context_block(top)\n",
    "\n",
    "#     # prompt = (\n",
    "#     #     'Summarise the following banker answer for PRA stakeholders.\\n'\n",
    "#     #     'Focus on concrete details related to the most relevant risk categories below.\\n\\n'\n",
    "#     #     'Relevant PRA risk categories:\\n'\n",
    "#     #     f'{context}\\n\\n'\n",
    "#     #     'Banker answer:\\n'\n",
    "#     #     f'{answer_text}\\n\\n'\n",
    "#     #     'Return 2 bullet points with a summary and then how it related to PRA risks'\n",
    "#     # )\n",
    "\n",
    "#     # out = summariser(prompt, max_length=max_len, min_length=min_len, do_sample=False)\n",
    "\n",
    "#     # return out[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ca7881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Wrapper function.\n",
    "# def pra_focused_summary(answer_text: str, k: int = 3) -> str:\n",
    "#     top = retrieve_pra_context(answer_text, k=k)\n",
    "#     return bart_pra_focused_summary(answer_text, top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bb16e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test on a sample.\n",
    "# banker_answers_df = jpm_2025_df[jpm_2025_df['role_normalised'] == 'banker'][['content']]\n",
    "# banker_answers_df_sample = banker_answers_df.head(25).copy()\n",
    "# banker_answers_df_sample['pra_summary'] = banker_answers_df_sample['content'].apply(pra_focused_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecde3900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(banker_answers_df_sample['pra_summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd9d93f",
   "metadata": {},
   "source": [
    "# **6. Evasion Scoring**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-evasion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
