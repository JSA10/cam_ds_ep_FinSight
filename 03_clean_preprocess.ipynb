{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2xXRGjXCIFH",
        "outputId": "7f336be4-51e9-440e-86ee-933673fcc3e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Cleaning and preprocessing data for bank: JPM\n"
          ]
        }
      ],
      "source": [
        "# FIXED 03_clean_preprocess.ipynb\n",
        "# Purpose: Clean and preprocess JPM earnings call transcript data\n",
        "# Input: raw_jpm_q1_2025_df, raw_jpm_q2_2025_df, raw_jpm_multi_2025_df\n",
        "# Output: clean_jpm_q1_2025_df, clean_jpm_q2_2025_df, clean_jpm_multi_2025_df\n",
        "\n",
        "## Import Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Location A: Google Drive (Primary drive)\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "\n",
        "# Load configuration and data registry\n",
        "config_path = Path(\"/content/drive/MyDrive/CAM_DS_AI_Project/config.json\")\n",
        "with open(config_path, \"r\") as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "registry_path = Path(config[\"drive_base\"]) / \"data_registry.json\"\n",
        "with open(registry_path, \"r\") as f:\n",
        "    data_registry = json.load(f)\n",
        "\n",
        "SEED = config[\"SEED\"]\n",
        "BANK_CODE = config[\"BANK_CODE\"]\n",
        "drive_base = Path(config[\"drive_base\"])\n",
        "colab_base = Path(config[\"colab_base\"])\n",
        "\n",
        "print(f\"Cleaning and preprocessing data for bank: {BANK_CODE.upper()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Define Paths\n",
        "\n",
        "raw_data_path = drive_base / \"data/raw/jpm\"\n",
        "clean_data_path = drive_base / \"data/clean/jpm\"\n",
        "processed_data_path = drive_base / \"data/processed/jpm\"\n",
        "\n",
        "# Ensure directories exist\n",
        "clean_data_path.mkdir(parents=True, exist_ok=True)\n",
        "processed_data_path.mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "Vzr6gF7eCUN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Load Raw Data\n",
        "\n",
        "def load_raw_dataset(dataset_key):\n",
        "    \"\"\"Load raw dataset using registry information.\"\"\"\n",
        "    if not data_registry[dataset_key][\"loaded\"]:\n",
        "        print(f\"‚ùå {dataset_key} was not successfully loaded in previous step\")\n",
        "        return None\n",
        "\n",
        "    file_path = Path(data_registry[dataset_key][\"path\"])\n",
        "    if not file_path.exists():\n",
        "        print(f\"‚ùå {dataset_key} file not found: {file_path}\")\n",
        "        return None\n",
        "\n",
        "    df = pd.read_csv(file_path)\n",
        "    expected_shape = data_registry[dataset_key][\"shape\"]\n",
        "    print(f\"‚úì Loaded {dataset_key}: {df.shape} (expected: {expected_shape})\")\n",
        "\n",
        "    return df\n",
        "\n",
        "print(\"Loading raw datasets...\")\n",
        "raw_jpm_q1_2025_df = load_raw_dataset(\"raw_jpm_q1_2025_df\")\n",
        "raw_jpm_q2_2025_df = load_raw_dataset(\"raw_jpm_q2_2025_df\")\n",
        "raw_jpm_multi_2025_df = load_raw_dataset(\"raw_jpm_multi_2025_df\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-J7mbZTkCXt6",
        "outputId": "81574ad2-7f57-45fe-e579-f464629b2992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading raw datasets...\n",
            "‚úì Loaded raw_jpm_q1_2025_df: (112, 10) (expected: [112, 10])\n",
            "‚úì Loaded raw_jpm_q2_2025_df: (149, 10) (expected: [149, 10])\n",
            "‚úì Loaded raw_jpm_multi_2025_df: (261, 10) (expected: [261, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## FIXED Data Cleaning Functions\n",
        "\n",
        "def clean_column_names(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Standardize column names to snake_case and map to expected names.\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # Convert to snake_case\n",
        "    new_columns = {}\n",
        "    for col in df.columns:\n",
        "        # Remove special characters and convert to lowercase\n",
        "        clean_col = re.sub(r'[^\\w\\s]', '', str(col).lower())\n",
        "        # Replace spaces with underscores\n",
        "        clean_col = re.sub(r'\\s+', '_', clean_col.strip())\n",
        "        # Remove multiple underscores\n",
        "        clean_col = re.sub(r'_+', '_', clean_col)\n",
        "        new_columns[col] = clean_col\n",
        "\n",
        "    df = df.rename(columns=new_columns)\n",
        "\n",
        "    # FIXED: Map column names to expected names\n",
        "    column_mapping = {\n",
        "        'content': 'text',  # Map 'content' to 'text'\n",
        "        'speaker_name': 'speaker',  # Map 'speaker_name' to 'speaker'\n",
        "        'role': 'original_role'  # Keep original role info\n",
        "    }\n",
        "\n",
        "    # Apply mapping if columns exist\n",
        "    for old_col, new_col in column_mapping.items():\n",
        "        if old_col in df.columns:\n",
        "            df = df.rename(columns={old_col: new_col})\n",
        "            print(f\"‚úì Mapped '{old_col}' ‚Üí '{new_col}'\")\n",
        "\n",
        "    print(f\"‚úì Column names standardized: {list(df.columns)}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def clean_speaker_names(df: pd.DataFrame, speaker_col: str = 'speaker') -> pd.DataFrame:\n",
        "    \"\"\"Clean and standardize speaker names.\"\"\"\n",
        "    if speaker_col not in df.columns:\n",
        "        print(f\"‚ö†Ô∏è  Speaker column '{speaker_col}' not found. Available: {list(df.columns)}\")\n",
        "        return df\n",
        "\n",
        "    df = df.copy()\n",
        "\n",
        "    # Define speaker role mapping\n",
        "    speaker_mapping = {\n",
        "        # Analyst patterns\n",
        "        r'.*analyst.*': 'analyst',\n",
        "        r'.*research.*': 'analyst',\n",
        "\n",
        "        # Executive patterns\n",
        "        r'.*ceo.*': 'ceo',\n",
        "        r'.*chief executive.*': 'ceo',\n",
        "        r'.*cfo.*': 'cfo',\n",
        "        r'.*chief financial.*': 'cfo',\n",
        "        r'.*coo.*': 'coo',\n",
        "        r'.*president.*': 'president',\n",
        "        r'.*chairman.*': 'chairman',\n",
        "\n",
        "        # Operator patterns\n",
        "        r'.*operator.*': 'operator',\n",
        "        r'.*moderator.*': 'operator',\n",
        "\n",
        "        # Generic patterns\n",
        "        r'.*management.*': 'executive',\n",
        "        r'.*executive.*': 'executive'\n",
        "    }\n",
        "\n",
        "    # Clean speaker names\n",
        "    df[speaker_col] = df[speaker_col].astype(str).str.lower().str.strip()\n",
        "\n",
        "    # Apply mapping\n",
        "    df[f'{speaker_col}_role'] = 'other'  # Default value\n",
        "\n",
        "    for pattern, role in speaker_mapping.items():\n",
        "        mask = df[speaker_col].str.contains(pattern, regex=True, na=False)\n",
        "        df.loc[mask, f'{speaker_col}_role'] = role\n",
        "\n",
        "    # Also check original_role column if it exists\n",
        "    if 'original_role' in df.columns:\n",
        "        df['original_role'] = df['original_role'].astype(str).str.lower().str.strip()\n",
        "        for pattern, role in speaker_mapping.items():\n",
        "            mask = df['original_role'].str.contains(pattern, regex=True, na=False)\n",
        "            df.loc[mask, f'{speaker_col}_role'] = role\n",
        "\n",
        "    print(f\"‚úì Speaker roles assigned:\")\n",
        "    role_counts = df[f'{speaker_col}_role'].value_counts()\n",
        "    for role, count in role_counts.items():\n",
        "        print(f\"  {role}: {count}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def clean_text_content(df: pd.DataFrame, text_col: str = 'text') -> pd.DataFrame:\n",
        "    \"\"\"Clean and preprocess text content.\"\"\"\n",
        "    if text_col not in df.columns:\n",
        "        print(f\"‚ö†Ô∏è  Text column '{text_col}' not found. Available: {list(df.columns)}\")\n",
        "        return df\n",
        "\n",
        "    df = df.copy()\n",
        "\n",
        "    print(f\"Cleaning text in column: {text_col}\")\n",
        "\n",
        "    # Convert to string and handle missing values\n",
        "    df[text_col] = df[text_col].astype(str).fillna('')\n",
        "\n",
        "    # Remove or replace common artifacts\n",
        "    df[f'{text_col}_clean'] = df[text_col].str.replace(r'\\[.*?\\]', '', regex=True)  # Remove [brackets]\n",
        "    df[f'{text_col}_clean'] = df[f'{text_col}_clean'].str.replace(r'\\(.*?\\)', '', regex=True)  # Remove (parentheses)\n",
        "    df[f'{text_col}_clean'] = df[f'{text_col}_clean'].str.replace(r'--+', ' ', regex=True)  # Replace dashes\n",
        "    df[f'{text_col}_clean'] = df[f'{text_col}_clean'].str.replace(r'\\s+', ' ', regex=True)  # Multiple spaces\n",
        "    df[f'{text_col}_clean'] = df[f'{text_col}_clean'].str.strip()\n",
        "\n",
        "    # Remove empty strings\n",
        "    df[f'{text_col}_clean'] = df[f'{text_col}_clean'].replace('', pd.NA)\n",
        "\n",
        "    # Calculate text statistics\n",
        "    df[f'{text_col}_length'] = df[f'{text_col}_clean'].str.len()\n",
        "    df[f'{text_col}_word_count'] = df[f'{text_col}_clean'].str.split().str.len()\n",
        "\n",
        "    # Remove very short texts (likely artifacts)\n",
        "    min_length = 10\n",
        "    short_text_mask = df[f'{text_col}_length'] < min_length\n",
        "    print(f\"  Texts shorter than {min_length} chars: {short_text_mask.sum()}\")\n",
        "\n",
        "    # Calculate cleaning stats\n",
        "    original_lengths = df[text_col].str.len()\n",
        "    clean_lengths = df[f'{text_col}_length'].fillna(0)\n",
        "    avg_reduction = (original_lengths - clean_lengths).mean()\n",
        "    print(f\"  Average length reduction: {avg_reduction:.1f} characters\")\n",
        "\n",
        "    # Show sample of cleaned text\n",
        "    valid_text_mask = df[f'{text_col}_clean'].notna() & (df[f'{text_col}_length'] >= min_length)\n",
        "    if valid_text_mask.sum() > 0:\n",
        "        sample_text = df.loc[valid_text_mask, f'{text_col}_clean'].iloc[0]\n",
        "        print(f\"  Sample cleaned text: '{sample_text[:100]}...'\")\n",
        "        print(f\"  Valid texts for processing: {valid_text_mask.sum()}/{len(df)}\")\n",
        "    else:\n",
        "        print(f\"  ‚ùå No valid texts found after cleaning!\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def remove_duplicates(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Remove duplicate entries.\"\"\"\n",
        "    original_count = len(df)\n",
        "\n",
        "    # Remove exact duplicates\n",
        "    df_dedup = df.drop_duplicates()\n",
        "\n",
        "    # Remove duplicates based on text content if available\n",
        "    if 'text_clean' in df.columns:\n",
        "        df_dedup = df_dedup.drop_duplicates(subset=['text_clean'])\n",
        "\n",
        "    removed_count = original_count - len(df_dedup)\n",
        "    print(f\"‚úì Removed {removed_count} duplicate entries ({removed_count/original_count*100:.1f}%)\")\n",
        "\n",
        "    return df_dedup\n",
        "\n",
        "def add_metadata_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Add metadata columns for analysis.\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # Add row ID\n",
        "    df['qa_id'] = range(len(df))\n",
        "\n",
        "    # Add timestamp if not present\n",
        "    if 'timestamp' not in df.columns:\n",
        "        df['timestamp'] = pd.Timestamp.now()\n",
        "\n",
        "    # Add bank identifier\n",
        "    df['bank_code'] = BANK_CODE\n",
        "\n",
        "    # Add is_valid flag\n",
        "    df['is_valid'] = True\n",
        "\n",
        "    # Mark invalid entries\n",
        "    if 'text_clean' in df.columns:\n",
        "        # Invalid if text is too short or missing\n",
        "        invalid_text_mask = (df['text_clean'].isna()) | (df['text_clean'].str.len() < 10)\n",
        "        df.loc[invalid_text_mask, 'is_valid'] = False\n",
        "\n",
        "    if 'speaker_role' in df.columns:\n",
        "        # Don't mark 'other' as invalid - they might still have valid content\n",
        "        pass\n",
        "\n",
        "    invalid_count = (~df['is_valid']).sum()\n",
        "    print(f\"‚úì Added metadata columns, marked {invalid_count} entries as invalid\")\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "XPWTnA1ZDjcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Clean Individual Datasets\n",
        "\n",
        "def clean_dataset(df: pd.DataFrame, dataset_name: str) -> pd.DataFrame:\n",
        "    \"\"\"Apply all cleaning steps to a dataset.\"\"\"\n",
        "    if df is None:\n",
        "        print(f\"‚ùå Cannot clean {dataset_name} - dataset is None\")\n",
        "        return None\n",
        "\n",
        "    print(f\"\\nüßπ CLEANING {dataset_name}\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"Input shape: {df.shape}\")\n",
        "    print(f\"Input columns: {list(df.columns)}\")\n",
        "\n",
        "    # Step 1: Clean column names\n",
        "    df_clean = clean_column_names(df)\n",
        "\n",
        "    # Step 2: Clean speaker names\n",
        "    df_clean = clean_speaker_names(df_clean)\n",
        "\n",
        "    # Step 3: Clean text content\n",
        "    df_clean = clean_text_content(df_clean)\n",
        "\n",
        "    # Step 4: Remove duplicates\n",
        "    df_clean = remove_duplicates(df_clean)\n",
        "\n",
        "    # Step 5: Add metadata\n",
        "    df_clean = add_metadata_columns(df_clean)\n",
        "\n",
        "    # Step 6: Filter out invalid entries but keep some for debugging\n",
        "    valid_df = df_clean[df_clean['is_valid']].copy()\n",
        "    invalid_count = len(df_clean) - len(valid_df)\n",
        "\n",
        "    print(f\"Final shape: {valid_df.shape} (removed {invalid_count} invalid entries)\")\n",
        "\n",
        "    return valid_df\n",
        "\n",
        "# Clean all datasets with enhanced debugging\n",
        "clean_jpm_q1_2025_df = clean_dataset(raw_jpm_q1_2025_df, \"Q1 2025\")\n",
        "clean_jpm_q2_2025_df = clean_dataset(raw_jpm_q2_2025_df, \"Q2 2025\")\n",
        "clean_jpm_multi_2025_df = clean_dataset(raw_jpm_multi_2025_df, \"Multi 2025\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1THLUCDDplR",
        "outputId": "d2e177e8-ae79-4888-f632-0b4a2048ae78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üßπ CLEANING Q1 2025\n",
            "----------------------------------------\n",
            "Input shape: (112, 10)\n",
            "Input columns: ['section', 'question_number', 'answer_number', 'speaker_name', 'role', 'company', 'content', 'year', 'quarter', 'is_pleasantry']\n",
            "‚úì Mapped 'content' ‚Üí 'text'\n",
            "‚úì Mapped 'speaker_name' ‚Üí 'speaker'\n",
            "‚úì Mapped 'role' ‚Üí 'original_role'\n",
            "‚úì Column names standardized: ['section', 'question_number', 'answer_number', 'speaker', 'original_role', 'company', 'text', 'year', 'quarter', 'is_pleasantry']\n",
            "‚úì Speaker roles assigned:\n",
            "  analyst: 44\n",
            "  cfo: 37\n",
            "  executive: 31\n",
            "Cleaning text in column: text\n",
            "  Texts shorter than 10 chars: 2\n",
            "  Average length reduction: 1.0 characters\n",
            "  Sample cleaned text: 'Thank you and good morning, everyone. Starting on page 1, the Firm reported net income of $14.6 bill...'\n",
            "  Valid texts for processing: 110/112\n",
            "‚úì Removed 1 duplicate entries (0.9%)\n",
            "‚úì Added metadata columns, marked 2 entries as invalid\n",
            "Final shape: (109, 18) (removed 2 invalid entries)\n",
            "\n",
            "üßπ CLEANING Q2 2025\n",
            "----------------------------------------\n",
            "Input shape: (149, 10)\n",
            "Input columns: ['section', 'question_number', 'answer_number', 'speaker_name', 'role', 'company', 'content', 'year', 'quarter', 'is_pleasantry']\n",
            "‚úì Mapped 'content' ‚Üí 'text'\n",
            "‚úì Mapped 'speaker_name' ‚Üí 'speaker'\n",
            "‚úì Mapped 'role' ‚Üí 'original_role'\n",
            "‚úì Column names standardized: ['section', 'question_number', 'answer_number', 'speaker', 'original_role', 'company', 'text', 'year', 'quarter', 'is_pleasantry']\n",
            "‚úì Speaker roles assigned:\n",
            "  cfo: 57\n",
            "  analyst: 57\n",
            "  executive: 35\n",
            "Cleaning text in column: text\n",
            "  Texts shorter than 10 chars: 4\n",
            "  Average length reduction: 0.6 characters\n",
            "  Sample cleaned text: 'names, partially offset by the scenario probability adjustment I mentioned upfront. Turning to Asset...'\n",
            "  Valid texts for processing: 145/149\n",
            "‚úì Removed 0 duplicate entries (0.0%)\n",
            "‚úì Added metadata columns, marked 4 entries as invalid\n",
            "Final shape: (145, 18) (removed 4 invalid entries)\n",
            "\n",
            "üßπ CLEANING Multi 2025\n",
            "----------------------------------------\n",
            "Input shape: (261, 10)\n",
            "Input columns: ['section', 'question_number', 'answer_number', 'speaker_name', 'role', 'company', 'content', 'year', 'quarter', 'is_pleasantry']\n",
            "‚úì Mapped 'content' ‚Üí 'text'\n",
            "‚úì Mapped 'speaker_name' ‚Üí 'speaker'\n",
            "‚úì Mapped 'role' ‚Üí 'original_role'\n",
            "‚úì Column names standardized: ['section', 'question_number', 'answer_number', 'speaker', 'original_role', 'company', 'text', 'year', 'quarter', 'is_pleasantry']\n",
            "‚úì Speaker roles assigned:\n",
            "  analyst: 101\n",
            "  cfo: 94\n",
            "  executive: 66\n",
            "Cleaning text in column: text\n",
            "  Texts shorter than 10 chars: 6\n",
            "  Average length reduction: 0.8 characters\n",
            "  Sample cleaned text: 'Thank you and good morning, everyone. Starting on page 1, the Firm reported net income of $14.6 bill...'\n",
            "  Valid texts for processing: 255/261\n",
            "‚úì Removed 4 duplicate entries (1.5%)\n",
            "‚úì Added metadata columns, marked 5 entries as invalid\n",
            "Final shape: (252, 18) (removed 5 invalid entries)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## FIXED Preprocessing for Sentiment Analysis\n",
        "\n",
        "def preprocess_for_sentiment(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Additional preprocessing specifically for sentiment analysis.\"\"\"\n",
        "    if df is None:\n",
        "        print(\"‚ùå Cannot preprocess - dataset is None\")\n",
        "        return None\n",
        "\n",
        "    print(f\"\\nüîÑ PREPROCESSING FOR SENTIMENT ANALYSIS\")\n",
        "    print(f\"Input shape: {df.shape}\")\n",
        "    print(f\"Available columns: {list(df.columns)}\")\n",
        "\n",
        "    # Check if text_clean column exists\n",
        "    if 'text_clean' not in df.columns:\n",
        "        print(\"‚ùå 'text_clean' column not found - cannot proceed with sentence splitting\")\n",
        "        return pd.DataFrame()  # Return empty DataFrame instead of None\n",
        "\n",
        "    df = df.copy()\n",
        "\n",
        "    # Create sentence-level splits for granular analysis\n",
        "    sentences = []\n",
        "    processed_count = 0\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        text_content = row.get('text_clean', '')\n",
        "\n",
        "        # Skip if no valid text content\n",
        "        if pd.isna(text_content) or str(text_content).strip() == '' or str(text_content) == 'nan':\n",
        "            continue\n",
        "\n",
        "        # Convert to string and clean\n",
        "        text_content = str(text_content).strip()\n",
        "\n",
        "        if len(text_content) < 10:  # Skip very short texts\n",
        "            continue\n",
        "\n",
        "        # Enhanced sentence splitting\n",
        "        # Split on multiple sentence terminators\n",
        "        text_sentences = re.split(r'[.!?]+', text_content)\n",
        "\n",
        "        sentence_count = 0\n",
        "        for sent_idx, sentence in enumerate(text_sentences):\n",
        "            sentence = sentence.strip()\n",
        "            if len(sentence) > 20:  # Only keep meaningful sentences\n",
        "                sentences.append({\n",
        "                    'original_qa_id': row.get('qa_id', idx),\n",
        "                    'sentence_id': f\"{row.get('qa_id', idx)}_{sent_idx}\",\n",
        "                    'text': sentence,\n",
        "                    'speaker': row.get('speaker', ''),\n",
        "                    'speaker_role': row.get('speaker_role', ''),\n",
        "                    'quarter': row.get('quarter', ''),\n",
        "                    'bank_code': row.get('bank_code', BANK_CODE),\n",
        "                    'sentence_length': len(sentence),\n",
        "                    'sentence_word_count': len(sentence.split())\n",
        "                })\n",
        "                sentence_count += 1\n",
        "\n",
        "        if sentence_count > 0:\n",
        "            processed_count += 1\n",
        "\n",
        "    sentences_df = pd.DataFrame(sentences)\n",
        "\n",
        "    print(f\"‚úì Processed {processed_count}/{len(df)} Q&A pairs\")\n",
        "    print(f\"‚úì Created sentence-level dataset: {len(sentences_df)} sentences\")\n",
        "\n",
        "    if len(sentences_df) > 0:\n",
        "        print(f\"  Sample sentence: '{sentences_df.iloc[0]['text'][:100]}...'\")\n",
        "        print(f\"  Average sentence length: {sentences_df['sentence_length'].mean():.1f} chars\")\n",
        "        print(f\"  Average words per sentence: {sentences_df['sentence_word_count'].mean():.1f}\")\n",
        "\n",
        "    return sentences_df\n",
        "\n",
        "# Create sentence-level datasets for sentiment analysis with enhanced processing\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PREPROCESSING FOR SENTIMENT ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "processed_jpm_q1_2025_df = preprocess_for_sentiment(clean_jpm_q1_2025_df)\n",
        "processed_jpm_q2_2025_df = preprocess_for_sentiment(clean_jpm_q2_2025_df)\n",
        "processed_jpm_multi_2025_df = preprocess_for_sentiment(clean_jpm_multi_2025_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAEwbBQuDtxz",
        "outputId": "4c9290b6-ae56-4535-a698-5e0de79eb5c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "PREPROCESSING FOR SENTIMENT ANALYSIS\n",
            "============================================================\n",
            "\n",
            "üîÑ PREPROCESSING FOR SENTIMENT ANALYSIS\n",
            "Input shape: (109, 18)\n",
            "Available columns: ['section', 'question_number', 'answer_number', 'speaker', 'original_role', 'company', 'text', 'year', 'quarter', 'is_pleasantry', 'speaker_role', 'text_clean', 'text_length', 'text_word_count', 'qa_id', 'timestamp', 'bank_code', 'is_valid']\n",
            "‚úì Processed 97/109 Q&A pairs\n",
            "‚úì Created sentence-level dataset: 578 sentences\n",
            "  Sample sentence: 'Thank you and good morning, everyone...'\n",
            "  Average sentence length: 94.6 chars\n",
            "  Average words per sentence: 17.0\n",
            "\n",
            "üîÑ PREPROCESSING FOR SENTIMENT ANALYSIS\n",
            "Input shape: (145, 18)\n",
            "Available columns: ['section', 'question_number', 'answer_number', 'speaker', 'original_role', 'company', 'text', 'year', 'quarter', 'is_pleasantry', 'speaker_role', 'text_clean', 'text_length', 'text_word_count', 'qa_id', 'timestamp', 'bank_code', 'is_valid']\n",
            "‚úì Processed 121/145 Q&A pairs\n",
            "‚úì Created sentence-level dataset: 532 sentences\n",
            "  Sample sentence: 'names, partially offset by the scenario probability adjustment I mentioned upfront...'\n",
            "  Average sentence length: 97.6 chars\n",
            "  Average words per sentence: 17.9\n",
            "\n",
            "üîÑ PREPROCESSING FOR SENTIMENT ANALYSIS\n",
            "Input shape: (252, 18)\n",
            "Available columns: ['section', 'question_number', 'answer_number', 'speaker', 'original_role', 'company', 'text', 'year', 'quarter', 'is_pleasantry', 'speaker_role', 'text_clean', 'text_length', 'text_word_count', 'qa_id', 'timestamp', 'bank_code', 'is_valid']\n",
            "‚úì Processed 218/252 Q&A pairs\n",
            "‚úì Created sentence-level dataset: 1110 sentences\n",
            "  Sample sentence: 'Thank you and good morning, everyone...'\n",
            "  Average sentence length: 96.0 chars\n",
            "  Average words per sentence: 17.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Enhanced Data Quality Assessment\n",
        "\n",
        "def assess_data_quality(df: pd.DataFrame, dataset_name: str):\n",
        "    \"\"\"Assess and report data quality metrics.\"\"\"\n",
        "    if df is None:\n",
        "        print(f\"‚ùå Cannot assess {dataset_name} - dataset is None\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nüìã DATA QUALITY ASSESSMENT - {dataset_name}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Basic stats\n",
        "    print(f\"Shape: {df.shape}\")\n",
        "    print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "    # Missing values\n",
        "    missing = df.isnull().sum()\n",
        "    if missing.any():\n",
        "        print(f\"\\nMissing values:\")\n",
        "        for col, count in missing[missing > 0].items():\n",
        "            pct = (count / len(df)) * 100\n",
        "            print(f\"  {col}: {count} ({pct:.1f}%)\")\n",
        "    else:\n",
        "        print(\"‚úì No missing values\")\n",
        "\n",
        "    # Text quality metrics\n",
        "    if 'text_clean' in df.columns:\n",
        "        valid_text_mask = df['text_clean'].notna() & (df['text_clean'] != '') & (df['text_clean'] != 'nan')\n",
        "        valid_texts = df.loc[valid_text_mask, 'text_clean']\n",
        "\n",
        "        if len(valid_texts) > 0:\n",
        "            text_lengths = valid_texts.str.len()\n",
        "            word_counts = valid_texts.str.split().str.len()\n",
        "\n",
        "            print(f\"\\nText quality metrics ({len(valid_texts)} valid texts):\")\n",
        "            print(f\"  Length - Mean: {text_lengths.mean():.0f}, Median: {text_lengths.median():.0f}\")\n",
        "            print(f\"  Length - Min: {text_lengths.min()}, Max: {text_lengths.max()}\")\n",
        "            print(f\"  Words - Mean: {word_counts.mean():.1f}, Median: {word_counts.median():.1f}\")\n",
        "\n",
        "            # Show sample text\n",
        "            print(f\"  Sample text: '{valid_texts.iloc[0][:100]}...'\")\n",
        "        else:\n",
        "            print(f\"\\n‚ùå No valid text content found!\")\n",
        "\n",
        "    # Check for 'text' column (should exist after processing)\n",
        "    if 'text' in df.columns:\n",
        "        valid_text_mask = df['text'].notna() & (df['text'] != '') & (df['text'] != 'nan')\n",
        "        print(f\"\\nText column: {valid_text_mask.sum()} valid entries\")\n",
        "        if valid_text_mask.sum() > 0:\n",
        "            sample_text = df.loc[valid_text_mask, 'text'].iloc[0]\n",
        "            print(f\"  Sample: '{sample_text[:100]}...'\")\n",
        "\n",
        "    # Speaker distribution\n",
        "    if 'speaker_role' in df.columns:\n",
        "        print(f\"\\nSpeaker role distribution:\")\n",
        "        for role, count in df['speaker_role'].value_counts().items():\n",
        "            pct = (count / len(df)) * 100\n",
        "            print(f\"  {role}: {count} ({pct:.1f}%)\")\n",
        "\n",
        "# Assess all datasets\n",
        "assess_data_quality(clean_jpm_q1_2025_df, \"Q1 2025 Clean\")\n",
        "assess_data_quality(clean_jpm_q2_2025_df, \"Q2 2025 Clean\")\n",
        "assess_data_quality(clean_jpm_multi_2025_df, \"Multi 2025 Clean\")\n",
        "\n",
        "assess_data_quality(processed_jpm_q1_2025_df, \"Q1 2025 Processed\")\n",
        "assess_data_quality(processed_jpm_q2_2025_df, \"Q2 2025 Processed\")\n",
        "assess_data_quality(processed_jpm_multi_2025_df, \"Multi 2025 Processed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZFYOj_IDxuw",
        "outputId": "ad688941-ddec-4287-e75e-94d1123d6403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìã DATA QUALITY ASSESSMENT - Q1 2025 Clean\n",
            "--------------------------------------------------\n",
            "Shape: (109, 18)\n",
            "Memory usage: 0.32 MB\n",
            "\n",
            "Missing values:\n",
            "  question_number: 1 (0.9%)\n",
            "  answer_number: 23 (21.1%)\n",
            "\n",
            "Text quality metrics (109 valid texts):\n",
            "  Length - Mean: 531, Median: 262\n",
            "  Length - Min: 10, Max: 9998\n",
            "  Words - Mean: 93.2, Median: 47.0\n",
            "  Sample text: 'Thank you and good morning, everyone. Starting on page 1, the Firm reported net income of $14.6 bill...'\n",
            "\n",
            "Text column: 109 valid entries\n",
            "  Sample: 'Thank you and good morning, everyone. Starting on page 1, the Firm reported net income of $14.6 bill...'\n",
            "\n",
            "Speaker role distribution:\n",
            "  analyst: 41 (37.6%)\n",
            "  cfo: 37 (33.9%)\n",
            "  executive: 31 (28.4%)\n",
            "\n",
            "üìã DATA QUALITY ASSESSMENT - Q2 2025 Clean\n",
            "--------------------------------------------------\n",
            "Shape: (145, 18)\n",
            "Memory usage: 0.27 MB\n",
            "\n",
            "Missing values:\n",
            "  question_number: 5 (3.4%)\n",
            "  answer_number: 38 (26.2%)\n",
            "\n",
            "Text quality metrics (145 valid texts):\n",
            "  Length - Mean: 381, Median: 247\n",
            "  Length - Min: 10, Max: 2490\n",
            "  Words - Mean: 68.5, Median: 45.0\n",
            "  Sample text: 'names, partially offset by the scenario probability adjustment I mentioned upfront. Turning to Asset...'\n",
            "\n",
            "Text column: 145 valid entries\n",
            "  Sample: 'names, partially offset by the scenario probability adjustment I mentioned upfront. Turning to Asset...'\n",
            "\n",
            "Speaker role distribution:\n",
            "  analyst: 57 (39.3%)\n",
            "  cfo: 55 (37.9%)\n",
            "  executive: 33 (22.8%)\n",
            "\n",
            "üìã DATA QUALITY ASSESSMENT - Multi 2025 Clean\n",
            "--------------------------------------------------\n",
            "Shape: (252, 18)\n",
            "Memory usage: 0.59 MB\n",
            "\n",
            "Missing values:\n",
            "  question_number: 6 (2.4%)\n",
            "  answer_number: 61 (24.2%)\n",
            "\n",
            "Text quality metrics (252 valid texts):\n",
            "  Length - Mean: 449, Median: 264\n",
            "  Length - Min: 10, Max: 9998\n",
            "  Words - Mean: 79.7, Median: 46.0\n",
            "  Sample text: 'Thank you and good morning, everyone. Starting on page 1, the Firm reported net income of $14.6 bill...'\n",
            "\n",
            "Text column: 252 valid entries\n",
            "  Sample: 'Thank you and good morning, everyone. Starting on page 1, the Firm reported net income of $14.6 bill...'\n",
            "\n",
            "Speaker role distribution:\n",
            "  analyst: 96 (38.1%)\n",
            "  cfo: 92 (36.5%)\n",
            "  executive: 64 (25.4%)\n",
            "\n",
            "üìã DATA QUALITY ASSESSMENT - Q1 2025 Processed\n",
            "--------------------------------------------------\n",
            "Shape: (578, 9)\n",
            "Memory usage: 0.25 MB\n",
            "‚úì No missing values\n",
            "\n",
            "Text column: 578 valid entries\n",
            "  Sample: 'Thank you and good morning, everyone...'\n",
            "\n",
            "Speaker role distribution:\n",
            "  cfo: 257 (44.5%)\n",
            "  executive: 203 (35.1%)\n",
            "  analyst: 118 (20.4%)\n",
            "\n",
            "üìã DATA QUALITY ASSESSMENT - Q2 2025 Processed\n",
            "--------------------------------------------------\n",
            "Shape: (532, 9)\n",
            "Memory usage: 0.23 MB\n",
            "‚úì No missing values\n",
            "\n",
            "Text column: 532 valid entries\n",
            "  Sample: 'names, partially offset by the scenario probability adjustment I mentioned upfront...'\n",
            "\n",
            "Speaker role distribution:\n",
            "  cfo: 227 (42.7%)\n",
            "  executive: 180 (33.8%)\n",
            "  analyst: 125 (23.5%)\n",
            "\n",
            "üìã DATA QUALITY ASSESSMENT - Multi 2025 Processed\n",
            "--------------------------------------------------\n",
            "Shape: (1110, 9)\n",
            "Memory usage: 0.49 MB\n",
            "‚úì No missing values\n",
            "\n",
            "Text column: 1110 valid entries\n",
            "  Sample: 'Thank you and good morning, everyone...'\n",
            "\n",
            "Speaker role distribution:\n",
            "  cfo: 484 (43.6%)\n",
            "  executive: 383 (34.5%)\n",
            "  analyst: 243 (21.9%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Save Clean and Processed Datasets\n",
        "\n",
        "def save_dataset_multiple_locations(df, filename, description):\n",
        "    \"\"\"Save dataset to multiple locations with error handling.\"\"\"\n",
        "    if df is None or len(df) == 0:\n",
        "        print(f\"‚ùå Cannot save {description} - dataset is None or empty\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Saving {description}...\")\n",
        "\n",
        "    paths_saved = []\n",
        "\n",
        "    try:\n",
        "        # Save to clean data directory\n",
        "        clean_path = clean_data_path / filename\n",
        "        df.to_csv(clean_path, index=False)\n",
        "        paths_saved.append(str(clean_path))\n",
        "        print(f\"  ‚úì Clean: {clean_path} ({len(df)} rows)\")\n",
        "\n",
        "        # Save to processed directory if it's a processed dataset\n",
        "        if 'processed' in filename:\n",
        "            processed_path = processed_data_path / filename\n",
        "            df.to_csv(processed_path, index=False)\n",
        "            paths_saved.append(str(processed_path))\n",
        "            print(f\"  ‚úì Processed: {processed_path} ({len(df)} rows)\")\n",
        "\n",
        "        # Save to colab for easy access\n",
        "        colab_clean_path = colab_base / \"data/clean/jpm\" / filename\n",
        "        colab_clean_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        df.to_csv(colab_clean_path, index=False)\n",
        "        paths_saved.append(str(colab_clean_path))\n",
        "        print(f\"  ‚úì Colab: {colab_clean_path} ({len(df)} rows)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error saving {description}: {str(e)}\")\n",
        "\n",
        "    return paths_saved\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SAVING CLEAN AND PROCESSED DATASETS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Save clean datasets (Q&A level)\n",
        "save_dataset_multiple_locations(clean_jpm_q1_2025_df, \"clean_jpm_q1_2025.csv\", \"Q1 2025 clean data\")\n",
        "save_dataset_multiple_locations(clean_jpm_q2_2025_df, \"clean_jpm_q2_2025.csv\", \"Q2 2025 clean data\")\n",
        "save_dataset_multiple_locations(clean_jpm_multi_2025_df, \"clean_jmp_multi_2025.csv\", \"Multi 2025 clean data\")\n",
        "\n",
        "# Save processed datasets (sentence level) - only if they have data\n",
        "if processed_jpm_q1_2025_df is not None and len(processed_jpm_q1_2025_df) > 0:\n",
        "    save_dataset_multiple_locations(processed_jpm_q1_2025_df, \"processed_jpm_q1_2025.csv\", \"Q1 2025 processed data\")\n",
        "else:\n",
        "    print(\"‚ùå Q1 2025 processed data is empty - not saving\")\n",
        "\n",
        "if processed_jpm_q2_2025_df is not None and len(processed_jpm_q2_2025_df) > 0:\n",
        "    save_dataset_multiple_locations(processed_jpm_q2_2025_df, \"processed_jpm_q2_2025.csv\", \"Q2 2025 processed data\")\n",
        "else:\n",
        "    print(\"‚ùå Q2 2025 processed data is empty - not saving\")\n",
        "\n",
        "if processed_jpm_multi_2025_df is not None and len(processed_jpm_multi_2025_df) > 0:\n",
        "    save_dataset_multiple_locations(processed_jpm_multi_2025_df, \"processed_jmp_multi_2025.csv\", \"Multi 2025 processed data\")\n",
        "else:\n",
        "    print(\"‚ùå Multi 2025 processed data is empty - not saving\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DtBYknMD1XA",
        "outputId": "a32fb909-4633-4419-e4c6-73433db7be49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "SAVING CLEAN AND PROCESSED DATASETS\n",
            "============================================================\n",
            "Saving Q1 2025 clean data...\n",
            "  ‚úì Clean: /content/drive/MyDrive/CAM_DS_AI_Project/data/clean/jpm/clean_jpm_q1_2025.csv (109 rows)\n",
            "  ‚úì Colab: /content/cam_ds_ai_project/data/clean/jpm/clean_jpm_q1_2025.csv (109 rows)\n",
            "Saving Q2 2025 clean data...\n",
            "  ‚úì Clean: /content/drive/MyDrive/CAM_DS_AI_Project/data/clean/jpm/clean_jpm_q2_2025.csv (145 rows)\n",
            "  ‚úì Colab: /content/cam_ds_ai_project/data/clean/jpm/clean_jpm_q2_2025.csv (145 rows)\n",
            "Saving Multi 2025 clean data...\n",
            "  ‚úì Clean: /content/drive/MyDrive/CAM_DS_AI_Project/data/clean/jpm/clean_jmp_multi_2025.csv (252 rows)\n",
            "  ‚úì Colab: /content/cam_ds_ai_project/data/clean/jpm/clean_jmp_multi_2025.csv (252 rows)\n",
            "Saving Q1 2025 processed data...\n",
            "  ‚úì Clean: /content/drive/MyDrive/CAM_DS_AI_Project/data/clean/jpm/processed_jpm_q1_2025.csv (578 rows)\n",
            "  ‚úì Processed: /content/drive/MyDrive/CAM_DS_AI_Project/data/processed/jpm/processed_jpm_q1_2025.csv (578 rows)\n",
            "  ‚úì Colab: /content/cam_ds_ai_project/data/clean/jpm/processed_jpm_q1_2025.csv (578 rows)\n",
            "Saving Q2 2025 processed data...\n",
            "  ‚úì Clean: /content/drive/MyDrive/CAM_DS_AI_Project/data/clean/jpm/processed_jpm_q2_2025.csv (532 rows)\n",
            "  ‚úì Processed: /content/drive/MyDrive/CAM_DS_AI_Project/data/processed/jpm/processed_jpm_q2_2025.csv (532 rows)\n",
            "  ‚úì Colab: /content/cam_ds_ai_project/data/clean/jpm/processed_jpm_q2_2025.csv (532 rows)\n",
            "Saving Multi 2025 processed data...\n",
            "  ‚úì Clean: /content/drive/MyDrive/CAM_DS_AI_Project/data/clean/jpm/processed_jmp_multi_2025.csv (1110 rows)\n",
            "  ‚úì Processed: /content/drive/MyDrive/CAM_DS_AI_Project/data/processed/jpm/processed_jmp_multi_2025.csv (1110 rows)\n",
            "  ‚úì Colab: /content/cam_ds_ai_project/data/clean/jpm/processed_jmp_multi_2025.csv (1110 rows)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Final Status Report\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL PROCESSING STATUS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "datasets = [\n",
        "    (\"Clean Q1 2025\", clean_jpm_q1_2025_df),\n",
        "    (\"Clean Q2 2025\", clean_jpm_q2_2025_df),\n",
        "    (\"Clean Multi 2025\", clean_jpm_multi_2025_df),\n",
        "    (\"Processed Q1 2025\", processed_jpm_q1_2025_df),\n",
        "    (\"Processed Q2 2025\", processed_jpm_q2_2025_df),\n",
        "    (\"Processed Multi 2025\", processed_jpm_multi_2025_df)\n",
        "]\n",
        "\n",
        "successful_datasets = 0\n",
        "total_sentences = 0\n",
        "\n",
        "for name, df in datasets:\n",
        "    if df is not None and len(df) > 0:\n",
        "        print(f\"‚úÖ {name}: {df.shape}\")\n",
        "        successful_datasets += 1\n",
        "        if 'Processed' in name:\n",
        "            total_sentences += len(df)\n",
        "    else:\n",
        "        print(f\"‚ùå {name}: Empty or None\")\n",
        "\n",
        "print(f\"\\nüìä Summary:\")\n",
        "print(f\"  Successful datasets: {successful_datasets}/6\")\n",
        "print(f\"  Total sentences ready for sentiment analysis: {total_sentences}\")\n",
        "\n",
        "if total_sentences > 0:\n",
        "    print(f\"\\n‚úÖ SUCCESS: Ready for sentiment analysis!\")\n",
        "    print(f\"   Use the processed datasets in notebook 04\")\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è  WARNING: No sentences generated for sentiment analysis\")\n",
        "    print(f\"   Check the text content in your raw data files\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmtbirD_D5jy",
        "outputId": "0d649902-8b81-49be-ed1f-07879db5be5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "FINAL PROCESSING STATUS\n",
            "============================================================\n",
            "‚úÖ Clean Q1 2025: (109, 18)\n",
            "‚úÖ Clean Q2 2025: (145, 18)\n",
            "‚úÖ Clean Multi 2025: (252, 18)\n",
            "‚úÖ Processed Q1 2025: (578, 9)\n",
            "‚úÖ Processed Q2 2025: (532, 9)\n",
            "‚úÖ Processed Multi 2025: (1110, 9)\n",
            "\n",
            "üìä Summary:\n",
            "  Successful datasets: 6/6\n",
            "  Total sentences ready for sentiment analysis: 2220\n",
            "\n",
            "‚úÖ SUCCESS: Ready for sentiment analysis!\n",
            "   Use the processed datasets in notebook 04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Export Variables Summary\n",
        "\n",
        "final_datasets = {\n",
        "    \"clean_qa_level\": [\n",
        "        clean_jpm_q1_2025_df,\n",
        "        clean_jpm_q2_2025_df,\n",
        "        clean_jpm_multi_2025_df\n",
        "    ],\n",
        "    \"processed_sentence_level\": [\n",
        "        processed_jpm_q1_2025_df,\n",
        "        processed_jpm_q2_2025_df,\n",
        "        processed_jpm_multi_2025_df\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Count total records ready for sentiment analysis\n",
        "total_sentences = 0\n",
        "total_qa_pairs = 0\n",
        "\n",
        "for df in final_datasets[\"clean_qa_level\"]:\n",
        "    if df is not None:\n",
        "        total_qa_pairs += len(df)\n",
        "\n",
        "for df in final_datasets[\"processed_sentence_level\"]:\n",
        "    if df is not None:\n",
        "        total_sentences += len(df)\n",
        "\n",
        "print(f\"\\nReady for sentiment analysis:\")\n",
        "print(f\"  Q&A pairs: {total_qa_pairs:,}\")\n",
        "print(f\"  Sentences: {total_sentences:,}\")\n",
        "print(f\"  Total memory: {sum(df.memory_usage(deep=True).sum() for df in final_datasets['clean_qa_level'] + final_datasets['processed_sentence_level'] if df is not None) / 1024**2:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eGFUVypD9wO",
        "outputId": "a97adbae-0073-4647-dab8-fc3cb75b5fbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ready for sentiment analysis:\n",
            "  Q&A pairs: 506\n",
            "  Sentences: 2,220\n",
            "  Total memory: 2.16 MB\n"
          ]
        }
      ]
    }
  ]
}