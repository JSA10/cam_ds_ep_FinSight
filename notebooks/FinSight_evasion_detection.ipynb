{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dc758a1",
   "metadata": {},
   "source": [
    "# **Evasion Detection Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d970815",
   "metadata": {},
   "source": [
    "# **1. Objectives**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1387398",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to contain the evasion detection pipeline. \n",
    "1. **Baseline Evasion score** (rule-based) is made up of three components:\n",
    "- **Cosine similarity**- similarity of the question and answer, lower similarity = more evasive\n",
    "- **Numeric specificity check**- does the question require a number, if so does the answer contain a number?, e.g. requests for financial data\n",
    "- **Evasive phrases**- does the answer contain evasive phrases?, presence = more evasive\n",
    "\n",
    "2. **LLM evasion score** (RoBERTa-MNLI) uses entailment/neutral/contradiction between the question and answer\n",
    "- Lower entailment (and higher neutral + contradiction) = more evasive\n",
    "  \n",
    "3. **Blended evasion score** combines both scores including a weight for the LLM component\n",
    "- Rationale is that baseline enforces precision while the LLM will capture semantics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8372746",
   "metadata": {},
   "source": [
    "# **1. Set up Workspace**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "431bddd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# Core python\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any \n",
    "import csv\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "# NLP & Summarisation\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import transformers, datasets, inspect\n",
    "from llama_cpp import Llama \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Retrieval\n",
    "from sentence_transformers import SentenceTransformer \n",
    "\n",
    "# ML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score \n",
    "from sklearn.model_selection import GroupShuffleSplit \n",
    "\n",
    "# Visualisations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "# Set SEED.\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3d4ae2",
   "metadata": {},
   "source": [
    "# **2. Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "30edeb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>question_number</th>\n",
       "      <th>answer_number</th>\n",
       "      <th>speaker_name</th>\n",
       "      <th>role</th>\n",
       "      <th>company</th>\n",
       "      <th>content</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>is_pleasantry</th>\n",
       "      <th>source_pdf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>presentation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jeremy Barnum</td>\n",
       "      <td>Chief Financial Officer</td>\n",
       "      <td>JPMorganChase</td>\n",
       "      <td>Thanks, and good morning, everyone. The presen...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q1</td>\n",
       "      <td>False</td>\n",
       "      <td>data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Steven Chubak</td>\n",
       "      <td>analyst</td>\n",
       "      <td>Wolfe Research LLC</td>\n",
       "      <td>Hey, good morning.</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q1</td>\n",
       "      <td>True</td>\n",
       "      <td>data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jeremy Barnum</td>\n",
       "      <td>Chief Financial Officer</td>\n",
       "      <td>JPMorgan Chase &amp; Co.</td>\n",
       "      <td>Good morning, Steve.</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q1</td>\n",
       "      <td>True</td>\n",
       "      <td>data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Steven Chubak</td>\n",
       "      <td>analyst</td>\n",
       "      <td>Wolfe Research LLC</td>\n",
       "      <td>So, Jamie, I was actually hoping to get your p...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q1</td>\n",
       "      <td>False</td>\n",
       "      <td>data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Jamie Dimon</td>\n",
       "      <td>Chairman &amp; Chief Executive Officer</td>\n",
       "      <td>JPMorgan Chase &amp; Co.</td>\n",
       "      <td>Well, I think you were already kind of complet...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q1</td>\n",
       "      <td>False</td>\n",
       "      <td>data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        section  question_number  answer_number   speaker_name  \\\n",
       "0  presentation              NaN            NaN  Jeremy Barnum   \n",
       "1            qa              NaN            NaN  Steven Chubak   \n",
       "2            qa              NaN            NaN  Jeremy Barnum   \n",
       "3            qa              1.0            NaN  Steven Chubak   \n",
       "4            qa              1.0            1.0    Jamie Dimon   \n",
       "\n",
       "                                 role               company  \\\n",
       "0             Chief Financial Officer         JPMorganChase   \n",
       "1                             analyst    Wolfe Research LLC   \n",
       "2             Chief Financial Officer  JPMorgan Chase & Co.   \n",
       "3                             analyst    Wolfe Research LLC   \n",
       "4  Chairman & Chief Executive Officer  JPMorgan Chase & Co.   \n",
       "\n",
       "                                             content  year quarter  \\\n",
       "0  Thanks, and good morning, everyone. The presen...  2023      Q1   \n",
       "1                                 Hey, good morning.  2023      Q1   \n",
       "2                               Good morning, Steve.  2023      Q1   \n",
       "3  So, Jamie, I was actually hoping to get your p...  2023      Q1   \n",
       "4  Well, I think you were already kind of complet...  2023      Q1   \n",
       "\n",
       "   is_pleasantry                                         source_pdf  \n",
       "0          False  data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...  \n",
       "1           True  data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...  \n",
       "2           True  data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...  \n",
       "3          False  data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...  \n",
       "4          False  data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 1411\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "all_jpm_2023_2025 = pd.read_csv('../data/processed/jpm/all_jpm_2023_2025.csv')\n",
    "\n",
    "# View dataset.\n",
    "display(all_jpm_2023_2025.head())\n",
    "\n",
    "# Number of rows.\n",
    "print('Number of rows:', all_jpm_2023_2025.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e7647de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 1241\n"
     ]
    }
   ],
   "source": [
    "# Remove pleasantries.\n",
    "all_jpm_2023_2025_cleaned = all_jpm_2023_2025[all_jpm_2023_2025['is_pleasantry'] == False]\n",
    "print('Number of rows:', all_jpm_2023_2025_cleaned.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "39b9e01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with no content: 23\n"
     ]
    }
   ],
   "source": [
    "# Check content column.\n",
    "print('Number of rows with no content:', all_jpm_2023_2025_cleaned['content'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "31340c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with no content.\n",
    "all_jpm_2023_2025_cleaned = all_jpm_2023_2025_cleaned.dropna(subset=['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "35c042a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with no content: 0\n"
     ]
    }
   ],
   "source": [
    "# Check content column.\n",
    "print('Number of rows with no content:', all_jpm_2023_2025_cleaned['content'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2752faaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Chief Financial Officer', 'analyst',\n",
       "       'Chairman & Chief Executive Officer',\n",
       "       'And then some. Theres a lot of value added.', 'Okay',\n",
       "       \"We're fundamentally\", 'Thanks', 'Almost no chance.'], dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View roles.\n",
    "all_jpm_2023_2025_cleaned['role'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dc3188",
   "metadata": {},
   "source": [
    "- Some text has leaked into role column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ee0d690f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>question_number</th>\n",
       "      <th>answer_number</th>\n",
       "      <th>speaker_name</th>\n",
       "      <th>role</th>\n",
       "      <th>company</th>\n",
       "      <th>content</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>is_pleasantry</th>\n",
       "      <th>source_pdf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>qa</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Chief Financial Officer, JPMorganChase</td>\n",
       "      <td>And then some. Theres a lot of value added.</td>\n",
       "      <td>JPMorganChase</td>\n",
       "      <td>Yeah. And obviously, I mean, we're not going t...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q2</td>\n",
       "      <td>False</td>\n",
       "      <td>data/raw/jpm/.ipynb_checkpoints/jpm-2q25-earni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>qa</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Chief Financial Officer, JPMorganChase</td>\n",
       "      <td>Okay</td>\n",
       "      <td>there you have it.</td>\n",
       "      <td>But it's not like I thought it would do badly,...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q2</td>\n",
       "      <td>False</td>\n",
       "      <td>data/raw/jpm/.ipynb_checkpoints/jpm-2q25-earni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>qa</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Who knows how important politics are in all th...</td>\n",
       "      <td>We're fundamentally</td>\n",
       "      <td>as I said, I think on the press call, happy to...</td>\n",
       "      <td>little bit cautious about the pull-forward dyn...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Q1</td>\n",
       "      <td>False</td>\n",
       "      <td>data/raw/jpm/jpm-1q24-earnings-call-transcript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>qa</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Chief Financial Officer, JPMorgan Chase &amp; Co.</td>\n",
       "      <td>Thanks</td>\n",
       "      <td>Glenn.</td>\n",
       "      <td>Operator: Next, we'll go to the line of Matt O...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Q2</td>\n",
       "      <td>False</td>\n",
       "      <td>data/raw/jpm/jpm-2q24-earnings-call-transcript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>qa</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Chief Financial Officer, JPMorganChase</td>\n",
       "      <td>And then some. Theres a lot of value added.</td>\n",
       "      <td>JPMorganChase</td>\n",
       "      <td>Yeah. And obviously, I mean, we're not going t...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q2</td>\n",
       "      <td>False</td>\n",
       "      <td>data/raw/jpm/jpm-2q25-earnings-call-transcript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>qa</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Chief Financial Officer, JPMorganChase</td>\n",
       "      <td>Okay</td>\n",
       "      <td>there you have it.</td>\n",
       "      <td>But it's not like I thought it would do badly,...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q2</td>\n",
       "      <td>False</td>\n",
       "      <td>data/raw/jpm/jpm-2q25-earnings-call-transcript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>qa</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Chairman &amp; Chief Executive Officer, JPMorgan C...</td>\n",
       "      <td>Almost no chance.</td>\n",
       "      <td>JPMorganChase</td>\n",
       "      <td>Well, but having – it's very important. While ...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Q3</td>\n",
       "      <td>False</td>\n",
       "      <td>data/raw/jpm/jpm-3q24-earnings-conference-call...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     section  question_number  answer_number  \\\n",
       "305       qa             22.0            4.0   \n",
       "309       qa             23.0            3.0   \n",
       "650       qa             10.0            3.0   \n",
       "924       qa              8.0            2.0   \n",
       "1059      qa             22.0            4.0   \n",
       "1063      qa             23.0            3.0   \n",
       "1274      qa             23.0            1.0   \n",
       "\n",
       "                                           speaker_name  \\\n",
       "305              Chief Financial Officer, JPMorganChase   \n",
       "309              Chief Financial Officer, JPMorganChase   \n",
       "650   Who knows how important politics are in all th...   \n",
       "924       Chief Financial Officer, JPMorgan Chase & Co.   \n",
       "1059             Chief Financial Officer, JPMorganChase   \n",
       "1063             Chief Financial Officer, JPMorganChase   \n",
       "1274  Chairman & Chief Executive Officer, JPMorgan C...   \n",
       "\n",
       "                                             role  \\\n",
       "305   And then some. Theres a lot of value added.   \n",
       "309                                          Okay   \n",
       "650                           We're fundamentally   \n",
       "924                                        Thanks   \n",
       "1059  And then some. Theres a lot of value added.   \n",
       "1063                                         Okay   \n",
       "1274                            Almost no chance.   \n",
       "\n",
       "                                                company  \\\n",
       "305                                       JPMorganChase   \n",
       "309                                  there you have it.   \n",
       "650   as I said, I think on the press call, happy to...   \n",
       "924                                              Glenn.   \n",
       "1059                                      JPMorganChase   \n",
       "1063                                 there you have it.   \n",
       "1274                                      JPMorganChase   \n",
       "\n",
       "                                                content  year quarter  \\\n",
       "305   Yeah. And obviously, I mean, we're not going t...  2025      Q2   \n",
       "309   But it's not like I thought it would do badly,...  2025      Q2   \n",
       "650   little bit cautious about the pull-forward dyn...  2024      Q1   \n",
       "924   Operator: Next, we'll go to the line of Matt O...  2024      Q2   \n",
       "1059  Yeah. And obviously, I mean, we're not going t...  2025      Q2   \n",
       "1063  But it's not like I thought it would do badly,...  2025      Q2   \n",
       "1274  Well, but having – it's very important. While ...  2024      Q3   \n",
       "\n",
       "      is_pleasantry                                         source_pdf  \n",
       "305           False  data/raw/jpm/.ipynb_checkpoints/jpm-2q25-earni...  \n",
       "309           False  data/raw/jpm/.ipynb_checkpoints/jpm-2q25-earni...  \n",
       "650           False  data/raw/jpm/jpm-1q24-earnings-call-transcript...  \n",
       "924           False  data/raw/jpm/jpm-2q24-earnings-call-transcript...  \n",
       "1059          False  data/raw/jpm/jpm-2q25-earnings-call-transcript...  \n",
       "1063          False  data/raw/jpm/jpm-2q25-earnings-call-transcript...  \n",
       "1274          False  data/raw/jpm/jpm-3q24-earnings-conference-call...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View rows with invalid roles. \n",
    "valid_roles = 'analyst', 'Chief Financial Officer', 'Chairman & Chief Executive Officer'\n",
    "invalid_roles_df = all_jpm_2023_2025_cleaned[~all_jpm_2023_2025_cleaned['role'].isin(valid_roles)]\n",
    "invalid_roles_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c2103540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the correct role information.\n",
    "all_jpm_2023_2025_cleaned.loc[[305, 309, 924, 1059, 1063], 'role'] = 'Chief Financial Officer'\n",
    "all_jpm_2023_2025_cleaned.loc[[1274], 'role'] = 'Chairman & Chief Executive Officer'\n",
    "\n",
    "# Drop nonsence row.\n",
    "all_jpm_2023_2025_cleaned = all_jpm_2023_2025_cleaned.drop(index=650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b80ad9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Chief Financial Officer', 'analyst',\n",
       "       'Chairman & Chief Executive Officer'], dtype=object)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the roles have been updated.\n",
    "all_jpm_2023_2025_cleaned['role'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1ac15ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise role names.\n",
    "role_map = {\n",
    "    'analyst': 'analyst',\n",
    "    'Chief Financial Officer': 'banker',\n",
    "    'Chairman & Chief Executive Officer': 'banker'\n",
    "}\n",
    "\n",
    "# Map roles.\n",
    "all_jpm_2023_2025_cleaned['role_normalised'] = all_jpm_2023_2025_cleaned['role'].map(role_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "829a8e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>question_number</th>\n",
       "      <th>answer_number</th>\n",
       "      <th>speaker_name</th>\n",
       "      <th>role</th>\n",
       "      <th>company</th>\n",
       "      <th>content</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>is_pleasantry</th>\n",
       "      <th>source_pdf</th>\n",
       "      <th>role_normalised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>presentation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jeremy Barnum</td>\n",
       "      <td>Chief Financial Officer</td>\n",
       "      <td>JPMorganChase</td>\n",
       "      <td>Thanks, and good morning, everyone. The presen...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q1</td>\n",
       "      <td>False</td>\n",
       "      <td>data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...</td>\n",
       "      <td>banker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Steven Chubak</td>\n",
       "      <td>analyst</td>\n",
       "      <td>Wolfe Research LLC</td>\n",
       "      <td>So, Jamie, I was actually hoping to get your p...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q1</td>\n",
       "      <td>False</td>\n",
       "      <td>data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...</td>\n",
       "      <td>analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Jamie Dimon</td>\n",
       "      <td>Chairman &amp; Chief Executive Officer</td>\n",
       "      <td>JPMorgan Chase &amp; Co.</td>\n",
       "      <td>Well, I think you were already kind of complet...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q1</td>\n",
       "      <td>False</td>\n",
       "      <td>data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...</td>\n",
       "      <td>banker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>qa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Steven Chubak</td>\n",
       "      <td>analyst</td>\n",
       "      <td>Wolfe Research LLC</td>\n",
       "      <td>Got it. And just in terms of appetite for the ...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q1</td>\n",
       "      <td>False</td>\n",
       "      <td>data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...</td>\n",
       "      <td>analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>qa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Jamie Dimon</td>\n",
       "      <td>Chairman &amp; Chief Executive Officer</td>\n",
       "      <td>JPMorgan Chase &amp; Co.</td>\n",
       "      <td>Oh, yeah.</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q1</td>\n",
       "      <td>False</td>\n",
       "      <td>data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...</td>\n",
       "      <td>banker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        section  question_number  answer_number   speaker_name  \\\n",
       "0  presentation              NaN            NaN  Jeremy Barnum   \n",
       "3            qa              1.0            NaN  Steven Chubak   \n",
       "4            qa              1.0            1.0    Jamie Dimon   \n",
       "5            qa              1.0            1.0  Steven Chubak   \n",
       "6            qa              1.0            2.0    Jamie Dimon   \n",
       "\n",
       "                                 role               company  \\\n",
       "0             Chief Financial Officer         JPMorganChase   \n",
       "3                             analyst    Wolfe Research LLC   \n",
       "4  Chairman & Chief Executive Officer  JPMorgan Chase & Co.   \n",
       "5                             analyst    Wolfe Research LLC   \n",
       "6  Chairman & Chief Executive Officer  JPMorgan Chase & Co.   \n",
       "\n",
       "                                             content  year quarter  \\\n",
       "0  Thanks, and good morning, everyone. The presen...  2023      Q1   \n",
       "3  So, Jamie, I was actually hoping to get your p...  2023      Q1   \n",
       "4  Well, I think you were already kind of complet...  2023      Q1   \n",
       "5  Got it. And just in terms of appetite for the ...  2023      Q1   \n",
       "6                                          Oh, yeah.  2023      Q1   \n",
       "\n",
       "   is_pleasantry                                         source_pdf  \\\n",
       "0          False  data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...   \n",
       "3          False  data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...   \n",
       "4          False  data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...   \n",
       "5          False  data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...   \n",
       "6          False  data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...   \n",
       "\n",
       "  role_normalised  \n",
       "0          banker  \n",
       "3         analyst  \n",
       "4          banker  \n",
       "5         analyst  \n",
       "6          banker  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 1217\n"
     ]
    }
   ],
   "source": [
    "# View dataset.\n",
    "display(all_jpm_2023_2025_cleaned.head())\n",
    "print('Number of rows:', all_jpm_2023_2025_cleaned.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8054baa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned dataset.\n",
    "all_jpm_2023_2025_cleaned.to_csv('../data/processed/jpm/cleaned/all_jpm_2023_2025_cleaned') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d6934907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to remove duplicates within questions and answers. \n",
    "def clean_repeats(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "\n",
    "    # 1) Normalize whitespace\n",
    "    t = ' '.join(text.split()).strip()\n",
    "    if not t:\n",
    "        return t\n",
    "\n",
    "    # 2) If the whole-string is a back-to-back duplicate (A+A) = keep first half\n",
    "    mid = len(t) // 2\n",
    "    if len(t) % 2 == 0 and t[:mid] == t[mid:]:\n",
    "        t = t[:mid]\n",
    "\n",
    "    # 3) Collapse immediate repeated token spans (n-grams)\n",
    "    toks = t.split()\n",
    "    out = []\n",
    "    i = 0\n",
    "    while i < len(toks):\n",
    "        matched = False\n",
    "        max_span = min(50, len(toks) - i)  # cap span to remaining length\n",
    "        for n in range(max_span, 4, -1):  # try longer spans first: 50..5\n",
    "            if i + 2*n <= len(toks) and toks[i:i+n] == toks[i+n:i+2*n]:\n",
    "                out.extend(toks[i:i+n])  # keep one copy\n",
    "                i += 2*n                # skip the duplicate block\n",
    "                matched = True\n",
    "                break\n",
    "        if not matched:\n",
    "            out.append(toks[i])\n",
    "            i += 1\n",
    "    t = ' '.join(out)\n",
    "\n",
    "    # 4) Remove duplicate sentences globally (order-preserving)\n",
    "    sents = re.split(r'(?<=[.!?])\\s+', t)\n",
    "    seen = set()\n",
    "    uniq = []\n",
    "    for s in sents:\n",
    "        s_norm = s.strip()\n",
    "        if not s_norm:\n",
    "            continue\n",
    "        key = ' '.join(s_norm.lower().split())\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            uniq.append(s_norm)\n",
    "    return ' '.join(uniq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c551bb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert datasets into question and answer pairs.\n",
    "def create_qa_pairs(df, min_answer_words=30):\n",
    "    # Keep only the Q&A section.\n",
    "    qa_df = df[df['section'].astype(str).str.lower() == 'qa'].copy()\n",
    "\n",
    "    # Split into roles.\n",
    "    analyst_rows = qa_df[qa_df['role_normalised'] == 'analyst'].copy()\n",
    "    banker_rows  = qa_df[qa_df['role_normalised'] == 'banker' ].copy()\n",
    "\n",
    "    # Keys to keep quarters separated\n",
    "    key_q = ['year', 'quarter', 'question_number']\n",
    "\n",
    "    # Build full question text per (year, quarter, question_number)\n",
    "    question_text_map = (\n",
    "        analyst_rows\n",
    "        .groupby(key_q, dropna=False)['content']\n",
    "        .apply(lambda parts: clean_repeats(' '.join(parts.astype(str))))\n",
    "        .rename('question')\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Ensure bankers have an answer_number — sequential per (year, quarter, question_number) if missing\n",
    "    if 'answer_number' not in banker_rows.columns or banker_rows['answer_number'].isna().any():\n",
    "        banker_rows = banker_rows.sort_index().copy()\n",
    "        banker_rows['answer_number'] = (\n",
    "            banker_rows\n",
    "            .groupby(key_q, dropna=False)\n",
    "            .cumcount() + 1\n",
    "        )\n",
    "\n",
    "    # Combine multiple banker utterances belonging to the same answer\n",
    "    banker_answers = (\n",
    "        banker_rows\n",
    "        .groupby(key_q + ['answer_number'], dropna=False)\n",
    "        .agg({\n",
    "            'content':        lambda parts: clean_repeats(' '.join(parts.astype(str))),\n",
    "            'speaker_name':   'first',\n",
    "            'role':           'first',\n",
    "            'role_normalised':'first',\n",
    "            'source_pdf':     'first'\n",
    "        })\n",
    "        .rename(columns={'content': 'answer'})\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Merge question text back onto each answer row\n",
    "    qa_pairs = banker_answers.merge(\n",
    "        question_text_map,\n",
    "        on=key_q,\n",
    "        how='left',\n",
    "        validate='many_to_one'\n",
    "    )\n",
    "\n",
    "    # Order columns for readability\n",
    "    column_order = [\n",
    "        'year', 'quarter', 'question_number', 'answer_number',\n",
    "        'question', 'answer',\n",
    "        'speaker_name', 'role', 'role_normalised',\n",
    "        'source_pdf'\n",
    "    ]\n",
    "    qa_pairs = qa_pairs.reindex(columns=[c for c in column_order if c in qa_pairs.columns])\n",
    "\n",
    "    # Sort and reset index.\n",
    "    qa_pairs = qa_pairs.sort_values(['year', 'quarter', 'question_number', 'answer_number']).reset_index(drop=True)\n",
    "\n",
    "    # Drop duplicate answers.\n",
    "    qa_pairs = qa_pairs.drop_duplicates(subset=['answer'])\n",
    "\n",
    "    # Drop short answers below threshold to ensure quality answers.\n",
    "    qa_pairs = qa_pairs[qa_pairs['answer'].astype(str).str.split().str.len() >= int(min_answer_words)]\n",
    "\n",
    "    return qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c8425a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create q&A pairs.\n",
    "all_jpm_2023_2025_qa = create_qa_pairs(all_jpm_2023_2025_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "03b82548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 309\n"
     ]
    }
   ],
   "source": [
    "# View number of examples.\n",
    "print('Number of examples:', all_jpm_2023_2025_qa.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e070042f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into prediction set and validation/training/test set.\n",
    "jpm_2025_predict_qa = all_jpm_2023_2025_qa[all_jpm_2023_2025_qa['year'] == 2025]\n",
    "jpm_2023_2024_qa = all_jpm_2023_2025_qa[all_jpm_2023_2025_qa['year'].isin([2023, 2024])]\n",
    "\n",
    "# Save the datasets.\n",
    "jpm_2025_predict_qa.to_csv('../data/processed/jpm/cleaned/jpm_2025_predict_qa.csv') \n",
    "jpm_2023_2024_qa.to_csv('../data/processed/jpm/cleaned/jpm_2023_2024_qa.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15c481b",
   "metadata": {},
   "source": [
    "The jpm_2023_2024_qa dataset was then manually labelled according to whether the banker's answer was deemed 'Direct' or 'Evasive'. The label was appended by a new column 'label'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fa178cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>question_number</th>\n",
       "      <th>answer_number</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>speaker_name</th>\n",
       "      <th>role</th>\n",
       "      <th>role_normalised</th>\n",
       "      <th>source_pdf</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>Q4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Good morning. Thanks for all the comments on t...</td>\n",
       "      <td>Yeah. Matt, not particularly updating. I think...</td>\n",
       "      <td>Jeremy Barnum</td>\n",
       "      <td>Chief Financial Officer</td>\n",
       "      <td>banker</td>\n",
       "      <td>data/raw/jpm/jpm-4q23-earnings-call-transcript...</td>\n",
       "      <td>Direct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>Q4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Okay. And then just separately, you bought bac...</td>\n",
       "      <td>Yeah. Good question. And I think you framed it...</td>\n",
       "      <td>Jeremy Barnum</td>\n",
       "      <td>Chief Financial Officer</td>\n",
       "      <td>banker</td>\n",
       "      <td>data/raw/jpm/jpm-4q23-earnings-call-transcript...</td>\n",
       "      <td>Direct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>Q4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Thanks. Jeremy, could you give a little more c...</td>\n",
       "      <td>Yeah. Actually, John, this quarter, that's all...</td>\n",
       "      <td>Jeremy Barnum</td>\n",
       "      <td>Chief Financial Officer</td>\n",
       "      <td>banker</td>\n",
       "      <td>data/raw/jpm/jpm-4q23-earnings-call-transcript...</td>\n",
       "      <td>Direct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>Q4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Okay. And then, just to follow up on the NII, ...</td>\n",
       "      <td>Sure. Yeah, happy to do that, John. So, I thin...</td>\n",
       "      <td>Jeremy Barnum</td>\n",
       "      <td>Chief Financial Officer</td>\n",
       "      <td>banker</td>\n",
       "      <td>data/raw/jpm/jpm-4q23-earnings-call-transcript...</td>\n",
       "      <td>Direct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>Q4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hey. Good morning. Maybe just to follow up in ...</td>\n",
       "      <td>Yeah. Both good questions. So let's do reprice...</td>\n",
       "      <td>Jeremy Barnum</td>\n",
       "      <td>Chief Financial Officer</td>\n",
       "      <td>banker</td>\n",
       "      <td>data/raw/jpm/jpm-4q23-earnings-call-transcript...</td>\n",
       "      <td>Direct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year quarter  question_number  answer_number  \\\n",
       "0  2023      Q4              1.0            1.0   \n",
       "1  2023      Q4              2.0            1.0   \n",
       "2  2023      Q4              3.0            1.0   \n",
       "3  2023      Q4              4.0            1.0   \n",
       "4  2023      Q4              5.0            1.0   \n",
       "\n",
       "                                            question  \\\n",
       "0  Good morning. Thanks for all the comments on t...   \n",
       "1  Okay. And then just separately, you bought bac...   \n",
       "2  Thanks. Jeremy, could you give a little more c...   \n",
       "3  Okay. And then, just to follow up on the NII, ...   \n",
       "4  Hey. Good morning. Maybe just to follow up in ...   \n",
       "\n",
       "                                              answer   speaker_name  \\\n",
       "0  Yeah. Matt, not particularly updating. I think...  Jeremy Barnum   \n",
       "1  Yeah. Good question. And I think you framed it...  Jeremy Barnum   \n",
       "2  Yeah. Actually, John, this quarter, that's all...  Jeremy Barnum   \n",
       "3  Sure. Yeah, happy to do that, John. So, I thin...  Jeremy Barnum   \n",
       "4  Yeah. Both good questions. So let's do reprice...  Jeremy Barnum   \n",
       "\n",
       "                      role role_normalised  \\\n",
       "0  Chief Financial Officer          banker   \n",
       "1  Chief Financial Officer          banker   \n",
       "2  Chief Financial Officer          banker   \n",
       "3  Chief Financial Officer          banker   \n",
       "4  Chief Financial Officer          banker   \n",
       "\n",
       "                                          source_pdf   label  \n",
       "0  data/raw/jpm/jpm-4q23-earnings-call-transcript...  Direct  \n",
       "1  data/raw/jpm/jpm-4q23-earnings-call-transcript...  Direct  \n",
       "2  data/raw/jpm/jpm-4q23-earnings-call-transcript...  Direct  \n",
       "3  data/raw/jpm/jpm-4q23-earnings-call-transcript...  Direct  \n",
       "4  data/raw/jpm/jpm-4q23-earnings-call-transcript...  Direct  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the labelled dataset.\n",
    "jpm_2023_2024_qa_labelled = pd.read_csv('../data/processed/jpm/cleaned/jpm_2023_2024_qa_labelled.csv')\n",
    "\n",
    "# View the dataset.\n",
    "jpm_2023_2024_qa_labelled = jpm_2023_2024_qa_labelled.drop('Unnamed: 0', axis=1)\n",
    "jpm_2023_2024_qa_labelled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4a43aa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split into test, training and validation datasets, preserve number of evasive cases per set.\n",
    "def train_val_test(df, group_key, test_fraction, val_fraction, random_state):\n",
    "\n",
    "    # Split test from full data.\n",
    "    gss1 = GroupShuffleSplit(n_splits=1, test_size=test_fraction, random_state=random_state)\n",
    "    idx_trainval, idx_test = next(gss1.split(df, groups=df[group_key]))\n",
    "    train_and_val = df.iloc[idx_trainval].reset_index(drop=True)\n",
    "    test_set = df.iloc[idx_test].reset_index(drop=True)\n",
    "\n",
    "    # Split VAL from the remaining data (val is relative to full size)\n",
    "    val_fraction_of_remaining = val_fraction / (1.0 - test_fraction)\n",
    "    gss2 = GroupShuffleSplit(n_splits=1, test_size=val_fraction_of_remaining, random_state=random_state + 1)\n",
    "    idx_train, idx_val = next(gss2.split(train_and_val, groups=train_and_val[group_key]))\n",
    "    train_set = train_and_val.iloc[idx_train].reset_index(drop=True)\n",
    "    val_set = train_and_val.iloc[idx_val].reset_index(drop=True)\n",
    "\n",
    "    return train_set, val_set, test_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f8ba04bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a group key so answers for the same question are not split between datasets.\n",
    "jpm_2023_2024_qa_labelled['group_key'] = (\n",
    "    jpm_2023_2024_qa_labelled[\"year\"].astype(str) + \"_\" +\n",
    "    jpm_2023_2024_qa_labelled[\"quarter\"].astype(str) + \"_\" +\n",
    "    jpm_2023_2024_qa_labelled[\"question_number\"].astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2d87dc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into test, training and validation datasets.\n",
    "jpm_train, jpm_val, jpm_test = train_val_test(\n",
    "    jpm_2023_2024_qa_labelled,\n",
    "    group_key='group_key',\n",
    "    test_fraction=0.30,\n",
    "    val_fraction=0.20,\n",
    "    random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2cf10685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 107 (evasive: 22)\n",
      "Number of validation examples: 43 (evasive: 11)\n",
      "Number of test examples: 65 (evasive: 9)\n"
     ]
    }
   ],
   "source": [
    "# View the split. \n",
    "print(f'Number of training examples: {jpm_train.shape[0]} (evasive: {jpm_train[jpm_train[\"label\"] == \"Evasive\"].shape[0]})')\n",
    "print(f'Number of validation examples: {jpm_val.shape[0]} (evasive: {jpm_val[jpm_val[\"label\"] == \"Evasive\"].shape[0]})')\n",
    "print(f'Number of test examples: {jpm_test.shape[0]} (evasive: {jpm_test[jpm_test[\"label\"] == \"Evasive\"].shape[0]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0adfe513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the datasets.\n",
    "jpm_train.to_csv('../data/processed/jpm/cleaned/jpm_train.csv') \n",
    "jpm_val.to_csv('../data/processed/jpm/cleaned/jpm_val.csv') \n",
    "jpm_test.to_csv('../data/processed/jpm/cleaned/jpm_test.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cd7965",
   "metadata": {},
   "source": [
    "# **3. Rule-based Baseline**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3698b7be",
   "metadata": {},
   "source": [
    "## **3.1 Set-up**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f012907c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of evasive phrases\n",
    "EVASIVE_PHRASES = [\n",
    "    r\"\\btoo early\\b\",\n",
    "    r\"\\bcan't (?:comment|share|discuss)\\b\",\n",
    "    r\"\\bwon't (?:comment|share|provide)\\b\",\n",
    "    r\"\\bno (?:update|comment)\\b\",\n",
    "    r\"\\bwe (?:don't|do not) (?:break out|provide guidance)\\b\",\n",
    "    r\"\\bnot (?:going to|able to) (?:comment|share|provide)\\b\",\n",
    "    r\"\\bwe'll (?:come back|circle back)\\b\",\n",
    "    r\"\\bnot something we disclose\\b\",\n",
    "    r\"\\bas (?:we|I) (?:said|mentioned)\\b\",\n",
    "    r\"\\bgenerally speaking\\b\",\n",
    "    r\"\\bit's premature\\b\",\n",
    "    r\"\\bit's difficult to say\\b\",\n",
    "    r\"\\bI (?:wouldn't|won't) want to (?:speculate|get into)\\b\",\n",
    "    r\"\\bI (?:think|guess|suppose)\\b\",\n",
    "    r\"\\bkind of\\b\",\n",
    "    r\"\\bsort of\\b\",\n",
    "    r\"\\baround\\b\",\n",
    "    r\"\\broughly\\b\",\n",
    "    r\"\\bwe (?:prefer|plan) not to\\b\",\n",
    "    r\"\\bwe're not prepared to\\b\",\n",
    "]\n",
    "\n",
    "# List of words that suggest the answer needs specific financial numbers to properly answer the question.\n",
    "SPECIFICITY_TRIGGERS = [\n",
    "    \"how much\",\"how many\",\"what is\",\"what are\",\"when\",\"which\",\"where\",\"who\",\"why\",\n",
    "    \"range\",\"guidance\",\"margin\",\"capex\",\"opex\",\"revenue\",\"sales\",\"eps\",\"ebitda\",\n",
    "    \"timeline\",\"date\",\"target\",\"growth\",\"update\",\"split\",\"dividend\",\"cost\",\"price\",\n",
    "    \"units\",\"volumes\",\"gross\",\"net\",\"tax\",\"percentage\",\"utilization\",\"order book\"\n",
    "]\n",
    "\n",
    "NUMERIC_PATTERN = r\"(?:\\d+(?:\\.\\d+)?%|\\b\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?\\b|£|\\$|€)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4585b1",
   "metadata": {},
   "source": [
    "## **3.2 Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59f8212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate cosine similarity between question and answers.\n",
    "def cosine_sim(q, a):\n",
    "    vec = TfidfVectorizer(stop_words='english').fit_transform([q, a]) # converts text to vectors \n",
    "    sim = float(cosine_similarity(vec[0], vec[1])[0, 0]) # calculate the cosine similarity between the two vectors\n",
    "\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38d819de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute baseline evasion score.\n",
    "def baseline_evasion_score(q, a):\n",
    "    # 1. Cosine similarity\n",
    "    sim = cosine_sim(q, a) # calculates cosine similarity using previous function\n",
    "    sim_component = (1 - sim) * 45 # less similar the answer is, the bigger the contribution to the evasion score, scaled by 45\n",
    "\n",
    "    # 2. Numerical specificity- Does the question require and answer with financial figures/ a specific answer?\n",
    "    needs_num = any(t in q.lower() for t in SPECIFICITY_TRIGGERS) # true if the question requires a numeric/ specific answer\n",
    "    has_num = bool(re.search(NUMERIC_PATTERN, a)) # true if the answer includes a number \n",
    "    numeric_component = 25 if needs_num and not has_num else 0 # score of 25 if the question needs a number but the answer doesn't give one\n",
    "\n",
    "    # 3. Evasive phrases- does the answer contain evasive phrases?\n",
    "    phrase_hits = sum(len(re.findall(p, a.lower())) for p in EVASIVE_PHRASES) # counts how many times an evasive phrase appears in the answer\n",
    "    phrase_component = min(3, phrase_hits) * 8 # max of 3 hits counted, each hit = 8 points \n",
    "\n",
    "    # Final evasion score.\n",
    "    score = min(100, sim_component + numeric_component + phrase_component) # adds components together and caps score at 100\n",
    "    \n",
    "    return score, sim, phrase_hits, needs_num, has_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c25ce77",
   "metadata": {},
   "source": [
    "# **4. LLM**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2afef3",
   "metadata": {},
   "source": [
    "## **4.1 Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f09efe1",
   "metadata": {},
   "source": [
    "Small, lightweight models were selected for this to prevent memory overload and long training times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de25a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base save directory.\n",
    "BASE_SAVE_DIR = \"/Users/laurenbrixey/Documents/Data Science Career Accelerator/EP Model Training\"\n",
    "os.makedirs(BASE_SAVE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952d444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model names.\n",
    "distil_roberta_name = 'distilroberta-base'\n",
    "deberta_name = 'microsoft/deberta-v3-small'\n",
    "\n",
    "# Tokenizers.\n",
    "distil_roberta_tok = AutoTokenizer.from_pretrained(distil_roberta_name)\n",
    "deberta_tok = AutoTokenizer.from_pretrained (deberta_name)\n",
    "\n",
    "# Models with binary heads.\n",
    "distil_roberta_model = AutoModelForSequenceClassification.from_pretrained(distil_roberta_name, num_labels=2)\n",
    "deberta_model = AutoModelForSequenceClassification.from_pretrained(deberta_model, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4845a810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device set-up\n",
    "use_mps = torch.backends.mps.is_available()\n",
    "device = torch.device('mps' if use_mps else ('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "os.environment['PYTORCH_ENABLE_MPS_FALLBACK'] = 1\n",
    "\n",
    "distil_roberta_model.to(device)\n",
    "deberta_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2602416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build the premise from the Q&A transcripts \n",
    "def build_premise(q, a):\n",
    "    return f'[QUESTION] {q} [ANSWER] {a}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e71fa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset wrapper.\n",
    "class EvasionDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=512):\n",
    "        \n",
    "        # columns = question, answer, label (direct/evasive)\n",
    "        texts = [build_premise(q, a) for q, a in zip(df['question'].astype(str), df['answer'].astype.(str))]\n",
    "        self.enc = tokenizer(texts, truncation=True, padding=True, max_length=max_length)\n",
    "\n",
    "        # map labels (evasion=1, direct=0)\n",
    "        self.labels = (df['label'].astype(str).str.strip().str.lower() == 'evasive').astype(int).tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.items()}\n",
    "        item['label'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432287ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build datasets.\n",
    "distil_roberta_train = EvasionDataset(jpm_train, distil_roberta_tok)\n",
    "distil_roberta_val = EvasionDataset(jpm_val, distil_roberta_tok)\n",
    "\n",
    "deberta_train = EvasionDataset(jpm_train, deberta_tok)\n",
    "deberta_val = EvasionDataset(jpm_val, deberta_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5764f31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model save paths.\n",
    "DISTIL_SAVE_DIR  = os.path.join(BASE_SAVE_DIR, \"distil_roberta_tuned\")\n",
    "DEBERTA_SAVE_DIR = os.path.join(BASE_SAVE_DIR, \"deberta_small_tuned\")\n",
    "os.makedirs(DISTIL_SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(DEBERTA_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Distil-roberta training parameters.\n",
    "distil_roberta_args = TrainingArguments(\n",
    "    output_dir=DISTIL_SAVE_DIR,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    logging_steps=50,\n",
    "    report_to=[],\n",
    "    dataloader_pin_memory=False,\n",
    "    gradient_accumulation_steps=1,\n",
    "    fp16=False,\n",
    "    bf16=False\n",
    ")\n",
    "\n",
    "# Deberta training parameters.\n",
    "deberta_args = TrainingArguments(\n",
    "    output_dir=DEBERTA_SAVE_DIR,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    logging_steps=50,\n",
    "    report_to=[],\n",
    "    dataloader_pin_memory=False,\n",
    "    gradient_accumulation_steps=1,\n",
    "    fp16=False,\n",
    "    bf16=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53799a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute metrics during training.\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = (logits[:,1] > logits[:,0].astype(int))\n",
    "    return {'acc': (preds == labels).mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a59e455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distil-roberta model trainer.\n",
    "distil_roberta_trainer = Trainer(\n",
    "    model=distil_roberta_model,\n",
    "    args=distil_roberta_args,\n",
    "    train_dataset=distil_roberta_train,\n",
    "    eval_dataset=distil_roberta_val,\n",
    "    tokenizer=distil_roberta_tok,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train distil_roberta.\n",
    "distil_roberta_trainer.train()\n",
    "\n",
    "# Save the tuned model.\n",
    "distil_roberta_trainer.save_model(DISTIL_SAVE_DIR)\n",
    "\n",
    "# Deberta model trainer.\n",
    "deberta_trainer = Trainer(\n",
    "    model=deberta_model,\n",
    "    args=deberta_args,\n",
    "    train_dataset=deberta_train,\n",
    "    eval_dataset=deberta_val,\n",
    "    tokenizer=deberta_tok,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train deberta.\n",
    "deberta_trainer.train()\n",
    "\n",
    "# Save the tuned models.\n",
    "deberta_trainer.save_model(DEBERTA_SAVE_DIR)\n",
    "\n",
    "# Reload the best models.\n",
    "distil_roberta_model  = AutoModelForSequenceClassification.from_pretrained(DISTIL_SAVE_DIR).to(device).eval()\n",
    "deberta_model = AutoModelForSequenceClassification.from_pretrained(DEBERTA_SAVE_DIR).to(device).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f90ed9f",
   "metadata": {},
   "source": [
    "## **4.2 Functions for pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80af43fd",
   "metadata": {},
   "source": [
    "# **5. Evasion Detection Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac468677",
   "metadata": {},
   "source": [
    "## **5.1 Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345f4908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to label 'Direct' or 'Evasive' based on the score.\n",
    "def label_from_score(score, threshold):\n",
    "    return 'Evasive' if score >= threshold else 'Direct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4555b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract ground truth (1 = Evasive, 0 = Direct)\n",
    "def extract_y_true(df):\n",
    "    return (df['label'].astype(str).str.strip().str.lower() == 'evasive').astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cba814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the logits margin.\n",
    "def compute_logits_margin(model, tokenizer, df, batch_size=32, max_length=512):\n",
    "    model.eval()\n",
    "    margins = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(df), batch_size):\n",
    "            b = df.iloc[i:i+batch_size]\n",
    "            texts = [build_premise(q, a) for q, a in zip(b['question'].astype(str), b['answer'].astype(str))]\n",
    "            enc = tokenizer(texts, truncation=True, padding=True, max_length=max_length, return_tensors='pt')\n",
    "            enc = {k: v.to(device) for k, v in enc.items()}\n",
    "            out = model(**enc).logits  # [B,2]\n",
    "            margins.extend((out[:,1] - out[:,0]).detach().cpu().numpy().tolist())\n",
    "    return np.array(margins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5871f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_evasion_score(question, answer, model, tokenizer, platt_model, max_length=512):\n",
    "    text = build_premise(question, answer)\n",
    "    enc = tokenizer(text, truncation=True, padding=True, max_length=max_length, return_tensors='pt')\n",
    "    enc = {k: v.to(device) for k, v in enc.items()}\n",
    "    with torch.no_grad():\n",
    "        logits = model(**enc).logits.squeeze(0)  # [2]\n",
    "    margin = float((logits[1] - logits[0]).detach().cpu().numpy())\n",
    "    p_ev = float(platt_model.predict_proba([[margin]])[0,1])\n",
    "    return {'p_evasive': p_ev, 'p_direct': 1.0 - p_ev}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6507595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute blended evasion score and return all scores.\n",
    "def compute_all_evasion_scores(q, a, *, models_and_tokenizers, device, LLM_WEIGHT=0.30):\n",
    "    \n",
    "    # Compute baseline evasion score.\n",
    "    base_score, _, _, _, _ = baseline_evasion_score(q, a)\n",
    "\n",
    "    # Individual LLM scores.\n",
    "    llm_scores = {}\n",
    "    for key, (_, m, t, platt) in models_and_tokenizers.items():\n",
    "        scores = llm_evasion_score(q, a, m, t, platt)\n",
    "        llm_scores[key] = float(100.0 * scores['p_evasive'])\n",
    "\n",
    "    # Ensemble LLM score.\n",
    "    llm_avg = float(np.mean(list(llm_scores.values()))) if llm_scores else 0.0\n",
    "\n",
    "    # Compute blended score.\n",
    "    blended_score = float(np.clip((1.0 - LLM_WEIGHT) * base_score + LLM_WEIGHT * llm_avg, 0.0, 100.0))\n",
    "\n",
    "    return {\n",
    "        'baseline': base_score,\n",
    "        'llm_individual': llm_scores,\n",
    "        'llm_avg': llm_avg,\n",
    "        'blended': blended_score\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607eb637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main evasion Pipeline\n",
    "def evasion_pipeline(df, models_and_tokenizers, device, LLM_WEIGHT, EVASION_THRESHOLD_BASE, EVASION_THRESHOLD_LLM, EVASION_THRESHOLD_BLENDED):\n",
    "    records = []\n",
    "    for _, row in df.iterrows():\n",
    "        q, a = str(row['question']), str(row['answer'])\n",
    "        out = compute_all_evasion_scores(q=q, a=a, LLM_WEIGHT=LLM_WEIGHT, models_and_tokenizers=models_and_tokenizers, device=device)\n",
    "\n",
    "        rec = {\n",
    "            'question_number': row.get('question_number'),\n",
    "            'question': q, 'answer': a,\n",
    "            'evasion_score_baseline': int(out['baseline']),\n",
    "            'evasion_score_llm_avg': int(out['llm_avg']),\n",
    "            'evasion_score_blended': int(out['blended']),\n",
    "            'prediction_baseline': label_from_score(out['baseline'], EVASION_THRESHOLD_BASE),\n",
    "            'prediction_llm_avg': label_from_score(out['llm_avg'], EVASION_THRESHOLD_LLM),\n",
    "            'prediction_blended': label_from_score(out['blended'], EVASION_THRESHOLD_BLENDED),\n",
    "        }\n",
    "        # add individual models dynamically\n",
    "        for model_name, score in out['llm_individual'].items():\n",
    "            rec[f'evasion_score_{model_name}'] = int(score)\n",
    "            rec[f'prediction_{model_name}'] = label_from_score(score, EVASION_THRESHOLD_LLM)\n",
    "\n",
    "        records.append(rec)\n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc58f2c8",
   "metadata": {},
   "source": [
    "## **5.2 Threshold Tuning & Model Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed308658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrate LLM labelling threshold on validation set.\n",
    "y_val = extract_y_true(jpm_val)\n",
    "\n",
    "distil_roberta_val_margins = compute_logits_margin(distil_roberta_model, distil_roberta_tok, jpm_val)\n",
    "deberta_val_margins = compute_logits_margin(deberta_model, deberta_tok, jpm_val)\n",
    "\n",
    "distil_roberta_platt = LogisticRegression(solver='lbfgs').fit(distil_roberta_val_margins.reshape(1, -1), y_val)\n",
    "derberta_platt = LogisticRegression(solver='lbfgs').fit(deberta_val_margins.reshape(1, -1), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99783b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models.\n",
    "models_and_tokenizers = {\n",
    "    'distil_roberta': ('distil_roberta', distil_roberta_model, distil_roberta_tok, distil_roberta_platt)\n",
    "    'deberta': ('deberta', deberta_model, deberta_tok, deberta_platt)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a95702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fine tune the threshold \n",
    "def tune_threshold(df, score_col, thr_grid):\n",
    "    y_true = extract_y_true(df)\n",
    "    scores = df[score_col].astype(float).values\n",
    "    rows = []\n",
    "    for thr in thr_grid:\n",
    "        y_pred = (scores >= thr).astype(int)\n",
    "        rows.append({\n",
    "            'threshold': float(thr),\n",
    "            'precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "            'recall':    recall_score(y_true, y_pred, zero_division=0),\n",
    "            'f1':        f1_score(y_true, y_pred, zero_division=0),\n",
    "            'accuracy':  accuracy_score(y_true, y_pred)\n",
    "        })\n",
    "    return pd.DataFrame(rows).sort_values(by=['f1','recall'], ascending=[False, False]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c091eaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform an initial run with preliminary threshold values.\n",
    "LLM_WEIGHT = 0.30\n",
    "EVASION_THRESHOLD_BASE = 30.0\n",
    "EVASION_THRESHOLD_LLM = 30.0\n",
    "EVASION_THRESHOLD_BLENDED = 30.0\n",
    "\n",
    "jpm_val_scores = evasion_pipeline(\n",
    "    jpm_val, \n",
    "    models_and_tokenizers, \n",
    "    device, \n",
    "    LLM_WEIGHT, \n",
    "    EVASION_THRESHOLD_BASE, \n",
    "    EVASION_THRESHOLD_LLM, \n",
    "    EVASION_THRESHOLD_BLENDED\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428fc79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the results and reappend the label.\n",
    "jpm_val_scores['label'] = jpm_val_qa_labelled['label'].values\n",
    "jpm_val_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c87a4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define threshold grid.\n",
    "thr_grid = np.arange(30, 85, 5)\n",
    "\n",
    "# Tune all thresholds.\n",
    "base_results = tune_threshold(jpm_val_scores, 'evasion_score_baseline', thr_grid)\n",
    "llm_avg_results = tune_threshold(jpm_val_scores, 'evasion_score_llm_avg', thr_grid)\n",
    "blend_results = tune_threshold(jpm_val_scores, 'evasion_score_blended', thr_grid)\n",
    "\n",
    "best_base_thr    = float(base_results.loc[0, 'threshold'])\n",
    "best_llm_avg_thr = float(llm_avg_results.loc[0, 'threshold'])\n",
    "best_blend_thr   = float(blend_results.loc[0, 'threshold'])\n",
    "best_model_thrs  = {k: float(v.loc[0, 'threshold']) for k, v in per_model_results.items()}\n",
    "\n",
    "print(\"=== Best thresholds (VAL) ===\")\n",
    "print(\"Baseline:\", best_base_thr)\n",
    "print(\"LLM Avg:\", best_llm_avg_thr)\n",
    "print(\"Blended:\", best_blend_thr)\n",
    "for k, thr in best_model_thrs.items():\n",
    "    print(f\"{k}: {thr}\")\n",
    "\n",
    "# View top configs. \n",
    "print(\"\\nTop 5 baseline:\\n\", base_results.head())\n",
    "print(\"\\nTop 5 llm_avg:\\n\", llm_avg_results.head())\n",
    "print(\"\\nTop 5 blended:\\n\", blend_results.head())\n",
    "for k, dfres in per_model_results.items():\n",
    "    print(f\"\\nTop 5 {k}:\\n\", dfres.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c08171",
   "metadata": {},
   "source": [
    "## **5.2 Optimised Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725ef6c7",
   "metadata": {},
   "source": [
    "## **5.3 2025 Predictions**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-evasion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
