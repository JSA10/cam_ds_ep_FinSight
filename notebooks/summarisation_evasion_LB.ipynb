{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b820ac6",
   "metadata": {},
   "source": [
    "# **Summarisation & Evasion Notebook (LB)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79cb78c",
   "metadata": {},
   "source": [
    "# **1. Objective**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538b76a8",
   "metadata": {},
   "source": [
    "- Summarise banker answers into short, PRA relevant insights.\n",
    "- Generate an evasion score to tag summaries.\n",
    "- RAG pipeline to bring in relevant external documents (e.g. PRA risk definitions, regulatory news).\n",
    "- Optional extension: validate flagged risks with external/regulatory news."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94670282",
   "metadata": {},
   "source": [
    "# **2. Set up Workspace**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f5f5884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# Core python\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any \n",
    "import csv\n",
    "\n",
    "# NLP & Summarisation\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import nltk\n",
    "import spacy\n",
    "from llama_cpp import Llama \n",
    "\n",
    "# Evaluation\n",
    "from rouge_score import rouge_scorer\n",
    "import evaluate\n",
    "from bert_score import score as bertscore \n",
    "\n",
    "# Retrieval\n",
    "from sentence_transformers import SentenceTransformer \n",
    "import faiss\n",
    "import chromadb\n",
    "import langchain\n",
    "import llama_index\n",
    "\n",
    "# ML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Visualisations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b91bb8c",
   "metadata": {},
   "source": [
    "# **3. Load the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "743f6bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_number</th>\n",
       "      <th>answer_number</th>\n",
       "      <th>speaker_name</th>\n",
       "      <th>role</th>\n",
       "      <th>company</th>\n",
       "      <th>content</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>source_pdf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ken Usdin</td>\n",
       "      <td>analyst</td>\n",
       "      <td>Autonomous Research</td>\n",
       "      <td>Good morning, Jeremy. Wondering if you could s...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q1</td>\n",
       "      <td>data/raw/jpm/jpm-1q25-earnings-call-transcript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Jeremy Barnum</td>\n",
       "      <td>Chief Financial Officer</td>\n",
       "      <td>JPMorganChase</td>\n",
       "      <td>Sure, Ken. So I mean, at a high level, I would...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q1</td>\n",
       "      <td>data/raw/jpm/jpm-1q25-earnings-call-transcript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ken Usdin</td>\n",
       "      <td>analyst</td>\n",
       "      <td>Autonomous Research</td>\n",
       "      <td>Yeah. And just one question on the NII ex. Mar...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q1</td>\n",
       "      <td>data/raw/jpm/jpm-1q25-earnings-call-transcript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Jeremy Barnum</td>\n",
       "      <td>Chief Financial Officer</td>\n",
       "      <td>JPMorganChase</td>\n",
       "      <td>Yeah, that's a good question, Ken. You're righ...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q1</td>\n",
       "      <td>data/raw/jpm/jpm-1q25-earnings-call-transcript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Jamie Dimon</td>\n",
       "      <td>Chairman &amp; Chief Executive Officer</td>\n",
       "      <td>JPMorganChase</td>\n",
       "      <td>In the curve basically.</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q1</td>\n",
       "      <td>data/raw/jpm/jpm-1q25-earnings-call-transcript...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_number  answer_number   speaker_name  \\\n",
       "0                1            NaN      Ken Usdin   \n",
       "1                1            1.0  Jeremy Barnum   \n",
       "2                2            NaN      Ken Usdin   \n",
       "3                2            1.0  Jeremy Barnum   \n",
       "4                2            2.0    Jamie Dimon   \n",
       "\n",
       "                                 role              company  \\\n",
       "0                             analyst  Autonomous Research   \n",
       "1             Chief Financial Officer        JPMorganChase   \n",
       "2                             analyst  Autonomous Research   \n",
       "3             Chief Financial Officer        JPMorganChase   \n",
       "4  Chairman & Chief Executive Officer        JPMorganChase   \n",
       "\n",
       "                                             content  year quarter  \\\n",
       "0  Good morning, Jeremy. Wondering if you could s...  2025      Q1   \n",
       "1  Sure, Ken. So I mean, at a high level, I would...  2025      Q1   \n",
       "2  Yeah. And just one question on the NII ex. Mar...  2025      Q1   \n",
       "3  Yeah, that's a good question, Ken. You're righ...  2025      Q1   \n",
       "4                            In the curve basically.  2025      Q1   \n",
       "\n",
       "                                          source_pdf  \n",
       "0  data/raw/jpm/jpm-1q25-earnings-call-transcript...  \n",
       "1  data/raw/jpm/jpm-1q25-earnings-call-transcript...  \n",
       "2  data/raw/jpm/jpm-1q25-earnings-call-transcript...  \n",
       "3  data/raw/jpm/jpm-1q25-earnings-call-transcript...  \n",
       "4  data/raw/jpm/jpm-1q25-earnings-call-transcript...  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset.\n",
    "jpm_2025_df = pd.read_csv('../data/processed/jpm/all_jpm_2025.csv')\n",
    "\n",
    "# View the data.\n",
    "jpm_2025_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f75628c",
   "metadata": {},
   "source": [
    "# **4. Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bc49b23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['analyst', 'Chief Financial Officer',\n",
       "       'Chairman & Chief Executive Officer',\n",
       "       'And then some. Theres a lot of value added.', 'Okay'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View speaker roles.\n",
    "jpm_2025_df['role'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0ec70c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_number</th>\n",
       "      <th>answer_number</th>\n",
       "      <th>speaker_name</th>\n",
       "      <th>role</th>\n",
       "      <th>company</th>\n",
       "      <th>content</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>source_pdf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Chief Financial Officer, JPMorganChase</td>\n",
       "      <td>And then some. Theres a lot of value added.</td>\n",
       "      <td>JPMorganChase</td>\n",
       "      <td>Yeah. And obviously, I mean, we're not going t...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q2</td>\n",
       "      <td>data/raw/jpm/jpm-2q25-earnings-call-transcript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>36</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Chief Financial Officer, JPMorganChase</td>\n",
       "      <td>Okay</td>\n",
       "      <td>there you have it.</td>\n",
       "      <td>But it's not like I thought it would do badly,...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q2</td>\n",
       "      <td>data/raw/jpm/jpm-2q25-earnings-call-transcript...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     question_number  answer_number                            speaker_name  \\\n",
       "201               35            5.0  Chief Financial Officer, JPMorganChase   \n",
       "205               36            3.0  Chief Financial Officer, JPMorganChase   \n",
       "\n",
       "                                            role             company  \\\n",
       "201  And then some. Theres a lot of value added.       JPMorganChase   \n",
       "205                                         Okay  there you have it.   \n",
       "\n",
       "                                               content  year quarter  \\\n",
       "201  Yeah. And obviously, I mean, we're not going t...  2025      Q2   \n",
       "205  But it's not like I thought it would do badly,...  2025      Q2   \n",
       "\n",
       "                                            source_pdf  \n",
       "201  data/raw/jpm/jpm-2q25-earnings-call-transcript...  \n",
       "205  data/raw/jpm/jpm-2q25-earnings-call-transcript...  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View rows with invalid roles.\n",
    "valid_roles = 'analyst', 'Chief Financial Officer', 'Chairman & Chief Executive Officer'\n",
    "invalid_roles_df = jpm_2025_df[~jpm_2025_df['role'].isin(valid_roles)]\n",
    "\n",
    "# Number of rows with invalid roles.\n",
    "print('Number of rows:', invalid_roles_df.shape[0])\n",
    "\n",
    "# View the rows.\n",
    "invalid_roles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1e31cc18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['analyst', 'Chief Financial Officer',\n",
       "       'Chairman & Chief Executive Officer',\n",
       "       'And then some. Theres a lot of value added.'], dtype=object)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input the correct role information.\n",
    "jpm_2025_df.at[205, 'role'] = 'Chief Financial Officer'\n",
    "jpm_2025_df.at[209, 'role'] = 'Chief Financial Officer'\n",
    "\n",
    "# Verify the roles have been updated.\n",
    "jpm_2025_df['role'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e44043a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define role mapping.\n",
    "role_map = {\n",
    "    'analyst': 'analyst',\n",
    "    'Chief Financial Officer': 'banker',\n",
    "    'Chairman & Chief Executive Officer': 'banker'\n",
    "}\n",
    "\n",
    "# Apply to dataset.\n",
    "jpm_2025_df['role_normalised'] = jpm_2025_df['role'].map(role_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "755f26e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_number</th>\n",
       "      <th>answer_number</th>\n",
       "      <th>speaker_name</th>\n",
       "      <th>role</th>\n",
       "      <th>company</th>\n",
       "      <th>content</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>source_pdf</th>\n",
       "      <th>role_normalised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ken Usdin</td>\n",
       "      <td>analyst</td>\n",
       "      <td>Autonomous Research</td>\n",
       "      <td>Good morning, Jeremy. Wondering if you could s...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q1</td>\n",
       "      <td>data/raw/jpm/jpm-1q25-earnings-call-transcript...</td>\n",
       "      <td>analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Jeremy Barnum</td>\n",
       "      <td>Chief Financial Officer</td>\n",
       "      <td>JPMorganChase</td>\n",
       "      <td>Sure, Ken. So I mean, at a high level, I would...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q1</td>\n",
       "      <td>data/raw/jpm/jpm-1q25-earnings-call-transcript...</td>\n",
       "      <td>banker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ken Usdin</td>\n",
       "      <td>analyst</td>\n",
       "      <td>Autonomous Research</td>\n",
       "      <td>Yeah. And just one question on the NII ex. Mar...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q1</td>\n",
       "      <td>data/raw/jpm/jpm-1q25-earnings-call-transcript...</td>\n",
       "      <td>analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Jeremy Barnum</td>\n",
       "      <td>Chief Financial Officer</td>\n",
       "      <td>JPMorganChase</td>\n",
       "      <td>Yeah, that's a good question, Ken. You're righ...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q1</td>\n",
       "      <td>data/raw/jpm/jpm-1q25-earnings-call-transcript...</td>\n",
       "      <td>banker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Jamie Dimon</td>\n",
       "      <td>Chairman &amp; Chief Executive Officer</td>\n",
       "      <td>JPMorganChase</td>\n",
       "      <td>In the curve basically.</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q1</td>\n",
       "      <td>data/raw/jpm/jpm-1q25-earnings-call-transcript...</td>\n",
       "      <td>banker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_number  answer_number   speaker_name  \\\n",
       "0                1            NaN      Ken Usdin   \n",
       "1                1            1.0  Jeremy Barnum   \n",
       "2                2            NaN      Ken Usdin   \n",
       "3                2            1.0  Jeremy Barnum   \n",
       "4                2            2.0    Jamie Dimon   \n",
       "\n",
       "                                 role              company  \\\n",
       "0                             analyst  Autonomous Research   \n",
       "1             Chief Financial Officer        JPMorganChase   \n",
       "2                             analyst  Autonomous Research   \n",
       "3             Chief Financial Officer        JPMorganChase   \n",
       "4  Chairman & Chief Executive Officer        JPMorganChase   \n",
       "\n",
       "                                             content  year quarter  \\\n",
       "0  Good morning, Jeremy. Wondering if you could s...  2025      Q1   \n",
       "1  Sure, Ken. So I mean, at a high level, I would...  2025      Q1   \n",
       "2  Yeah. And just one question on the NII ex. Mar...  2025      Q1   \n",
       "3  Yeah, that's a good question, Ken. You're righ...  2025      Q1   \n",
       "4                            In the curve basically.  2025      Q1   \n",
       "\n",
       "                                          source_pdf role_normalised  \n",
       "0  data/raw/jpm/jpm-1q25-earnings-call-transcript...         analyst  \n",
       "1  data/raw/jpm/jpm-1q25-earnings-call-transcript...          banker  \n",
       "2  data/raw/jpm/jpm-1q25-earnings-call-transcript...         analyst  \n",
       "3  data/raw/jpm/jpm-1q25-earnings-call-transcript...          banker  \n",
       "4  data/raw/jpm/jpm-1q25-earnings-call-transcript...          banker  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the dataset.\n",
    "jpm_2025_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02cf565",
   "metadata": {},
   "source": [
    "# **5. Summarisation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6401764b",
   "metadata": {},
   "source": [
    "## **5.1 Baseline**\n",
    "- Model = BART (not instruction tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "671f20e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, Ken. So I mean, at a high level, I would say that obviously, some of the salient news flow is quite recent. So, we've done some soundings and some checking both on the consumer side and on the w\n"
     ]
    }
   ],
   "source": [
    "# Filter data to banker answers only.\n",
    "banker_answers = jpm_2025_df[jpm_2025_df['role_normalised'] == 'banker']['content'].tolist()\n",
    "print(banker_answers[0][:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "54559054",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Sure, Ken. So I mean, at a high level, I would say that obviously, some of the salient news flow is quite recent. So, we've done some soundings and some checking both on the consumer side and on the wholesale side. I think on the consumer side, the thing to check is the spending data. And to be honest, the main thing that we see there, what would appear to be a certain amount of frontloading of sp\n",
      "Summary: The main thing that we see there, what would appear to be a certain amount of frontloading of spending ahead of people expecting price increases from tariffs. So ironically, that's actually somewhat supportive, all else equal. In terms of our corporate clients, obviously, they've been reacting to the changes in tariff policy.\n"
     ]
    }
   ],
   "source": [
    "# Summarisation baseline (BART)\n",
    "summariser = pipeline('summarization', model='facebook/bart-large-cnn')\n",
    "\n",
    "sample_text = banker_answers[0]\n",
    "summary = summariser(sample_text, max_length=80, min_length=30, do_sample=False)\n",
    "print('Original:', sample_text[:400])\n",
    "print('Summary:', summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "024bd2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Sure, Ken. So I mean, at a high level, I would say that obviously, some of the salient news flow is quite recent. So, we've done some soundings and some checking both on the consumer side and on the wholesale side. I think on the consumer side, the thing to check is the spending data. And to be honest, the main thing that we see there, what would appear to be a certain amount of frontloading of sp\n",
      "Summary: Corporates are taking a wait-and-see approach to tariff policy. Some sectors are going to be much more exposed than others. Small business and smaller corporates are probably a little more challenged.\n"
     ]
    }
   ],
   "source": [
    "# Prompt conditioning to make PRA relevant.\n",
    "prompt = \"Summarise this answer, focusing on risk, capital and evasion of detail: \" + sample_text\n",
    "summary = summariser(prompt, max_length=80, min_length=30)\n",
    "print('Original:', sample_text[:400])\n",
    "print('Summary:', summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6813acc2",
   "metadata": {},
   "source": [
    "## **5.2 Adding Context**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8e1b7a",
   "metadata": {},
   "source": [
    "Retrieve PRA risk categories to give greater PRA focus to summaries (local RAG loop).\n",
    "- measure cosine similarity between transcript chunks and PRA risk categories (vectors)\n",
    "- retrieve the top 2-3 most relevant risk categories \n",
    "- prepend them to the summarisation prompt to make summaries PRA-aligned instead of just summarised answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81f2bd1",
   "metadata": {},
   "source": [
    "- Attempting to use BART resulted in prompt echoing.\n",
    "- New attempt using Mistral-7B-Instruct.\n",
    "- Using sentence-BERT vs TF-IDF for vectorisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6b05ed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove whitespace in text.\n",
    "def clean_text(text: str):\n",
    "    return re.sub(r'\\s+', ' ', text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c4f9ee77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split the transcript into smaller chunks.\n",
    "def chunk_text(text: str, max_chars: int = 6000):\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip()) # split into sentences \n",
    "    chunks, current_chunk, current_len = [], [], 0 # list of chunks, sentences collecting for current chunk, character count for current chunk\n",
    "\n",
    "    for s in sentences:\n",
    "        if current_len + len(s) + 1 <= max_chars: # if the characters of current chunk + new sentence is below the limit:\n",
    "            current_chunk.append(s) # add sentence to current chunk \n",
    "            current_len += len(s) + 1 # update running character count \n",
    "        \n",
    "        else: # if the characters is above the limit:\n",
    "            chunks.append(' '.join(current_chunk)) # add the current chunk to the final chunk list\n",
    "            current_chunk, current_len = [s], len(s) # start a new chunk containing the sentence and update current len\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(' '.join(current_chunk)) # add any sentences in current chunk after loop ends \n",
    "\n",
    "    return chunks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4fe2b709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pra_categories(path: Path):\n",
    "    with open(path, newline='', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        return [\n",
    "            (row.get('category', '').strip(), [row.get('definition', '').strip()])\n",
    "            for row in reader if row.get('category')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "db60595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Sentence-BERT embedding index for PRA categories.\n",
    "def build_embedding_index(pra_categories):\n",
    "    embedder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    pra_risk_embeddings = embedder.encode(pra_risk_df['doc'], batch_size=32, normalize_embeddings=True)\n",
    "\n",
    "    return embedder, np.asarray(pra_risk_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9f02cbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the relevant PRA categories to the transcript chunks.\n",
    "def find_rel_categories(chunk, pra_categories, embedder, pra_risk_embeddings, top_k=2):\n",
    "    query_vec = embedder.encode([chunk], normalize_embeddings=True) # turns chunk into embedding\n",
    "    sims = cosine_similarity(query_vec, pra_risk_embeddings).ravel() # compares the chunk to each category doc \n",
    "    top_indices = np.argsort(-sims)[:top_k] # sorts scores descending and selected top k cateogories \n",
    "\n",
    "    return [pra_categories[i] for i in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a7d85bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json_block(model_output: str) -> str:\n",
    "    \"\"\"If the model adds extra text, grab the first JSON object.\"\"\"\n",
    "    a = model_output.find(\"{\")\n",
    "    b = model_output.rfind(\"}\")\n",
    "    return model_output[a:b+1] if a != -1 and b != -1 and b > a else model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2d0fa31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON instructions for the output file.\n",
    "JSON_INSTRUCTIONS = \"\"\"\\\n",
    "You are a careful data extraction model.\n",
    "Return ONLY valid minified JSON with EXACT keys: summary, evidence, pra_categories.\n",
    "Schema:\n",
    "{\n",
    "  \"summary\": \"string (4-6 sentences, neutral tone)\",\n",
    "  \"evidence\": [\"string\", ...],               // up to N quotes/facts\n",
    "  \"pra_categories\": [                        // 1â€“3 items\n",
    "    {\"name\": \"string\", \"why\": \"string\"},\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "Rules:\n",
    "- Use standard double quotes; no trailing commas; no markdown or prose.\n",
    "- If something is unknown, return an empty string or [] (do NOT omit keys).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "77206958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to summarise the chunk.\n",
    "def summarise_chunk(model, chunk, relevant_categories, max_evidence=5):\n",
    "    lines = []\n",
    "    for name, definition in relevant_categories:\n",
    "        lines.append(f'- {name}:')\n",
    "        for d in definition:\n",
    "            lines.append(f'- {d}')\n",
    "    notes_block = '\\n'.join(lines)\n",
    "\n",
    "    system_prompt = (\n",
    "        JSON_INSTRUCTIONS\n",
    "        + '\\nYou are a Data Scientist producing PRA-aligned summaries.'\n",
    "        'Use only the transcript text as evidence. Map content to the PRA categories provided.'\n",
    "    )\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "TRANSCRIPT:\n",
    "{chunk}\n",
    "\n",
    "PRA NOTES:\n",
    "{notes_block}\n",
    "\n",
    "TASK:\n",
    "Return STRICT JSON with keys:\n",
    "- evidence: list of up to {max_evidence} bullet strings\n",
    "- pra categories: list of objects {{ 'name': '...', 'why': '...' }}\n",
    "- summary: 4-6 sentences, neutral tone\n",
    "\n",
    "RULES:\n",
    "- Do not invent facts. If evidence is lacking, use a single bullet 'Insufficient evidence'.\n",
    "- Only choose categories supported by the evidence.\n",
    "- No markdown. Output JSON only.\n",
    "\"\"\"\n",
    "    \n",
    "    response = model.create_chat_completion(\n",
    "        messages=[\n",
    "            {'role': 'system', 'content': system_prompt},\n",
    "            {'role': 'user', 'content': clean_text(user_prompt)}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        max_tokens=700,\n",
    "        repeat_penalty=1.1\n",
    "    ) \n",
    "\n",
    "    text = response['choices'][0]['message']['content'].strip()\n",
    "    try:\n",
    "        return json.loads(exytact_json_block(text))\n",
    "    except Exception:\n",
    "        return {'raw': text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e398a6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables.\n",
    "MODEL_PATH = '/Users/laurenbrixey/Documents/Data Science Career Accelerator/Project Submissions/Course 3/topic_project_4.1/mistral-7b-instruct-v0.1.Q4_K_M.gguf'\n",
    "PRA_NOTES_PATH = '../data/RAG-resources/PRA_risk_categories.csv'\n",
    "TRANSCRIPT_PATH = '../data/processed/jpm/all_jpm_2025.csv'\n",
    "OUTPUT_PATH = \"jpm_mistral_pra_summary.json\"\n",
    "TOP_K = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c7cff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_load_from_file_impl: using device Metal (Apple M3) - 17592186041507 MiB free\n",
      "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from /Users/laurenbrixey/Documents/Data Science Career Accelerator/Project Submissions/Course 3/topic_project_4.1/mistral-7b-instruct-v0.1.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.1\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "print_info: file format = GGUF V2\n",
      "print_info: file type   = Q4_K - Medium\n",
      "print_info: file size   = 4.07 GiB (4.83 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 1\n",
      "load: control token:      2 '</s>' is not marked as EOG\n",
      "load: control token:      1 '<s>' is not marked as EOG\n",
      "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "load: printing all EOG tokens:\n",
      "load:   - 2 ('</s>')\n",
      "load: special tokens cache size = 3\n",
      "load: token to piece cache size = 0.1637 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 32768\n",
      "print_info: n_embd           = 4096\n",
      "print_info: n_layer          = 32\n",
      "print_info: n_head           = 32\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: is_swa_any       = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 4\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 14336\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 10000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 32768\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: model type       = 7B\n",
      "print_info: model params     = 7.24 B\n",
      "print_info: general.name     = mistralai_mistral-7b-instruct-v0.1\n",
      "print_info: vocab type       = SPM\n",
      "print_info: n_vocab          = 32000\n",
      "print_info: n_merges         = 0\n",
      "print_info: BOS token        = 1 '<s>'\n",
      "print_info: EOS token        = 2 '</s>'\n",
      "print_info: UNK token        = 0 '<unk>'\n",
      "print_info: LF token         = 13 '<0x0A>'\n",
      "print_info: EOG token        = 2 '</s>'\n",
      "print_info: max token length = 48\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  12 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  13 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  14 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  15 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  16 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  17 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  18 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  19 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  20 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  21 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  22 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  23 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  24 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  25 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  26 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  27 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  28 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  29 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  30 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  31 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  32 assigned to device CPU, is_swa = 0\n",
      "load_tensors: tensor 'token_embd.weight' (q4_K) (and 110 others) cannot be used with preferred buffer type CPU_REPACK, using CPU instead\n"
     ]
    }
   ],
   "source": [
    "# Runner code.\n",
    "pra_categories = load_pra_categories(Path(PRA_NOTES_PATH)) # load pra category file\n",
    "embedder, category_embeddings = build_embedding_index(pra_categories) # embed pra categories\n",
    "\n",
    "transcript_text = Path(TRANSCRIPT_PATH).read_text() # load the transcript text\n",
    "transcript_chunks = chunk_text(transcript_text) # split the transcript into smaller chunks\n",
    "\n",
    "n_threads = max(4, (os.cpu_count() or 8) - 2)\n",
    "\n",
    "model = Llama(\n",
    "    model_path=str(MODEL_PATH), \n",
    "    n_ctx=4096, \n",
    "    n_gpu_layers=20, \n",
    "    chat_format='mistral-instruct', \n",
    "    n_threads=n_threads)\n",
    "\n",
    "results = []\n",
    "for i, chunk in enumerate(transcript_chunks, 1):\n",
    "    top_categories = find_rel_categories(chunk, pra_categories, embedder, category_embeddings)\n",
    "    summary_result = summarise_chunk(model, chunk, top_categories)\n",
    "    results.append({'chunk': i, 'result': summary_result})\n",
    "\n",
    "combined_summary = ' '.join(r['result'].get('summary', '') for r in results)\n",
    "final_output = {'chunks': results, 'combined_summary': combined_summary.strip()}\n",
    "\n",
    "Path(OUTPUT_PATH).write_text(json.dumps(final_output, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1aadc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean JSON saved to: ../notebooks/jpm_mistral_pra_summary.clean.json\n",
      "CSV saved to: ../notebooks/jpm_mistral_pra_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# # Post processing script.\n",
    "# INPUT_JSON = '../notebooks/jpm_mistral_pra_summary.json' # input path\n",
    "# INPUT_PATH = pathlib.Path(INPUT_JSON)\n",
    "\n",
    "# # Output paths \n",
    "# OUTPUT_JSON = INPUT_PATH.with_suffix('.clean.json')\n",
    "# OUTPUT_CSV = INPUT_PATH.with_suffix('.csv')\n",
    "\n",
    "# # Load the raw file.\n",
    "# with open(INPUT_PATH, 'r', encoding='utf-8') as f:\n",
    "#     raw_file = json.load(f)\n",
    "\n",
    "# chunks = raw_file.get('chunks', []) # get the list of chunks\n",
    "\n",
    "# rows = [] # empty list to store cleaned rows\n",
    "\n",
    "# for row in chunks:\n",
    "#     result= row.get('result', {})\n",
    "\n",
    "#     # Handle inconsistent key names.\n",
    "#     pra_categories = result.get('pra_categories') or result.get('pra categories')\n",
    "#     evidence = result.get('evidence') or result.get('raw')\n",
    "\n",
    "#     rows.append({\n",
    "#         'chunk_id': row.get('chunk'),\n",
    "#         'summary': result.get('summary'), \n",
    "#         'pra_categories': pra_categories,\n",
    "#         'supporting_evidence': evidence\n",
    "#     })\n",
    "\n",
    "# # Save clean JSON.\n",
    "# with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:\n",
    "#     json.dump(rows, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# # Save clean csv\n",
    "# df = pd.DataFrame(rows)\n",
    "# df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "# print(\"Clean JSON saved to:\", OUTPUT_JSON)\n",
    "# print(\"CSV saved to:\", OUTPUT_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "451d04e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: ../notebooks/jpm_mistral_pra_summary.clean.v2.json\n",
      "Wrote: ../notebooks/jpm_mistral_pra_summary.v2.csv\n"
     ]
    }
   ],
   "source": [
    "INPUT_JSON = pathlib.Path('../notebooks/jpm_mistral_pra_summary.json')\n",
    "OUTPUT_JSON = INPUT_JSON.with_suffix(\".clean.v2.json\")\n",
    "OUTPUT_CSV  = INPUT_JSON.with_suffix(\".v2.csv\")\n",
    "\n",
    "def safe_loads(s: str):\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def pick(d, *keys):\n",
    "    if not isinstance(d, dict): return None\n",
    "    for k in keys:\n",
    "        v = d.get(k)\n",
    "        if v is not None:\n",
    "            return v\n",
    "    return None\n",
    "\n",
    "raw = json.load(open(INPUT_JSON, \"r\", encoding=\"utf-8\"))\n",
    "rows = []\n",
    "for ch in raw.get(\"chunks\", []):\n",
    "    res = ch.get(\"result\", {}) or {}\n",
    "    raw_parsed = safe_loads(res.get(\"raw\")) if isinstance(res.get(\"raw\"), str) else None\n",
    "\n",
    "    summary = pick(res, \"summary\") or pick(raw_parsed or {}, \"summary\")\n",
    "    pra_categories = (\n",
    "        pick(res, \"pra_categories\", \"pra categories\")\n",
    "        or pick(raw_parsed or {}, \"pra_categories\", \"pra categories\")\n",
    "    )\n",
    "    evidence = pick(res, \"evidence\") or pick(raw_parsed or {}, \"evidence\")\n",
    "\n",
    "    rows.append({\n",
    "        \"chunk_id\": ch.get(\"chunk\"),\n",
    "        \"summary\": summary,\n",
    "        \"pra_categories\": pra_categories,\n",
    "        \"supporting_evidence\": evidence,\n",
    "    })\n",
    "\n",
    "# Save files\n",
    "with open(OUTPUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(rows, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "pd.DataFrame(rows).to_csv(OUTPUT_CSV, index=False)\n",
    "print(\"Wrote:\", OUTPUT_JSON)\n",
    "print(\"Wrote:\", OUTPUT_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd9d93f",
   "metadata": {},
   "source": [
    "# **6. Evasion Scoring**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-evasion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
