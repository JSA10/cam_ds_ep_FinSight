{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b09f0410",
   "metadata": {},
   "source": [
    "# **FinSight Evasion Detection Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563a4aa4",
   "metadata": {},
   "source": [
    "## **1. Documentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcfa95c",
   "metadata": {},
   "source": [
    "### **1.1 Purpose & Scope**\n",
    "This notebook implements a pipeline to detect evasive vs direct answers in Q&A transcripts. The primary buisness goal is to maximise recall for the evasive class (minimise false negatives) so reviewers recieve a shortlist of likely evasive answers to inspect. We report ranking metrics such as P@K (precison within the top-K% of predicted positives) to quantify shortlist quality for downstream PRA review. \n",
    "\n",
    "Validation and fine-tuning of thresholds was carried out on J.P. Morgan data 2023-2024 Q&A transcript data. J.P. Morgan 2025 and HSBC 2025 Q&A transcript data were used for predictions.\n",
    "\n",
    "### **1.2 Data & Inputs**\n",
    "- **Data:** Q&A transcripts (J.P. Morgan 2023-2025 and HSBC 2023-2025). J.P. Morgan used for validation & reporting, HSBC used for reporting.\n",
    "- **Input format:** A table with the following columns: question_number, answer_number, speaker_name, role, company, content, year, quarter and source_pdf\n",
    "- **Splits** `train` (used to test exemplar building), `jpm_val_qa_labelled` (for fine tuning thresholds & model selection) and `jpm_test_qa_labelled` (for final reporting). Final predictions were carried out on `jpm_2025_predict_qa` and `hsbc_2025_predict_qa`. \n",
    "- **Imbalance:** Strong class imbalance (evasive minority)\n",
    "\n",
    "### **1.3 Pipeline Overview**\n",
    "- **Rule-based Baseline:** Flag potential evasions by assessing question-answer semantic similarity, numerical expectations (e.g. question asks for numbers, answer lacks numbers) and evasive phrase hits.\n",
    "- **NLI-Based Scoring:** Treats each question + answer as the premise and probes entailment against hypotheses representing Direct and Evasive answers using large MNLI models i.e. `roberta-large-mnli`, `microsoft/deberta-large-mnli` and `MoritzLaurer/deberta-v3-large-zeroshot-v2.0`. Map model logits/probabilities to an evasion score. \n",
    "- **Few-Shot RAG Exemplars (tested)**: Retrieves a small set of labelled exemplars (via SBERT similarity on question) and prepends them to the NLI context.\n",
    "- **Blending:** Combines baseline and NLI scores (weighted blend) and averages LLM NLI scores.\n",
    "- **Thresholding:** Converts scores to binary flags using tuned thresholds. \n",
    "\n",
    "### **1.4 Evaluation Metrics**\n",
    "The notebook reports the following per threshold:\n",
    "- **Precision/ Recall/ F1** (Direct)\n",
    "- **Preicsion/ Recall / F1** (Evasive): primary gocus on recall_evasive \n",
    "- **AUPRC:** area under precision-recall curve for evasive class \n",
    "- **P@K% predicted positives:** e.g. 10%, 25%, 50%, use to set short-list size for flagged evasive answers (number of correctly predicted positives in K% of ranked list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd332e9",
   "metadata": {},
   "source": [
    "## **2. Set Up Workspace**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe4757be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/nlp-evasion/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "# Core python\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any \n",
    "import csv\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "\n",
    "# NLP & Summarisation\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from llama_cpp import Llama \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Retrieval\n",
    "from sentence_transformers import SentenceTransformer \n",
    "\n",
    "# ML\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit, StratifiedGroupKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, average_precision_score\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "# Visualisations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "# Set global SEED.\n",
    "SEED = 42\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d4faaf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>question_number</th>\n",
       "      <th>answer_number</th>\n",
       "      <th>speaker_name</th>\n",
       "      <th>role</th>\n",
       "      <th>company</th>\n",
       "      <th>content</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>is_pleasantry</th>\n",
       "      <th>source_pdf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>presentation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jeremy Barnum</td>\n",
       "      <td>Chief Financial Officer</td>\n",
       "      <td>JPMorganChase</td>\n",
       "      <td>Thanks, and good morning, everyone. The presen...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q1</td>\n",
       "      <td>False</td>\n",
       "      <td>data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Steven Chubak</td>\n",
       "      <td>analyst</td>\n",
       "      <td>Wolfe Research LLC</td>\n",
       "      <td>Hey, good morning.</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q1</td>\n",
       "      <td>True</td>\n",
       "      <td>data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jeremy Barnum</td>\n",
       "      <td>Chief Financial Officer</td>\n",
       "      <td>JPMorgan Chase &amp; Co.</td>\n",
       "      <td>Good morning, Steve.</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q1</td>\n",
       "      <td>True</td>\n",
       "      <td>data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Steven Chubak</td>\n",
       "      <td>analyst</td>\n",
       "      <td>Wolfe Research LLC</td>\n",
       "      <td>So, Jamie, I was actually hoping to get your p...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q1</td>\n",
       "      <td>False</td>\n",
       "      <td>data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Jamie Dimon</td>\n",
       "      <td>Chairman &amp; Chief Executive Officer</td>\n",
       "      <td>JPMorgan Chase &amp; Co.</td>\n",
       "      <td>Well, I think you were already kind of complet...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q1</td>\n",
       "      <td>False</td>\n",
       "      <td>data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        section  question_number  answer_number   speaker_name  \\\n",
       "0  presentation              NaN            NaN  Jeremy Barnum   \n",
       "1            qa              NaN            NaN  Steven Chubak   \n",
       "2            qa              NaN            NaN  Jeremy Barnum   \n",
       "3            qa              1.0            NaN  Steven Chubak   \n",
       "4            qa              1.0            1.0    Jamie Dimon   \n",
       "\n",
       "                                 role               company  \\\n",
       "0             Chief Financial Officer         JPMorganChase   \n",
       "1                             analyst    Wolfe Research LLC   \n",
       "2             Chief Financial Officer  JPMorgan Chase & Co.   \n",
       "3                             analyst    Wolfe Research LLC   \n",
       "4  Chairman & Chief Executive Officer  JPMorgan Chase & Co.   \n",
       "\n",
       "                                             content  year quarter  \\\n",
       "0  Thanks, and good morning, everyone. The presen...  2023      Q1   \n",
       "1                                 Hey, good morning.  2023      Q1   \n",
       "2                               Good morning, Steve.  2023      Q1   \n",
       "3  So, Jamie, I was actually hoping to get your p...  2023      Q1   \n",
       "4  Well, I think you were already kind of complet...  2023      Q1   \n",
       "\n",
       "   is_pleasantry                                         source_pdf  \n",
       "0          False  data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...  \n",
       "1           True  data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...  \n",
       "2           True  data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...  \n",
       "3          False  data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...  \n",
       "4          False  data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 1411\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset.\n",
    "url = 'https://raw.githubusercontent.com/JSA10/cam_ds_ep_FinSight/refs/heads/main/data/processed/jpm/all_jpm_2023_2025.csv'\n",
    "all_jpm_2023_2025 = pd.read_csv(url)\n",
    "\n",
    "# View dataset.\n",
    "display(all_jpm_2023_2025.head())\n",
    "\n",
    "# Number of rows.\n",
    "print('Number of rows:', all_jpm_2023_2025.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb37786",
   "metadata": {},
   "source": [
    "## **3. J.P. Morgan**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4052c2",
   "metadata": {},
   "source": [
    "### **3.1 Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d75741aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 1241\n"
     ]
    }
   ],
   "source": [
    "# Remove pleasantries.\n",
    "all_jpm_2023_2025_cleaned = all_jpm_2023_2025[all_jpm_2023_2025['is_pleasantry'] == False]\n",
    "print('Number of rows:', all_jpm_2023_2025_cleaned.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afdf6c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with no content: 23\n"
     ]
    }
   ],
   "source": [
    "# Check content column.\n",
    "print('Number of rows with no content:', all_jpm_2023_2025_cleaned['content'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bae31466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with no content.\n",
    "all_jpm_2023_2025_cleaned = all_jpm_2023_2025_cleaned.dropna(subset=['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ec90492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with no content: 0\n"
     ]
    }
   ],
   "source": [
    "# Check content column.\n",
    "print('Number of rows with no content:', all_jpm_2023_2025_cleaned['content'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e5f0b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Chief Financial Officer', 'analyst',\n",
       "       'Chairman & Chief Executive Officer',\n",
       "       'And then some. Theres a lot of value added.', 'Okay',\n",
       "       \"We're fundamentally\", 'Thanks', 'Almost no chance.'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View roles.\n",
    "all_jpm_2023_2025_cleaned['role'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d93c170",
   "metadata": {},
   "source": [
    "- Some text has leaked into role column and so this was manually corrected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51f313bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>question_number</th>\n",
       "      <th>answer_number</th>\n",
       "      <th>speaker_name</th>\n",
       "      <th>role</th>\n",
       "      <th>company</th>\n",
       "      <th>content</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>is_pleasantry</th>\n",
       "      <th>source_pdf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>qa</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Chief Financial Officer, JPMorganChase</td>\n",
       "      <td>And then some. Theres a lot of value added.</td>\n",
       "      <td>JPMorganChase</td>\n",
       "      <td>Yeah. And obviously, I mean, we're not going t...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q2</td>\n",
       "      <td>False</td>\n",
       "      <td>data/raw/jpm/.ipynb_checkpoints/jpm-2q25-earni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>qa</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Chief Financial Officer, JPMorganChase</td>\n",
       "      <td>Okay</td>\n",
       "      <td>there you have it.</td>\n",
       "      <td>But it's not like I thought it would do badly,...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q2</td>\n",
       "      <td>False</td>\n",
       "      <td>data/raw/jpm/.ipynb_checkpoints/jpm-2q25-earni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>qa</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Who knows how important politics are in all th...</td>\n",
       "      <td>We're fundamentally</td>\n",
       "      <td>as I said, I think on the press call, happy to...</td>\n",
       "      <td>little bit cautious about the pull-forward dyn...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Q1</td>\n",
       "      <td>False</td>\n",
       "      <td>data/raw/jpm/jpm-1q24-earnings-call-transcript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>qa</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Chief Financial Officer, JPMorgan Chase &amp; Co.</td>\n",
       "      <td>Thanks</td>\n",
       "      <td>Glenn.</td>\n",
       "      <td>Operator: Next, we'll go to the line of Matt O...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Q2</td>\n",
       "      <td>False</td>\n",
       "      <td>data/raw/jpm/jpm-2q24-earnings-call-transcript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>qa</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Chief Financial Officer, JPMorganChase</td>\n",
       "      <td>And then some. Theres a lot of value added.</td>\n",
       "      <td>JPMorganChase</td>\n",
       "      <td>Yeah. And obviously, I mean, we're not going t...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q2</td>\n",
       "      <td>False</td>\n",
       "      <td>data/raw/jpm/jpm-2q25-earnings-call-transcript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>qa</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Chief Financial Officer, JPMorganChase</td>\n",
       "      <td>Okay</td>\n",
       "      <td>there you have it.</td>\n",
       "      <td>But it's not like I thought it would do badly,...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q2</td>\n",
       "      <td>False</td>\n",
       "      <td>data/raw/jpm/jpm-2q25-earnings-call-transcript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>qa</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Chairman &amp; Chief Executive Officer, JPMorgan C...</td>\n",
       "      <td>Almost no chance.</td>\n",
       "      <td>JPMorganChase</td>\n",
       "      <td>Well, but having – it's very important. While ...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Q3</td>\n",
       "      <td>False</td>\n",
       "      <td>data/raw/jpm/jpm-3q24-earnings-conference-call...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     section  question_number  answer_number  \\\n",
       "305       qa             22.0            4.0   \n",
       "309       qa             23.0            3.0   \n",
       "650       qa             10.0            3.0   \n",
       "924       qa              8.0            2.0   \n",
       "1059      qa             22.0            4.0   \n",
       "1063      qa             23.0            3.0   \n",
       "1274      qa             23.0            1.0   \n",
       "\n",
       "                                           speaker_name  \\\n",
       "305              Chief Financial Officer, JPMorganChase   \n",
       "309              Chief Financial Officer, JPMorganChase   \n",
       "650   Who knows how important politics are in all th...   \n",
       "924       Chief Financial Officer, JPMorgan Chase & Co.   \n",
       "1059             Chief Financial Officer, JPMorganChase   \n",
       "1063             Chief Financial Officer, JPMorganChase   \n",
       "1274  Chairman & Chief Executive Officer, JPMorgan C...   \n",
       "\n",
       "                                             role  \\\n",
       "305   And then some. Theres a lot of value added.   \n",
       "309                                          Okay   \n",
       "650                           We're fundamentally   \n",
       "924                                        Thanks   \n",
       "1059  And then some. Theres a lot of value added.   \n",
       "1063                                         Okay   \n",
       "1274                            Almost no chance.   \n",
       "\n",
       "                                                company  \\\n",
       "305                                       JPMorganChase   \n",
       "309                                  there you have it.   \n",
       "650   as I said, I think on the press call, happy to...   \n",
       "924                                              Glenn.   \n",
       "1059                                      JPMorganChase   \n",
       "1063                                 there you have it.   \n",
       "1274                                      JPMorganChase   \n",
       "\n",
       "                                                content  year quarter  \\\n",
       "305   Yeah. And obviously, I mean, we're not going t...  2025      Q2   \n",
       "309   But it's not like I thought it would do badly,...  2025      Q2   \n",
       "650   little bit cautious about the pull-forward dyn...  2024      Q1   \n",
       "924   Operator: Next, we'll go to the line of Matt O...  2024      Q2   \n",
       "1059  Yeah. And obviously, I mean, we're not going t...  2025      Q2   \n",
       "1063  But it's not like I thought it would do badly,...  2025      Q2   \n",
       "1274  Well, but having – it's very important. While ...  2024      Q3   \n",
       "\n",
       "      is_pleasantry                                         source_pdf  \n",
       "305           False  data/raw/jpm/.ipynb_checkpoints/jpm-2q25-earni...  \n",
       "309           False  data/raw/jpm/.ipynb_checkpoints/jpm-2q25-earni...  \n",
       "650           False  data/raw/jpm/jpm-1q24-earnings-call-transcript...  \n",
       "924           False  data/raw/jpm/jpm-2q24-earnings-call-transcript...  \n",
       "1059          False  data/raw/jpm/jpm-2q25-earnings-call-transcript...  \n",
       "1063          False  data/raw/jpm/jpm-2q25-earnings-call-transcript...  \n",
       "1274          False  data/raw/jpm/jpm-3q24-earnings-conference-call...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View rows with invalid roles. \n",
    "valid_roles = 'analyst', 'Chief Financial Officer', 'Chairman & Chief Executive Officer'\n",
    "invalid_roles_df = all_jpm_2023_2025_cleaned[~all_jpm_2023_2025_cleaned['role'].isin(valid_roles)]\n",
    "invalid_roles_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7be6117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the correct role information.\n",
    "all_jpm_2023_2025_cleaned.loc[[305, 309, 924, 1059, 1063], 'role'] = 'Chief Financial Officer'\n",
    "all_jpm_2023_2025_cleaned.loc[[1274], 'role'] = 'Chairman & Chief Executive Officer'\n",
    "\n",
    "# Drop nonsence row.\n",
    "all_jpm_2023_2025_cleaned = all_jpm_2023_2025_cleaned.drop(index=650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b55ae80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Chief Financial Officer', 'analyst',\n",
       "       'Chairman & Chief Executive Officer'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the roles have been updated.\n",
    "all_jpm_2023_2025_cleaned['role'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44488c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise role names.\n",
    "role_map = {\n",
    "    'analyst': 'analyst',\n",
    "    'Chief Financial Officer': 'banker',\n",
    "    'Chairman & Chief Executive Officer': 'banker'\n",
    "}\n",
    "\n",
    "# Map roles.\n",
    "all_jpm_2023_2025_cleaned['role_normalised'] = all_jpm_2023_2025_cleaned['role'].map(role_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93a64b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>question_number</th>\n",
       "      <th>answer_number</th>\n",
       "      <th>speaker_name</th>\n",
       "      <th>role</th>\n",
       "      <th>company</th>\n",
       "      <th>content</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>is_pleasantry</th>\n",
       "      <th>source_pdf</th>\n",
       "      <th>role_normalised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>presentation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jeremy Barnum</td>\n",
       "      <td>Chief Financial Officer</td>\n",
       "      <td>JPMorganChase</td>\n",
       "      <td>Thanks, and good morning, everyone. The presen...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q1</td>\n",
       "      <td>False</td>\n",
       "      <td>data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...</td>\n",
       "      <td>banker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Steven Chubak</td>\n",
       "      <td>analyst</td>\n",
       "      <td>Wolfe Research LLC</td>\n",
       "      <td>So, Jamie, I was actually hoping to get your p...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q1</td>\n",
       "      <td>False</td>\n",
       "      <td>data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...</td>\n",
       "      <td>analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Jamie Dimon</td>\n",
       "      <td>Chairman &amp; Chief Executive Officer</td>\n",
       "      <td>JPMorgan Chase &amp; Co.</td>\n",
       "      <td>Well, I think you were already kind of complet...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q1</td>\n",
       "      <td>False</td>\n",
       "      <td>data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...</td>\n",
       "      <td>banker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>qa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Steven Chubak</td>\n",
       "      <td>analyst</td>\n",
       "      <td>Wolfe Research LLC</td>\n",
       "      <td>Got it. And just in terms of appetite for the ...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q1</td>\n",
       "      <td>False</td>\n",
       "      <td>data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...</td>\n",
       "      <td>analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>qa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Jamie Dimon</td>\n",
       "      <td>Chairman &amp; Chief Executive Officer</td>\n",
       "      <td>JPMorgan Chase &amp; Co.</td>\n",
       "      <td>Oh, yeah.</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q1</td>\n",
       "      <td>False</td>\n",
       "      <td>data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...</td>\n",
       "      <td>banker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        section  question_number  answer_number   speaker_name  \\\n",
       "0  presentation              NaN            NaN  Jeremy Barnum   \n",
       "3            qa              1.0            NaN  Steven Chubak   \n",
       "4            qa              1.0            1.0    Jamie Dimon   \n",
       "5            qa              1.0            1.0  Steven Chubak   \n",
       "6            qa              1.0            2.0    Jamie Dimon   \n",
       "\n",
       "                                 role               company  \\\n",
       "0             Chief Financial Officer         JPMorganChase   \n",
       "3                             analyst    Wolfe Research LLC   \n",
       "4  Chairman & Chief Executive Officer  JPMorgan Chase & Co.   \n",
       "5                             analyst    Wolfe Research LLC   \n",
       "6  Chairman & Chief Executive Officer  JPMorgan Chase & Co.   \n",
       "\n",
       "                                             content  year quarter  \\\n",
       "0  Thanks, and good morning, everyone. The presen...  2023      Q1   \n",
       "3  So, Jamie, I was actually hoping to get your p...  2023      Q1   \n",
       "4  Well, I think you were already kind of complet...  2023      Q1   \n",
       "5  Got it. And just in terms of appetite for the ...  2023      Q1   \n",
       "6                                          Oh, yeah.  2023      Q1   \n",
       "\n",
       "   is_pleasantry                                         source_pdf  \\\n",
       "0          False  data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...   \n",
       "3          False  data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...   \n",
       "4          False  data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...   \n",
       "5          False  data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...   \n",
       "6          False  data/raw/jpm/.ipynb_checkpoints/jpm-1q23-earni...   \n",
       "\n",
       "  role_normalised  \n",
       "0          banker  \n",
       "3         analyst  \n",
       "4          banker  \n",
       "5         analyst  \n",
       "6          banker  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 1217\n"
     ]
    }
   ],
   "source": [
    "# View dataset.\n",
    "display(all_jpm_2023_2025_cleaned.head())\n",
    "print('Number of rows:', all_jpm_2023_2025_cleaned.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abae0293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned dataset.\n",
    "all_jpm_2023_2025_cleaned.to_csv('../data/processed/jpm/cleaned/all_jpm_2023_2025_cleaned') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "592e5f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove duplicates within questions and answers. \n",
    "def clean_repeats(text):\n",
    "\n",
    "    # 1) Normalize whitespace\n",
    "    t = ' '.join(text.split()).strip()\n",
    "    if not t:\n",
    "        return t\n",
    "\n",
    "    # 2) If the whole-string is a back-to-back duplicate (A+A) = keep first half\n",
    "    mid = len(t) // 2\n",
    "    if len(t) % 2 == 0 and t[:mid] == t[mid:]:\n",
    "        t = t[:mid]\n",
    "\n",
    "    # 3) Collapse immediate repeated token spans (n-grams).\n",
    "    toks = t.split()\n",
    "    out = []\n",
    "    i = 0\n",
    "    while i < len(toks):\n",
    "        matched = False\n",
    "        max_span = min(50, len(toks) - i)  # cap span to remaining length\n",
    "        for n in range(max_span, 4, -1):  # try longer spans first: 50..5\n",
    "            if i + 2*n <= len(toks) and toks[i:i+n] == toks[i+n:i+2*n]:\n",
    "                out.extend(toks[i:i+n])  # keep one copy\n",
    "                i += 2*n                # skip the duplicate block\n",
    "                matched = True\n",
    "                break\n",
    "        if not matched:\n",
    "            out.append(toks[i])\n",
    "            i += 1\n",
    "    t = ' '.join(out)\n",
    "\n",
    "    # 4) Remove duplicate sentences globally (order-preserving)\n",
    "    sents = re.split(r'(?<=[.!?])\\s+', t)\n",
    "    seen = set()\n",
    "    uniq = []\n",
    "    for s in sents:\n",
    "        s_norm = s.strip()\n",
    "        if not s_norm:\n",
    "            continue\n",
    "        key = ' '.join(s_norm.lower().split())\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            uniq.append(s_norm)\n",
    "    return ' '.join(uniq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5348f73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert datasets into question and answer pairs.\n",
    "def create_qa_pairs(df, min_answer_words=30):\n",
    "    \n",
    "    # Keep only the Q&A section.\n",
    "    qa_df = df[df['section'].astype(str).str.lower() == 'qa'].copy()\n",
    "\n",
    "    # Split into roles.\n",
    "    analyst_rows = qa_df[qa_df['role_normalised'] == 'analyst'].copy()\n",
    "    banker_rows  = qa_df[qa_df['role_normalised'] == 'banker' ].copy()\n",
    "\n",
    "    # Keys to keep quarters separated\n",
    "    key_q = ['year', 'quarter', 'question_number']\n",
    "\n",
    "    # Build full question text per (year, quarter, question_number)\n",
    "    question_text_map = (\n",
    "        analyst_rows\n",
    "        .groupby(key_q, dropna=False)['content']\n",
    "        .apply(lambda parts: clean_repeats(' '.join(parts.astype(str))))\n",
    "        .rename('question')\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Ensure bankers have an answer_number — sequential per (year, quarter, question_number) if missing.\n",
    "    if 'answer_number' not in banker_rows.columns or banker_rows['answer_number'].isna().any():\n",
    "        banker_rows = banker_rows.sort_index().copy()\n",
    "        banker_rows['answer_number'] = (\n",
    "            banker_rows\n",
    "            .groupby(key_q, dropna=False)\n",
    "            .cumcount() + 1\n",
    "        )\n",
    "\n",
    "    # Combine multiple banker utterances belonging to the same answer.\n",
    "    banker_answers = (\n",
    "        banker_rows\n",
    "        .groupby(key_q + ['answer_number'], dropna=False)\n",
    "        .agg({\n",
    "            'content':        lambda parts: clean_repeats(' '.join(parts.astype(str))),\n",
    "            'speaker_name':   'first',\n",
    "            'role':           'first',\n",
    "            'role_normalised':'first',\n",
    "            'source_pdf':     'first'\n",
    "        })\n",
    "        .rename(columns={'content': 'answer'})\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Merge question text back onto each answer row.\n",
    "    qa_pairs = banker_answers.merge(\n",
    "        question_text_map,\n",
    "        on=key_q,\n",
    "        how='left',\n",
    "        validate='many_to_one'\n",
    "    )\n",
    "\n",
    "    # Order columns for readability.\n",
    "    column_order = [\n",
    "        'year', 'quarter', 'question_number', 'answer_number',\n",
    "        'question', 'answer',\n",
    "        'speaker_name', 'role', 'role_normalised',\n",
    "        'source_pdf'\n",
    "    ]\n",
    "    qa_pairs = qa_pairs.reindex(columns=[c for c in column_order if c in qa_pairs.columns])\n",
    "\n",
    "    # Sort and reset index.\n",
    "    qa_pairs = qa_pairs.sort_values(['year', 'quarter', 'question_number', 'answer_number']).reset_index(drop=True)\n",
    "\n",
    "    # Drop duplicate answers.\n",
    "    qa_pairs = qa_pairs.drop_duplicates(subset=['answer'])\n",
    "\n",
    "    # Drop short answers below threshold to ensure quality answers.\n",
    "    qa_pairs = qa_pairs[qa_pairs['answer'].astype(str).str.split().str.len() >= int(min_answer_words)]\n",
    "\n",
    "    return qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c5baeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create q&A pairs.\n",
    "all_jpm_2023_2025_qa = create_qa_pairs(all_jpm_2023_2025_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37bf88fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 309\n"
     ]
    }
   ],
   "source": [
    "# View number of examples.\n",
    "print('Number of examples:', all_jpm_2023_2025_qa.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80655a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into prediction set and validation/test set.\n",
    "jpm_2025_predict_qa = all_jpm_2023_2025_qa[all_jpm_2023_2025_qa['year'] == 2025]\n",
    "jpm_2023_2024_qa = all_jpm_2023_2025_qa[all_jpm_2023_2025_qa['year'].isin([2023, 2024])]\n",
    "\n",
    "# Save the datasets.\n",
    "jpm_2025_predict_qa.to_csv('../data/processed/jpm/cleaned/jpm_2025_predict_qa.csv') \n",
    "jpm_2023_2024_qa.to_csv('../data/processed/jpm/cleaned/jpm_2023_2024_qa.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014e28ad",
   "metadata": {},
   "source": [
    "The jpm_2023_2024_qa dataset was then manually labelled according to whether the banker's answer was deemed 'Direct' or 'Evasive'. The label was appended by a new column 'label'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61c4b567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>question_number</th>\n",
       "      <th>answer_number</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>speaker_name</th>\n",
       "      <th>role</th>\n",
       "      <th>role_normalised</th>\n",
       "      <th>source_pdf</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>Q4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Good morning. Thanks for all the comments on t...</td>\n",
       "      <td>Yeah. Matt, not particularly updating. I think...</td>\n",
       "      <td>Jeremy Barnum</td>\n",
       "      <td>Chief Financial Officer</td>\n",
       "      <td>banker</td>\n",
       "      <td>data/raw/jpm/jpm-4q23-earnings-call-transcript...</td>\n",
       "      <td>Direct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>Q4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Okay. And then just separately, you bought bac...</td>\n",
       "      <td>Yeah. Good question. And I think you framed it...</td>\n",
       "      <td>Jeremy Barnum</td>\n",
       "      <td>Chief Financial Officer</td>\n",
       "      <td>banker</td>\n",
       "      <td>data/raw/jpm/jpm-4q23-earnings-call-transcript...</td>\n",
       "      <td>Direct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>Q4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Thanks. Jeremy, could you give a little more c...</td>\n",
       "      <td>Yeah. Actually, John, this quarter, that's all...</td>\n",
       "      <td>Jeremy Barnum</td>\n",
       "      <td>Chief Financial Officer</td>\n",
       "      <td>banker</td>\n",
       "      <td>data/raw/jpm/jpm-4q23-earnings-call-transcript...</td>\n",
       "      <td>Direct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>Q4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Okay. And then, just to follow up on the NII, ...</td>\n",
       "      <td>Sure. Yeah, happy to do that, John. So, I thin...</td>\n",
       "      <td>Jeremy Barnum</td>\n",
       "      <td>Chief Financial Officer</td>\n",
       "      <td>banker</td>\n",
       "      <td>data/raw/jpm/jpm-4q23-earnings-call-transcript...</td>\n",
       "      <td>Direct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>Q4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hey. Good morning. Maybe just to follow up in ...</td>\n",
       "      <td>Yeah. Both good questions. So let's do reprice...</td>\n",
       "      <td>Jeremy Barnum</td>\n",
       "      <td>Chief Financial Officer</td>\n",
       "      <td>banker</td>\n",
       "      <td>data/raw/jpm/jpm-4q23-earnings-call-transcript...</td>\n",
       "      <td>Direct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year quarter  question_number  answer_number  \\\n",
       "0  2023      Q4              1.0            1.0   \n",
       "1  2023      Q4              2.0            1.0   \n",
       "2  2023      Q4              3.0            1.0   \n",
       "3  2023      Q4              4.0            1.0   \n",
       "4  2023      Q4              5.0            1.0   \n",
       "\n",
       "                                            question  \\\n",
       "0  Good morning. Thanks for all the comments on t...   \n",
       "1  Okay. And then just separately, you bought bac...   \n",
       "2  Thanks. Jeremy, could you give a little more c...   \n",
       "3  Okay. And then, just to follow up on the NII, ...   \n",
       "4  Hey. Good morning. Maybe just to follow up in ...   \n",
       "\n",
       "                                              answer   speaker_name  \\\n",
       "0  Yeah. Matt, not particularly updating. I think...  Jeremy Barnum   \n",
       "1  Yeah. Good question. And I think you framed it...  Jeremy Barnum   \n",
       "2  Yeah. Actually, John, this quarter, that's all...  Jeremy Barnum   \n",
       "3  Sure. Yeah, happy to do that, John. So, I thin...  Jeremy Barnum   \n",
       "4  Yeah. Both good questions. So let's do reprice...  Jeremy Barnum   \n",
       "\n",
       "                      role role_normalised  \\\n",
       "0  Chief Financial Officer          banker   \n",
       "1  Chief Financial Officer          banker   \n",
       "2  Chief Financial Officer          banker   \n",
       "3  Chief Financial Officer          banker   \n",
       "4  Chief Financial Officer          banker   \n",
       "\n",
       "                                          source_pdf   label  \n",
       "0  data/raw/jpm/jpm-4q23-earnings-call-transcript...  Direct  \n",
       "1  data/raw/jpm/jpm-4q23-earnings-call-transcript...  Direct  \n",
       "2  data/raw/jpm/jpm-4q23-earnings-call-transcript...  Direct  \n",
       "3  data/raw/jpm/jpm-4q23-earnings-call-transcript...  Direct  \n",
       "4  data/raw/jpm/jpm-4q23-earnings-call-transcript...  Direct  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 215\n"
     ]
    }
   ],
   "source": [
    "# Load the labelled dataset.\n",
    "url = 'https://raw.githubusercontent.com/JSA10/cam_ds_ep_FinSight/refs/heads/main/data/processed/jpm/cleaned/jpm_2023_2024_qa_labelled.csv'\n",
    "jpm_2023_2024_qa_labelled = pd.read_csv(url)\n",
    "\n",
    "# View the dataset.\n",
    "jpm_2023_2024_qa_labelled = jpm_2023_2024_qa_labelled.drop('Unnamed: 0', axis=1)\n",
    "display(jpm_2023_2024_qa_labelled.head())\n",
    "print('Number of examples:', jpm_2023_2024_qa_labelled.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a0c29a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split datasets while keeping answers for the same question grouped.\n",
    "def stratified_group_split(df, group_key, label_col='label', test_size=0.5, random_state=SEED):\n",
    "\n",
    "    y = (df[label_col].astype(str).str.strip().str.lower() == 'evasive').astype(int).values\n",
    "    groups = df[group_key].values\n",
    "    X_dummy = np.zeros(len(df))  # required placeholder\n",
    "\n",
    "    # Choose k so one fold approximates to test size.\n",
    "    n_splits = max(2, int(round(1.0 / float(test_size))))\n",
    "    sgkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    best = None\n",
    "    best_gap = None\n",
    "    for tr_idx, te_idx in sgkf.split(X_dummy, y, groups):\n",
    "        prop = len(te_idx) / len(df)\n",
    "        gap = abs(prop - test_size)\n",
    "        if best is None or gap < best_gap:\n",
    "            best = (tr_idx, te_idx)\n",
    "            best_gap = gap\n",
    "\n",
    "    train_idx, test_idx = best\n",
    "\n",
    "    # Name the held-out fold val, keep the rest as test.\n",
    "    val_df  = df.iloc[test_idx].reset_index(drop=True)\n",
    "    test_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "    return val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dee3a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a group key so that all answers for the same question stay in the same set. \n",
    "jpm_2023_2024_qa_labelled['group_key'] = (\n",
    "    jpm_2023_2024_qa_labelled['year'].astype(str) + '_' +\n",
    "    jpm_2023_2024_qa_labelled['quarter'].astype(str) + '_' +\n",
    "    jpm_2023_2024_qa_labelled['question_number'].astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66cd170d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of validation examples: 104 \n",
      "label\n",
      "Direct     78\n",
      "Evasive    26\n",
      "Name: count, dtype: int64\n",
      "Number of test examples: 111 \n",
      "label\n",
      "Direct     95\n",
      "Evasive    16\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split into validation and test set.\n",
    "jpm_val_qa_labelled, jpm_test_qa_labelled = stratified_group_split(\n",
    "    jpm_2023_2024_qa_labelled,\n",
    "    group_key='group_key',\n",
    "    label_col='label'\n",
    ")\n",
    "\n",
    "print(f'Number of validation examples: {jpm_val_qa_labelled.shape[0]} \\n{jpm_val_qa_labelled[\"label\"].value_counts()}')\n",
    "print(f'Number of test examples: {jpm_test_qa_labelled.shape[0]} \\n{jpm_test_qa_labelled[\"label\"].value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8d9aa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the datasets.\n",
    "jpm_val_qa_labelled.to_csv('../data/processed/jpm/cleaned/jpm_val_qa_labelled.csv')\n",
    "jpm_test_qa_labelled.to_csv('../data/processed/jpm/cleaned/jpm_test_qa_labelled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0f2172",
   "metadata": {},
   "source": [
    "### **3.2 Baseline Set Up**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71fc3fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of evasive phrases\n",
    "EVASIVE_PHRASES = [\n",
    "    r\"\\btoo early\\b\",\n",
    "    r\"\\bcan't (?:comment|share|discuss)\\b\",\n",
    "    r\"\\bwon't (?:comment|share|provide)\\b\",\n",
    "    r\"\\bno (?:update|comment)\\b\",\n",
    "    r\"\\bwe (?:don't|do not) (?:break out|provide guidance)\\b\",\n",
    "    r\"\\bnot (?:going to|able to) (?:comment|share|provide)\\b\",\n",
    "    r\"\\bwe'll (?:come back|circle back)\\b\",\n",
    "    r\"\\bnot something we disclose\\b\",\n",
    "    r\"\\bas (?:we|I) (?:said|mentioned)\\b\",\n",
    "    r\"\\bgenerally speaking\\b\",\n",
    "    r\"\\bit's premature\\b\",\n",
    "    r\"\\bit's difficult to say\\b\",\n",
    "    r\"\\bI (?:wouldn't|won't) want to (?:speculate|get into)\\b\",\n",
    "    r\"\\bI (?:think|guess|suppose)\\b\",\n",
    "    r\"\\bkind of\\b\",\n",
    "    r\"\\bsort of\\b\",\n",
    "    r\"\\baround\\b\",\n",
    "    r\"\\broughly\\b\",\n",
    "    r\"\\bwe (?:prefer|plan) not to\\b\",\n",
    "    r\"\\bwe're not prepared to\\b\",\n",
    "]\n",
    "\n",
    "# List of words that suggest the answer needs specific financial numbers to properly answer the question.\n",
    "SPECIFICITY_TRIGGERS = [\n",
    "    \"how much\",\"how many\",\"what is\",\"what are\",\"when\",\"which\",\"where\",\"who\",\"why\",\n",
    "    \"range\",\"guidance\",\"margin\",\"capex\",\"opex\",\"revenue\",\"sales\",\"eps\",\"ebitda\",\n",
    "    \"timeline\",\"date\",\"target\",\"growth\",\"update\",\"split\",\"dividend\",\"cost\",\"price\",\n",
    "    \"units\",\"volumes\",\"gross\",\"net\",\"tax\",\"percentage\",\"utilization\",\"order book\"\n",
    "]\n",
    "\n",
    "NUMERIC_PATTERN = r\"(?:\\d+(?:\\.\\d+)?%|\\b\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?\\b|£|\\$|€)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4464305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for semantic similarity.\n",
    "_sbert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "def semantic_sim(q, a):\n",
    "    qv, av = _sbert.encode([q, a], normalize_embeddings=True)\n",
    "    return float(np.dot(qv, av))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96c2fff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute baseline evasion score.\n",
    "def baseline_evasion_score(q, a):\n",
    "    # 1. Semantic similarity\n",
    "    sim = semantic_sim(q, a) # calculates semantic similarity using previous function\n",
    "    sim_component = (1 - sim) * 45 # less similar the answer is, the bigger the contribution to the evasion score, scaled by 45\n",
    "\n",
    "    # 2. Numerical specificity- Does the question require and answer with financial figures/ a specific answer?\n",
    "    needs_num = any(t in q.lower() for t in SPECIFICITY_TRIGGERS) # true if the question requires a numeric/ specific answer\n",
    "    has_num = bool(re.search(NUMERIC_PATTERN, a)) # true if the answer includes a number \n",
    "    numeric_component = 25 if needs_num and not has_num else 0 # score of 25 if the question needs a number but the answer doesn't give one\n",
    "\n",
    "    # 3. Evasive phrases- does the answer contain evasive phrases?\n",
    "    phrase_hits = sum(len(re.findall(p, a.lower())) for p in EVASIVE_PHRASES) # counts how many times an evasive phrase appears in the answer\n",
    "    phrase_component = min(3, phrase_hits) * 8 # max of 3 hits counted, each hit = 8 points \n",
    "\n",
    "    # Final evasion score.\n",
    "    score = min(100, sim_component + numeric_component + phrase_component) # adds components together and caps score at 100\n",
    "    \n",
    "    return score, sim, phrase_hits, needs_num, has_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feed0511",
   "metadata": {},
   "source": [
    "### **3.3 LLM Model Set Up**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "628c4653",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Model name checkpoints.\n",
    "roberta_name = 'roberta-large-mnli'\n",
    "deberta_name = 'microsoft/deberta-large-mnli'\n",
    "zs_deberta_name = 'MoritzLaurer/deberta-v3-large-zeroshot-v2.0'\n",
    "\n",
    "# Load tokenizers and models.\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained(roberta_name)\n",
    "roberta = AutoModelForSequenceClassification.from_pretrained(roberta_name)\n",
    "\n",
    "deberta_tokenizer = AutoTokenizer.from_pretrained(deberta_name)\n",
    "deberta = AutoModelForSequenceClassification.from_pretrained(deberta_name)\n",
    "\n",
    "zs_deberta_tokenizer = AutoTokenizer.from_pretrained(zs_deberta_name)\n",
    "zs_deberta = AutoModelForSequenceClassification.from_pretrained(zs_deberta_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61dd3ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta id2label: {0: 'CONTRADICTION', 1: 'NEUTRAL', 2: 'ENTAILMENT'}\n",
      "deberta id2label: {0: 'CONTRADICTION', 1: 'NEUTRAL', 2: 'ENTAILMENT'}\n",
      "zs_deberta id2label: {0: 'entailment', 1: 'not_entailment'}\n"
     ]
    }
   ],
   "source": [
    "# Verify label order per model.\n",
    "print(\"roberta id2label:\", roberta.config.id2label)\n",
    "print(\"deberta id2label:\", deberta.config.id2label)\n",
    "print(\"zs_deberta id2label:\", zs_deberta.config.id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4a9182",
   "metadata": {},
   "source": [
    "- Roberta and deberta have the standard 3 MNLI labels whereas zero shot deberta is binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1cd9f96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add models and tokenizers to dictionary.\n",
    "models_and_tokenizers = {\n",
    "        'roberta': (roberta, roberta_tokenizer),\n",
    "        'deberta': (deberta, deberta_tokenizer),\n",
    "        'zs_deberta': (zs_deberta, zs_deberta_tokenizer)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dccd8771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.autograd.grad_mode.set_grad_enabled(mode=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device \n",
    "USE_MPS = True\n",
    "\n",
    "if USE_MPS:\n",
    "    device = torch.device('mps')\n",
    "    DTYPE = torch.float32\n",
    "else:\n",
    "    device = device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    DTYPE = torch.float16 if device.type == \"cuda\" else torch.float32\n",
    "\n",
    "for model, tok in models_and_tokenizers.values():\n",
    "    model.to(device, dtype=DTYPE).eval()\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29de61d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build the premise for the model (question + answer).\n",
    "def build_premise(q, a):\n",
    "    return f'[QUESTION] {q} [ANSWER] {a}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044aad14",
   "metadata": {},
   "source": [
    "The following functions are helper functions for handling long Q/A text pairs by:\n",
    "- Figuring out out how much text fits\n",
    "- Splitting the answer into chunks\n",
    "- Encoding question + answer pairs, handling overflow\n",
    "- Retrieving the correct output label indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f50a3315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the max sequence length for the model.\n",
    "def model_max_len(tokenizer, model):\n",
    "    m = getattr(tokenizer, \"model_max_length\", None) # try to get max length from tokenizer \n",
    "    if m is None or m == int(1e30):\n",
    "        m = getattr(getattr(model, \"config\", None), \"max_position_embeddings\", 512) # default to 512 if not found\n",
    "    return int(m or 512)\n",
    "\n",
    "# Function to count how many tokens a text will take.\n",
    "def token_len(tokenizer, text):\n",
    "    return len(tokenizer.encode(text, add_special_tokens=False))\n",
    "\n",
    "# Function to calculate how much room is left for the answer in a Q/A pair\n",
    "def compute_answer_budget(tokenizer, model, question, hyp_max_tokens, q_cap=128, safety_margin=12):\n",
    "    max_len = model_max_len(tokenizer, model)           \n",
    "    specials = tokenizer.num_special_tokens_to_add(pair=True)\n",
    "    q_tokens = min(token_len(tokenizer, question), q_cap)\n",
    "    budget = max_len - specials - q_tokens - hyp_max_tokens - safety_margin\n",
    "    return max(32, budget) # ensure at least 32 tokens.\n",
    "\n",
    "# Function to split long answers into overlapping chunks that fit into the token budget.\n",
    "def chunk_answer_for_pair(tokenizer, answer, answer_budget, stride_tokens=128):\n",
    "\n",
    "    toks = tokenizer.tokenize(answer) # break answer into tokens.\n",
    "    if len(toks) <= answer_budget:\n",
    "        return [answer] # return as a single chunk if the answer fits inside the budget.\n",
    "\n",
    "    chunks, i = [], 0 # split long answers into overlapping chunks \n",
    "    while i < len(toks):\n",
    "        window_tokens = toks[i:i+answer_budget]\n",
    "        window_text = tokenizer.convert_tokens_to_string(window_tokens)\n",
    "        chunks.append(window_text)\n",
    "        if i + answer_budget >= len(toks):\n",
    "            break\n",
    "        i += max(1, answer_budget - stride_tokens)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c945812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode premise and hypothesis, handle overflow by chunking, run through model and return logits for each chunk.\n",
    "def pair_logits_chunks(model, tokenizer, device, premise, hypothesis, max_length=None, stride=128):\n",
    "    if max_length is None:\n",
    "        max_length = model_max_len(tokenizer, model)\n",
    "\n",
    "    # Encode Q/A pairs into tensors.\n",
    "    enc = tokenizer(\n",
    "        premise,\n",
    "        hypothesis,\n",
    "        return_tensors='pt',\n",
    "        truncation='only_first',          \n",
    "        max_length=max_length,\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        padding=True             \n",
    "    )\n",
    "\n",
    "    # keep only keys the model expects\n",
    "    input_names = set(getattr(tokenizer, \"model_input_names\",\n",
    "                              [\"input_ids\", \"attention_mask\", \"token_type_ids\"]))\n",
    "\n",
    "    # Extract one encoded chunk into a batch the model can handle and move it to device \n",
    "    def to_batch(enc_dict, i=None):\n",
    "        batch = {}\n",
    "        for k, v in enc_dict.items():\n",
    "            if k in input_names and isinstance(v, torch.Tensor):\n",
    "                batch[k] = (v[i:i+1] if i is not None else v).to(device)\n",
    "        return batch\n",
    "\n",
    "    # if there is only a single chunk, run model + return logits.\n",
    "    if enc[\"input_ids\"].shape[0] == 1:\n",
    "        batch = to_batch(enc)\n",
    "        with torch.no_grad():\n",
    "            logits = model(**batch).logits\n",
    "        return [logits.squeeze(0)]\n",
    "\n",
    "    # if there are multiple overflowed chunks, loop over each chunk, get logits and return list \n",
    "    logits_list = []\n",
    "    n = enc[\"input_ids\"].shape[0]\n",
    "    for i in range(n):\n",
    "        batch = to_batch(enc, i)\n",
    "        with torch.no_grad():\n",
    "            out = model(**batch).logits\n",
    "        logits_list.append(out.squeeze(0))\n",
    "    return logits_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "183460f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the label index for a given class name.\n",
    "def get_label_idx(model, name, default):\n",
    "    id2label = getattr(model.config, \"id2label\", {}) # get model mapping from class IDs to labels \n",
    "    if id2label:\n",
    "        for k, v in id2label.items():\n",
    "            if name in str(v).lower():\n",
    "                return int(k)\n",
    "    return default # return to default if not found "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46b0e874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to turn raw model outputs into a probability of entailment. \n",
    "def p_entail_from_logits(logits, model, temperature=None):\n",
    "\n",
    "    if temperature is not None and float(temperature) != 1.0:\n",
    "        logits = logits / float(temperature)\n",
    "\n",
    "    ent_i = get_label_idx(model, \"entail\", 2 if logits.shape[-1]==3 else 1) # if 3 classes = assume index 2, if binary = assume index 1\n",
    "    probs = torch.softmax(logits, dim=-1) # convert logits into probabilities using softmax.\n",
    "    return float(probs[ent_i])\n",
    "\n",
    "\n",
    "# Direct and evasive prompts.\n",
    "DIRECT_TEMPLATES = [\n",
    "    \"The answer gives a direct and specific response to the question.\",\n",
    "    \"The answer addresses the question explicitly and concretely.\",\n",
    "    \"The answer responds directly with actionable specifics.\",\n",
    "    \"The answer provides the requested figures.\", \n",
    "    \"The answer is specific and on-topic.\"\n",
    "]\n",
    "EVASIVE_TEMPLATES = [\n",
    "    \"The answer avoids giving a direct response to the question.\",\n",
    "    \"The answer is evasive or deflects without specifics.\",\n",
    "    \"The answer sidesteps the question and withholds details.\",\n",
    "    \"The answer avoids specifics or deflects.\", \n",
    "    \"The answer does not address the question.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dba9f602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to produce normalised probabilities for direct vs evasive \n",
    "def llm_evasion_score(question, answer, model, tokenizer, device, temperature=2.0, stride=128):\n",
    "    max_len = model_max_len(tokenizer, model)\n",
    "    n_dir, n_eva = len(DIRECT_TEMPLATES), len(EVASIVE_TEMPLATES)\n",
    "\n",
    "    p_ent_direct_list, p_ent_evasive_list = [], []\n",
    "\n",
    "    premise = f\"Q: {question}\\nA: {answer}\"\n",
    "\n",
    "    def agg_pents(pents, k=1):\n",
    "    # Take average of top-k highest probs\n",
    "        return float(np.mean(sorted(pents, reverse=True)[:k]))\n",
    "\n",
    "    # Collect P(entailment) for DIRECT hypotheses (over chunks), then mean over templates\n",
    "    for h in DIRECT_TEMPLATES:\n",
    "        logits_chunks = pair_logits_chunks(model, tokenizer, device, premise, h, max_length=max_len, stride=stride)\n",
    "        # For each chunk, compute P(entail); take the max across chunks \n",
    "        pents = [p_entail_from_logits(log, model, temperature) for log in logits_chunks]\n",
    "        p_ent_direct_list.append(agg_pents(pents, k=2))\n",
    "\n",
    "    # Same for EVASIVE hypotheses\n",
    "    for h in EVASIVE_TEMPLATES:\n",
    "        logits_chunks = pair_logits_chunks(model, tokenizer, device, premise, h, max_length=max_len, stride=stride)\n",
    "        pents = [p_entail_from_logits(log, model, temperature) for log in logits_chunks]\n",
    "        p_ent_evasive_list.append(agg_pents(pents, k=2))\n",
    "\n",
    "    # Mean over templates\n",
    "    p_ent_direct  = float(torch.tensor(p_ent_direct_list).mean())\n",
    "    p_ent_evasive = float(torch.tensor(p_ent_evasive_list).mean())\n",
    "\n",
    "    # Normalisation\n",
    "    denom = p_ent_evasive + p_ent_direct + 1e-9\n",
    "    p_evasive = float(p_ent_evasive / denom)\n",
    "    p_direct  = 1.0 - p_evasive\n",
    "\n",
    "    return {\n",
    "        'p_direct': p_direct,\n",
    "        'p_evasive': p_evasive,\n",
    "        'p_ent_direct': p_ent_direct,\n",
    "        'p_ent_evasive': p_ent_evasive\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c42cb3",
   "metadata": {},
   "source": [
    "### **3.4 Proof Of Concept**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30df4d38",
   "metadata": {},
   "source": [
    "To verify that the evasion scoring of the baseline and LLMs was logical at a basic level and the models behave as expected, the models were fed two simple prompts that were clearly direct or evasive, to which each model generated a probability of evasiveness (raw evasion score). This was also to check that the scoring system had been set-up correctly, i.e high evasion score = high probability of evasiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0faa6ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Probe 1 ===\n",
      "Q: What was CET1 at year-end?\n",
      "A: CET1 ratio was 13.4%, up 40bps YoY.\n",
      "DeBERTa evasive probabilitiy:                40.7 %\n",
      "Avg LLM evasive probabilitiy:                21.2 %\n",
      "Baseline evasive probabilitiy:               23.1 %\n",
      "Blended (base+DeBERTa) evasive probabilitiy: 35.4 % [LLM_WEIGHT=0.70]\n",
      "\n",
      "=== Probe 2 ===\n",
      "Q: When will you release site losses?\n",
      "A: We don’t provide those numbers at this time.\n",
      "DeBERTa evasive probabilitiy:                72.6 %\n",
      "Avg LLM evasive probabilitiy:                78.1 %\n",
      "Baseline evasive probabilitiy:               59.1 %\n",
      "Blended (base+DeBERTa) evasive probabilitiy: 68.6 % [LLM_WEIGHT=0.70]\n"
     ]
    }
   ],
   "source": [
    "# --- Probe: DeBERTa, Blended (baseline + DeBERTa), and Avg LLM ---\n",
    "def probe_deberta_blend_avg(LLM_WEIGHT=0.70):\n",
    "    pairs = [\n",
    "        (\"What was CET1 at year-end?\", \"CET1 ratio was 13.4%, up 40bps YoY.\"),  # DIRECT\n",
    "        (\"When will you release site losses?\", \"We don’t provide those numbers at this time.\")  # EVASIVE\n",
    "    ]\n",
    "\n",
    "    # Make sure we can access DeBERTa from your dict\n",
    "    m_deb, t_deb = models_and_tokenizers[\"deberta\"]\n",
    "\n",
    "    for i, (q, a) in enumerate(pairs, 1):\n",
    "        # --- DeBERTa ---\n",
    "        r_deb = llm_evasion_score(q, a, m_deb, t_deb, device)\n",
    "        p_eva_deb = float(r_deb[\"p_evasive\"])  # 0..1\n",
    "\n",
    "        # --- Avg LLM over all models you loaded ---\n",
    "        all_ps = []\n",
    "        for mname, (m, t) in models_and_tokenizers.items():\n",
    "            r = llm_evasion_score(q, a, m, t, device)\n",
    "            all_ps.append(float(r[\"p_evasive\"]))\n",
    "        p_eva_avg = float(np.mean(all_ps))\n",
    "\n",
    "        # --- Baseline (0..100) then blend with DeBERTa using LLM_WEIGHT ---\n",
    "        base_score, *_ = baseline_evasion_score(q, a)   # 0..100\n",
    "        base01 = base_score / 100.0\n",
    "        p_eva_blended = (1.0 - LLM_WEIGHT) * base01 + LLM_WEIGHT * p_eva_deb\n",
    "\n",
    "        print(f\"\\n=== Probe {i} ===\")\n",
    "        print(f\"Q: {q}\\nA: {a}\")\n",
    "        print(f\"DeBERTa evasive probabilitiy:                {p_eva_deb*100:.1f} %\")\n",
    "        print(f\"Avg LLM evasive probabilitiy:                {p_eva_avg*100:.1f} %\")\n",
    "        print(f\"Baseline evasive probabilitiy:               {base_score:.1f} %\")\n",
    "        print(f\"Blended (base+DeBERTa) evasive probabilitiy: {p_eva_blended*100:.1f} % \"\n",
    "              f\"[LLM_WEIGHT={LLM_WEIGHT:.2f}]\")\n",
    "\n",
    "# Run proof of concept.\n",
    "LLM_WEIGHT = 0.70\n",
    "probe_deberta_blend_avg(LLM_WEIGHT=LLM_WEIGHT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f9ca7c",
   "metadata": {},
   "source": [
    "**Proof of Concept Results**\n",
    "- **Probe 1:** All models leaned towards direct (low evasive probability) which is correct, with the avg_llm giving the lowest probability (21.2%).\n",
    "- **Probe 2:** All models assigned high evasive probabilities, correctly flagging it as evasive. Again the avg_llm gave the most extreme correct score, assigning the highest probability (78.1%).\n",
    "- **Overall:** This demonstrates the pipeline behaves as intended when faced with basic QA pairs.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8306748f",
   "metadata": {},
   "source": [
    "### **3.5 Generate Evasion Scores**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab400b1",
   "metadata": {},
   "source": [
    "Evasion scores were generated on the J.P. Morgan validation dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b92e455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate evasion scores for baseline + LLMs.\n",
    "def evasion_pipeline_val(df, models_and_tokenizers, device, LLM_WEIGHT):\n",
    "    rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        q, a = str(row['question']), str(row['answer'])\n",
    "\n",
    "        # baseline (raw 0..100 float)\n",
    "        base_score, *_ = baseline_evasion_score(q, a)\n",
    "\n",
    "        rec = {\n",
    "            'question_number': row.get('question_number'),\n",
    "            'question': q,\n",
    "            'answer': a,\n",
    "            'evasion_score_baseline': float(base_score),\n",
    "            'label': row['label'],  # keep human label\n",
    "        }\n",
    "\n",
    "        llm_scores = {}\n",
    "        for name, (m, t) in models_and_tokenizers.items():\n",
    "            r = llm_evasion_score(q, a, m, t, device)\n",
    "            s = float(100.0 * r['p_evasive'])\n",
    "            rec[f'evasion_score_{name}'] = s\n",
    "            llm_scores[name] = s\n",
    "\n",
    "        llm_avg = float(np.mean(list(llm_scores.values()))) if llm_scores else 0.0\n",
    "        rec['evasion_score_llm_avg'] = llm_avg\n",
    "        rec['evasion_score_blended'] = float(np.clip((1.0 - LLM_WEIGHT)*base_score + LLM_WEIGHT*llm_avg, 0.0, 100.0))\n",
    "\n",
    "        rows.append(rec)\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a084aa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform an initial run to get evasion scores on validation set. \n",
    "LLM_WEIGHT = 0.70\n",
    "\n",
    "jpm_val_qa_scores = evasion_pipeline_val(\n",
    "    jpm_val_qa_labelled, \n",
    "    models_and_tokenizers, \n",
    "    device, \n",
    "    LLM_WEIGHT\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bbd9d505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_number</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>evasion_score_baseline</th>\n",
       "      <th>label</th>\n",
       "      <th>evasion_score_roberta</th>\n",
       "      <th>evasion_score_deberta</th>\n",
       "      <th>evasion_score_zs_deberta</th>\n",
       "      <th>evasion_score_llm_avg</th>\n",
       "      <th>evasion_score_blended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Good morning. Thanks for all the comments on t...</td>\n",
       "      <td>Yeah. Matt, not particularly updating. I think...</td>\n",
       "      <td>30.251499</td>\n",
       "      <td>Direct</td>\n",
       "      <td>41.009685</td>\n",
       "      <td>71.487081</td>\n",
       "      <td>80.011915</td>\n",
       "      <td>64.169560</td>\n",
       "      <td>53.994142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Okay. And then, just to follow up on the NII, ...</td>\n",
       "      <td>Sure. Yeah, happy to do that, John. So, I thin...</td>\n",
       "      <td>36.422580</td>\n",
       "      <td>Direct</td>\n",
       "      <td>24.478366</td>\n",
       "      <td>42.467039</td>\n",
       "      <td>26.846263</td>\n",
       "      <td>31.263889</td>\n",
       "      <td>32.811496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Hey. Good morning. Maybe just to follow up in ...</td>\n",
       "      <td>Yeah. Both good questions. So let's do reprice...</td>\n",
       "      <td>60.731791</td>\n",
       "      <td>Direct</td>\n",
       "      <td>41.489162</td>\n",
       "      <td>46.582340</td>\n",
       "      <td>15.742660</td>\n",
       "      <td>34.604720</td>\n",
       "      <td>42.442842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Hey. Good morning. I guess maybe one question ...</td>\n",
       "      <td>Right. Okay, Ebrahim. So, I think a lot of tho...</td>\n",
       "      <td>43.920715</td>\n",
       "      <td>Direct</td>\n",
       "      <td>51.206240</td>\n",
       "      <td>62.483139</td>\n",
       "      <td>54.168614</td>\n",
       "      <td>55.952665</td>\n",
       "      <td>52.343080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Hey. Good morning. I guess maybe one question ...</td>\n",
       "      <td>So, one can speculate about different trajecto...</td>\n",
       "      <td>50.257613</td>\n",
       "      <td>Evasive</td>\n",
       "      <td>39.608096</td>\n",
       "      <td>69.655925</td>\n",
       "      <td>66.430823</td>\n",
       "      <td>58.564948</td>\n",
       "      <td>56.072747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_number                                           question  \\\n",
       "0              1.0  Good morning. Thanks for all the comments on t...   \n",
       "1              4.0  Okay. And then, just to follow up on the NII, ...   \n",
       "2              5.0  Hey. Good morning. Maybe just to follow up in ...   \n",
       "3              6.0  Hey. Good morning. I guess maybe one question ...   \n",
       "4              6.0  Hey. Good morning. I guess maybe one question ...   \n",
       "\n",
       "                                              answer  evasion_score_baseline  \\\n",
       "0  Yeah. Matt, not particularly updating. I think...               30.251499   \n",
       "1  Sure. Yeah, happy to do that, John. So, I thin...               36.422580   \n",
       "2  Yeah. Both good questions. So let's do reprice...               60.731791   \n",
       "3  Right. Okay, Ebrahim. So, I think a lot of tho...               43.920715   \n",
       "4  So, one can speculate about different trajecto...               50.257613   \n",
       "\n",
       "     label  evasion_score_roberta  evasion_score_deberta  \\\n",
       "0   Direct              41.009685              71.487081   \n",
       "1   Direct              24.478366              42.467039   \n",
       "2   Direct              41.489162              46.582340   \n",
       "3   Direct              51.206240              62.483139   \n",
       "4  Evasive              39.608096              69.655925   \n",
       "\n",
       "   evasion_score_zs_deberta  evasion_score_llm_avg  evasion_score_blended  \n",
       "0                 80.011915              64.169560              53.994142  \n",
       "1                 26.846263              31.263889              32.811496  \n",
       "2                 15.742660              34.604720              42.442842  \n",
       "3                 54.168614              55.952665              52.343080  \n",
       "4                 66.430823              58.564948              56.072747  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the results.\n",
    "jpm_val_qa_scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9606c551",
   "metadata": {},
   "source": [
    "### **3.6 Fine-Tune Thresholds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e32cd61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract ground truth (1 = Evasive, 0 = Direct)\n",
    "def extract_y_true(df):\n",
    "    return (df['label'].astype(str).str.strip().str.lower() == 'evasive').astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5028145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tune the threshold on raw evasion scores per model.\n",
    "def threshold_tuner(df, score_col, thr_grid, k_percents=(10, 25, 50)):\n",
    "    y_true = extract_y_true(df)                     # get true labels\n",
    "    scores = df[score_col].astype(float).values     # get raw evasion scores \n",
    "\n",
    "    n = len(scores)  # <-- define n BEFORE using it\n",
    "    k_take = {k: max(1, int(np.ceil(n * k / 100))) for k in k_percents}\n",
    "\n",
    "    rows = []\n",
    "    for thr in thr_grid:\n",
    "        y_pred = (scores >= thr).astype(int) # label response evasive (1) if score is higher than threshold\n",
    "\n",
    "        precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "        prec_cls, rec_cls, f1_cls, sup_cls = precision_recall_fscore_support(\n",
    "            y_true, y_pred, labels=[0,1], average=None, zero_division=0\n",
    "        )\n",
    "\n",
    "        predpos_idx = np.where(y_pred == 1)[0]\n",
    "        p_at_predpos = {}\n",
    "        if len(predpos_idx) > 0:\n",
    "            predpos_sorted = predpos_idx[np.argsort(-scores[predpos_idx])]\n",
    "            for k in k_percents:\n",
    "                k_pp = min(len(predpos_sorted), k_take[k])  # cap by pool size\n",
    "                if k_pp > 0:\n",
    "                    take = predpos_sorted[:k_pp]\n",
    "                    p_at_predpos[f\"P@{k}%_predpos\"] = float(y_true[take].mean())\n",
    "                else:\n",
    "                    p_at_predpos[f\"P@{k}%_predpos\"] = 0.0\n",
    "        else:\n",
    "            for k in k_percents:\n",
    "                p_at_predpos[f\"P@{k}%_predpos\"] = 0.0\n",
    "\n",
    "        rows.append({\n",
    "            'threshold': float(thr),\n",
    "            #'precision': precision,\n",
    "            #'recall': recall,\n",
    "            #'f1': f1,\n",
    "            #'accuracy': accuracy,\n",
    "            #'f1_macro':  (f1_cls[0] + f1_cls[1]) / 2.0,\n",
    "            'precision_direct':  prec_cls[0],\n",
    "            'recall_direct':     rec_cls[0],\n",
    "            'f1_direct':         f1_cls[0],\n",
    "\n",
    "            'precision_evasive': prec_cls[1],\n",
    "            'recall_evasive':    rec_cls[1],\n",
    "            'f1_evasive':        f1_cls[1],\n",
    "            **p_at_predpos\n",
    "        })\n",
    "    results = pd.DataFrame(rows).sort_values(\n",
    "        by=['f1_evasive', 'recall_evasive'],\n",
    "        ascending=[False, False]\n",
    "        ).reset_index(drop=True)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0af8e354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define thr_grid.\n",
    "thr_grid = np.arange(1, 100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a6ee9903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline / blended / avg LLM \n",
    "base_results = threshold_tuner(jpm_val_qa_scores, 'evasion_score_baseline', thr_grid)\n",
    "llm_avg_results = threshold_tuner(jpm_val_qa_scores, 'evasion_score_llm_avg', thr_grid)\n",
    "blend_results = threshold_tuner(jpm_val_qa_scores, 'evasion_score_blended', thr_grid)\n",
    "\n",
    "# Individual LLM models\n",
    "roberta_results = threshold_tuner(jpm_val_qa_scores, 'evasion_score_roberta', thr_grid)\n",
    "deberta_results = threshold_tuner(jpm_val_qa_scores, 'evasion_score_deberta', thr_grid)\n",
    "zs_deberta_results = threshold_tuner(jpm_val_qa_scores, 'evasion_score_zs_deberta', thr_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "43cfc5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline — Top 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>precision_direct</th>\n",
       "      <th>recall_direct</th>\n",
       "      <th>f1_direct</th>\n",
       "      <th>precision_evasive</th>\n",
       "      <th>recall_evasive</th>\n",
       "      <th>f1_evasive</th>\n",
       "      <th>P@10%_predpos</th>\n",
       "      <th>P@25%_predpos</th>\n",
       "      <th>P@50%_predpos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.089744</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.260417</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.409836</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.255102</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.255102</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  precision_direct  recall_direct  f1_direct  precision_evasive  \\\n",
       "0       22.0          0.875000       0.089744   0.162791           0.260417   \n",
       "1       20.0          0.833333       0.064103   0.119048           0.255102   \n",
       "2       21.0          0.833333       0.064103   0.119048           0.255102   \n",
       "3        1.0          0.000000       0.000000   0.000000           0.250000   \n",
       "4        2.0          0.000000       0.000000   0.000000           0.250000   \n",
       "\n",
       "   recall_evasive  f1_evasive  P@10%_predpos  P@25%_predpos  P@50%_predpos  \n",
       "0        0.961538    0.409836       0.272727       0.269231       0.230769  \n",
       "1        0.961538    0.403226       0.272727       0.269231       0.230769  \n",
       "2        0.961538    0.403226       0.272727       0.269231       0.230769  \n",
       "3        1.000000    0.400000       0.272727       0.269231       0.230769  \n",
       "4        1.000000    0.400000       0.272727       0.269231       0.230769  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLM Avg — Top 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>precision_direct</th>\n",
       "      <th>recall_direct</th>\n",
       "      <th>f1_direct</th>\n",
       "      <th>precision_evasive</th>\n",
       "      <th>recall_evasive</th>\n",
       "      <th>f1_evasive</th>\n",
       "      <th>P@10%_predpos</th>\n",
       "      <th>P@25%_predpos</th>\n",
       "      <th>P@50%_predpos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.276596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46.0</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.397436</td>\n",
       "      <td>0.539130</td>\n",
       "      <td>0.298507</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.430108</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.089744</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.268041</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.422764</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.0</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.559322</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  precision_direct  recall_direct  f1_direct  precision_evasive  \\\n",
       "0       33.0          1.000000       0.128205   0.227273           0.276596   \n",
       "1       46.0          0.837838       0.397436   0.539130           0.298507   \n",
       "2       32.0          1.000000       0.089744   0.164706           0.268041   \n",
       "3       47.0          0.825000       0.423077   0.559322           0.296875   \n",
       "4       31.0          1.000000       0.076923   0.142857           0.265306   \n",
       "\n",
       "   recall_evasive  f1_evasive  P@10%_predpos  P@25%_predpos  P@50%_predpos  \n",
       "0        1.000000    0.433333       0.363636       0.230769           0.25  \n",
       "1        0.769231    0.430108       0.363636       0.230769           0.25  \n",
       "2        1.000000    0.422764       0.363636       0.230769           0.25  \n",
       "3        0.730769    0.422222       0.363636       0.230769           0.25  \n",
       "4        1.000000    0.419355       0.363636       0.230769           0.25  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Blended — Top 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>precision_direct</th>\n",
       "      <th>recall_direct</th>\n",
       "      <th>f1_direct</th>\n",
       "      <th>precision_evasive</th>\n",
       "      <th>recall_evasive</th>\n",
       "      <th>f1_evasive</th>\n",
       "      <th>P@10%_predpos</th>\n",
       "      <th>P@25%_predpos</th>\n",
       "      <th>P@50%_predpos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.243590</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.280488</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.407767</td>\n",
       "      <td>0.278481</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.419048</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.183908</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.413223</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  precision_direct  recall_direct  f1_direct  precision_evasive  \\\n",
       "0       41.0          0.863636       0.243590   0.380000           0.280488   \n",
       "1       42.0          0.840000       0.269231   0.407767           0.278481   \n",
       "2       35.0          0.900000       0.115385   0.204545           0.265957   \n",
       "3       36.0          0.900000       0.115385   0.204545           0.265957   \n",
       "4       34.0          0.888889       0.102564   0.183908           0.263158   \n",
       "\n",
       "   recall_evasive  f1_evasive  P@10%_predpos  P@25%_predpos  P@50%_predpos  \n",
       "0        0.884615    0.425926       0.272727       0.269231           0.25  \n",
       "1        0.846154    0.419048       0.272727       0.269231           0.25  \n",
       "2        0.961538    0.416667       0.272727       0.269231           0.25  \n",
       "3        0.961538    0.416667       0.272727       0.269231           0.25  \n",
       "4        0.961538    0.413223       0.272727       0.269231           0.25  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RoBERTa — Top 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>precision_direct</th>\n",
       "      <th>recall_direct</th>\n",
       "      <th>f1_direct</th>\n",
       "      <th>precision_evasive</th>\n",
       "      <th>recall_evasive</th>\n",
       "      <th>f1_evasive</th>\n",
       "      <th>P@10%_predpos</th>\n",
       "      <th>P@25%_predpos</th>\n",
       "      <th>P@50%_predpos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.141026</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.271739</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.423729</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.224719</td>\n",
       "      <td>0.268817</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.420168</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.412698</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  precision_direct  recall_direct  f1_direct  precision_evasive  \\\n",
       "0       28.0          0.916667       0.141026   0.244444           0.271739   \n",
       "1       27.0          0.909091       0.128205   0.224719           0.268817   \n",
       "2       25.0          1.000000       0.076923   0.142857           0.265306   \n",
       "3       26.0          0.900000       0.115385   0.204545           0.265957   \n",
       "4       18.0          1.000000       0.051282   0.097561           0.260000   \n",
       "\n",
       "   recall_evasive  f1_evasive  P@10%_predpos  P@25%_predpos  P@50%_predpos  \n",
       "0        0.961538    0.423729       0.454545       0.230769           0.25  \n",
       "1        0.961538    0.420168       0.454545       0.230769           0.25  \n",
       "2        1.000000    0.419355       0.454545       0.230769           0.25  \n",
       "3        0.961538    0.416667       0.454545       0.230769           0.25  \n",
       "4        1.000000    0.412698       0.454545       0.230769           0.25  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DeBERTa — Top 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>precision_direct</th>\n",
       "      <th>recall_direct</th>\n",
       "      <th>f1_direct</th>\n",
       "      <th>precision_evasive</th>\n",
       "      <th>recall_evasive</th>\n",
       "      <th>f1_evasive</th>\n",
       "      <th>P@10%_predpos</th>\n",
       "      <th>P@25%_predpos</th>\n",
       "      <th>P@50%_predpos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.448718</td>\n",
       "      <td>0.578512</td>\n",
       "      <td>0.295082</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.397436</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>0.287879</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  precision_direct  recall_direct  f1_direct  precision_evasive  \\\n",
       "0       56.0          0.813953       0.448718   0.578512           0.295082   \n",
       "1       55.0          0.815789       0.397436   0.534483           0.287879   \n",
       "2       22.0          1.000000       0.025641   0.050000           0.254902   \n",
       "3       23.0          1.000000       0.025641   0.050000           0.254902   \n",
       "4       24.0          1.000000       0.025641   0.050000           0.254902   \n",
       "\n",
       "   recall_evasive  f1_evasive  P@10%_predpos  P@25%_predpos  P@50%_predpos  \n",
       "0        0.692308    0.413793       0.363636       0.269231       0.307692  \n",
       "1        0.730769    0.413043       0.363636       0.269231       0.307692  \n",
       "2        1.000000    0.406250       0.363636       0.269231       0.307692  \n",
       "3        1.000000    0.406250       0.363636       0.269231       0.307692  \n",
       "4        1.000000    0.406250       0.363636       0.269231       0.307692  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ZS-DeBERTa — Top 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>precision_direct</th>\n",
       "      <th>recall_direct</th>\n",
       "      <th>f1_direct</th>\n",
       "      <th>precision_evasive</th>\n",
       "      <th>recall_evasive</th>\n",
       "      <th>f1_evasive</th>\n",
       "      <th>P@10%_predpos</th>\n",
       "      <th>P@25%_predpos</th>\n",
       "      <th>P@50%_predpos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.141026</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.271739</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.423729</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.269231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.269231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.269231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.269231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.120482</td>\n",
       "      <td>0.262626</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.416000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.269231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  precision_direct  recall_direct  f1_direct  precision_evasive  \\\n",
       "0       23.0          0.916667       0.141026   0.244444           0.271739   \n",
       "1       16.0          1.000000       0.076923   0.142857           0.265306   \n",
       "2       21.0          0.900000       0.115385   0.204545           0.265957   \n",
       "3       22.0          0.900000       0.115385   0.204545           0.265957   \n",
       "4       15.0          1.000000       0.064103   0.120482           0.262626   \n",
       "\n",
       "   recall_evasive  f1_evasive  P@10%_predpos  P@25%_predpos  P@50%_predpos  \n",
       "0        0.961538    0.423729       0.090909       0.192308       0.269231  \n",
       "1        1.000000    0.419355       0.090909       0.192308       0.269231  \n",
       "2        0.961538    0.416667       0.090909       0.192308       0.269231  \n",
       "3        0.961538    0.416667       0.090909       0.192308       0.269231  \n",
       "4        1.000000    0.416000       0.090909       0.192308       0.269231  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View top 5 configurations for each model.\n",
    "print('\\nBaseline — Top 5')\n",
    "display(base_results.head(5))\n",
    "print('\\nLLM Avg — Top 5') \n",
    "display(llm_avg_results.head(5))\n",
    "print('\\nBlended — Top 5')\n",
    "display(blend_results.head(5))\n",
    "print('\\nRoBERTa — Top 5') \n",
    "display(roberta_results.head(5))\n",
    "print('\\nDeBERTa — Top 5')\n",
    "display(deberta_results.head(5))\n",
    "print('\\nZS-DeBERTa — Top 5')\n",
    "display(zs_deberta_results.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4825f119",
   "metadata": {},
   "source": [
    "**Threshold Tuning Results**\n",
    "\n",
    "Across models, evasive recall is consistently high (~73-100%), showing most evasive answers are being flagged. However, this comes at the cosr of low precision (~0.26-0.30), meaning many direct answers are also misclassified as evasive. \n",
    "- **Baseline:** Thresholds ~20-22 give very high evasive recall (0.96-1.0) but extremely poor direct recall (<0.1).\n",
    "- **LLM Avg:** Thresholds ~41-46 improve direct recall (0.24-0.42) while keeping evasive recall high (-.73-0.88), but does not substantially raise precision.\n",
    "- **RoBERTa:** Threshold ~28 performs well for shortlist ranking with the highest P@10% (0.45). Strong choice if prioritising top-ranked hits.\n",
    "- **DeBERTa:** Threshold ~55–56 provides the best balance: direct recall ~0.40–0.45, direct F1 ~0.58, while still catching most evasives (recall ~0.69–0.73).\n",
    "- **ZS-DeBERTa:** Performs poorly on ranking (P@10% = 0.09). Not recommended.\n",
    "\n",
    "**Recommendation Going Forward**\n",
    "- Use DeBERTa (threshold ~55–56) for balanced detection (best overall F1 and recall trade-off).\n",
    "- Use RoBERTa (threshold ~28) when prioritising shortlist precision (P@10%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e0ecea",
   "metadata": {},
   "source": [
    "As the best model going forward for labelling answers as evasive vs direct is DeBERTa, the blended (baseline + LLM) threshold will need to be retuned for this particular model blend and the best blend weight established."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b4097fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tune the \n",
    "def tune_blend_weight(\n",
    "    df,\n",
    "    base_col='evasion_score_baseline',\n",
    "    llm_col='evasion_score_deberta',\n",
    "    weight_grid=np.linspace(0, 1, 41),   # 0.00..1.00 step 0.025\n",
    "    thr_grid=np.arange(1, 100, 1),\n",
    "    objective='f1_evasive',\n",
    "    tie_break='recall_evasive'\n",
    "):\n",
    "    base = df[base_col].astype(float).values\n",
    "    llm  = df[llm_col].astype(float).values\n",
    "\n",
    "    candidates = []\n",
    "    for w in weight_grid:\n",
    "        blended = np.clip((1.0 - w)*base + w*llm, 0.0, 100.0)\n",
    "        tmp = df.copy()\n",
    "        tmp['evasion_score_blended'] = blended\n",
    "\n",
    "        tt = threshold_tuner(tmp, 'evasion_score_blended', thr_grid)\n",
    "        if tt.empty:\n",
    "            continue\n",
    "\n",
    "        best = tt.sort_values(\n",
    "            by=[objective, tie_break, 'threshold'],\n",
    "            ascending=[False, False, True]\n",
    "        ).iloc[0].to_dict()\n",
    "        best.update({'weight': float(w)})\n",
    "        candidates.append(best)\n",
    "\n",
    "    if not candidates:\n",
    "        raise ValueError(\"No feasible (weight, threshold) found.\")\n",
    "\n",
    "    results = pd.DataFrame(candidates).sort_values(\n",
    "        by=[objective, tie_break, 'weight'],\n",
    "        ascending=[False, False, True]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return float(results.loc[0, 'weight']), float(results.loc[0, 'threshold']), results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f7afec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1) Tune on your existing validation scores ---\n",
    "BEST_W, BLENDED_THR, blend_leaderboard = tune_blend_weight(\n",
    "    jpm_val_qa_scores,\n",
    "    base_col='evasion_score_baseline',\n",
    "    llm_col='evasion_score_deberta',     # or 'evasion_score_llm_avg'\n",
    "    weight_grid=np.linspace(0, 1, 41),\n",
    "    thr_grid=thr_grid,\n",
    "    objective='f1_evasive',\n",
    "    tie_break='recall_evasive'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0178b05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best weight: 0.625 | Best blended threshold: 43.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>precision_direct</th>\n",
       "      <th>recall_direct</th>\n",
       "      <th>f1_direct</th>\n",
       "      <th>precision_evasive</th>\n",
       "      <th>recall_evasive</th>\n",
       "      <th>f1_evasive</th>\n",
       "      <th>P@10%_predpos</th>\n",
       "      <th>P@25%_predpos</th>\n",
       "      <th>P@50%_predpos</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43.0</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.424779</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.0</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.547009</td>\n",
       "      <td>0.292308</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.417582</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.547009</td>\n",
       "      <td>0.292308</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.417582</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  precision_direct  recall_direct  f1_direct  precision_evasive  \\\n",
       "0       43.0          0.882353       0.192308   0.315789           0.275862   \n",
       "1       41.0          0.875000       0.179487   0.297872           0.272727   \n",
       "2       42.0          0.875000       0.179487   0.297872           0.272727   \n",
       "3       52.0          0.820513       0.410256   0.547009           0.292308   \n",
       "4       55.0          0.820513       0.410256   0.547009           0.292308   \n",
       "\n",
       "   recall_evasive  f1_evasive  P@10%_predpos  P@25%_predpos  P@50%_predpos  \\\n",
       "0        0.923077    0.424779       0.272727       0.230769       0.211538   \n",
       "1        0.923077    0.421053       0.272727       0.269231       0.211538   \n",
       "2        0.923077    0.421053       0.272727       0.269231       0.230769   \n",
       "3        0.730769    0.417582       0.454545       0.230769       0.269231   \n",
       "4        0.730769    0.417582       0.363636       0.269231       0.307692   \n",
       "\n",
       "   weight  \n",
       "0   0.625  \n",
       "1   0.550  \n",
       "2   0.575  \n",
       "3   0.800  \n",
       "4   0.975  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Best weight: {BEST_W:.3f} | Best blended threshold: {BLENDED_THR:.1f}\")\n",
    "display(blend_leaderboard.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74128223",
   "metadata": {},
   "source": [
    "### **3.7 Generate Evasion Labels**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42e75f5",
   "metadata": {},
   "source": [
    "With the tuned threshold values in hand, evasion scores were generated for the J.P. Morgan Test set and the respective thresholds were applied to these values to ultimately label each Q&A pair as either 'Direct' or 'Evasive'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1b27bab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants.\n",
    "LLM_WEIGHT = 0.625\n",
    "SELECTED_LLM = ['deberta', 'roberta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "004e2992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for the evasion pipeline adjusted for the test set (using best LLM model)\n",
    "def evasion_pipeline_test(\n",
    "    df,\n",
    "    models_and_tokenizers,\n",
    "    device,\n",
    "    llm_weight,\n",
    "    llm_name,                \n",
    "    avg_llm=False,            # if True, compute evasion_score_llm_avg\n",
    "    avg_names=None            # subset to average; if None, average over all provided models\n",
    "):\n",
    "\n",
    "    # Normalise inputs\n",
    "    if isinstance(llm_name, str) or llm_name is None:\n",
    "        selected_llms = [] if llm_name is None else [llm_name]\n",
    "    else:\n",
    "        selected_llms = list(llm_name)\n",
    "\n",
    "    # Average set\n",
    "    if avg_llm:\n",
    "        if avg_names is None:\n",
    "            avg_list = list(models_and_tokenizers.keys())\n",
    "        else:\n",
    "            avg_list = [n for n in avg_names if n in models_and_tokenizers]\n",
    "    else:\n",
    "        avg_list = []\n",
    "\n",
    "    need_models = list(dict.fromkeys([*selected_llms, *avg_list]))  \n",
    "\n",
    "    rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        q, a = str(row['question']), str(row['answer'])\n",
    "\n",
    "        # Baseline\n",
    "        base_score, *_ = baseline_evasion_score(q, a)\n",
    "        base_score = float(np.clip(base_score, 0.0, 100.0))\n",
    "\n",
    "        rec = {\n",
    "            'question_number': row.get('question_number'),\n",
    "            'question': q,\n",
    "            'answer': a,\n",
    "            'label': row.get('label'),\n",
    "            'evasion_score_baseline': base_score,\n",
    "        }\n",
    "\n",
    "        # Compute all needed LLM scores once\n",
    "        llm_scores = {}\n",
    "        for name in need_models:\n",
    "            m, t = models_and_tokenizers[name]\n",
    "            r = llm_evasion_score(q, a, m, t, device)\n",
    "            s = float(100.0 * r['p_evasive'])\n",
    "            s = float(np.clip(s, 0.0, 100.0))\n",
    "            rec[f'evasion_score_{name}'] = s\n",
    "            llm_scores[name] = s\n",
    "\n",
    "        # LLM average \n",
    "        if avg_llm and len(avg_list) > 0:\n",
    "            vals = [llm_scores[n] for n in avg_list if n in llm_scores]\n",
    "            rec['evasion_score_llm_avg'] = float(np.mean(vals)) if len(vals) > 0 else np.nan\n",
    "        else:\n",
    "            rec['evasion_score_llm_avg'] = np.nan\n",
    "\n",
    "        # Blends for each selected LLM\n",
    "        # blend = (1-W)*baseline + W*LLM\n",
    "        for name in selected_llms:\n",
    "            llm_val = rec.get(f'evasion_score_{name}', np.nan)\n",
    "            rec[f'evasion_score_blended_{name}'] = (\n",
    "                float(np.clip((1.0 - llm_weight) * base_score + llm_weight * llm_val, 0.0, 100.0))\n",
    "                if np.isfinite(llm_val) else np.nan\n",
    "            )\n",
    "\n",
    "        rows.append(rec)\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5eebd36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evasion pipeline on test dataset to generate raw evasion scores. \n",
    "jpm_test_qa_scores = evasion_pipeline_test(\n",
    "    jpm_test_qa_labelled,\n",
    "    models_and_tokenizers,\n",
    "    device,\n",
    "    LLM_WEIGHT,\n",
    "    SELECTED_LLM,\n",
    "    avg_llm=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "afc860b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the best threshold based on validation set.\n",
    "BLENDED_THR = 43\n",
    "DEBERTA_THR = 56\n",
    "ROBERTA_THR = 28\n",
    "BASELINE_THR = 21\n",
    "AVG_LLM_THR = 46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a7a2c3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply validation thresholds to the test dataset to generate labels.\n",
    "def compute_evasion_labels(df, score_col, thr):\n",
    "\n",
    "    scores = df[score_col].astype(float).values\n",
    "    pred = np.where(scores >= float(thr), 'Evasive', 'Direct')\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "194a5eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply validation thresholds to the test dataset to generate labels.\n",
    "jpm_test_qa_preds = jpm_test_qa_scores.copy()\n",
    "jpm_test_qa_preds['pred_label_baseline'] = compute_evasion_labels(jpm_test_qa_scores, 'evasion_score_baseline', BASELINE_THR)\n",
    "jpm_test_qa_preds['pred_label_deberta'] = compute_evasion_labels(jpm_test_qa_scores, 'evasion_score_deberta', DEBERTA_THR)\n",
    "jpm_test_qa_preds['pred_label_roberta'] = compute_evasion_labels(jpm_test_qa_scores, 'evasion_score_roberta', ROBERTA_THR)\n",
    "jpm_test_qa_preds['pred_label_llm_avg'] = compute_evasion_labels(jpm_test_qa_scores, 'evasion_score_llm_avg', AVG_LLM_THR)\n",
    "jpm_test_qa_preds['pred_label_blended_deberta'] = compute_evasion_labels(jpm_test_qa_scores, 'evasion_score_blended_deberta', BLENDED_THR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6261f",
   "metadata": {},
   "source": [
    "### **3.8 Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb61986f",
   "metadata": {},
   "source": [
    "The results were evaluated using the key metrics: precision/recall/F1 (direct and evasive), AUPRC, P@10%-50% (ranking flagged evasive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e57f847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate predicted labels.\n",
    "def evaluate_predictions(df, true_col, models, k_percents=(10, 25, 50)):\n",
    "    # Convert true labels to 0/1\n",
    "    y_true = df[true_col].astype(str).str.strip().str.lower().eq('evasive').astype(int)\n",
    "    results = []\n",
    "    conf_matrices = {}\n",
    "\n",
    "    for name, cfg in models.items():\n",
    "        # Scores + predictions for this model\n",
    "        scores = df[cfg['score_col']].astype(float).values\n",
    "        y_pred = (df[cfg['pred_col']] == \"Evasive\").astype(int).values\n",
    "\n",
    "        # Class-specific metrics\n",
    "        prec_dir = precision_score(y_true, y_pred, pos_label=0, zero_division=0)\n",
    "        rec_dir  = recall_score(y_true, y_pred, pos_label=0, zero_division=0)\n",
    "        f1_dir   = f1_score(y_true, y_pred, pos_label=0, zero_division=0)\n",
    "\n",
    "        prec_eva = precision_score(y_true, y_pred, pos_label=1, zero_division=0)\n",
    "        rec_eva  = recall_score(y_true, y_pred, pos_label=1, zero_division=0)\n",
    "        f1_eva   = f1_score(y_true, y_pred, pos_label=1, zero_division=0)\n",
    "\n",
    "        # AUPRC (ranking quality)\n",
    "        auprc = average_precision_score(y_true, scores)\n",
    "\n",
    "        # Precision@K% (top by score)\n",
    "        n = len(y_true)\n",
    "        order = np.argsort(-scores)\n",
    "        p_at = {}\n",
    "        for k in k_percents:\n",
    "            top_k = int(np.ceil(n * k / 100))\n",
    "            top_idx = order[:top_k]\n",
    "            p_at[f\"P@{k}%\"] = y_true[top_idx].mean()\n",
    "\n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "        cm_df = pd.DataFrame(\n",
    "            cm,\n",
    "            index=[\"True_Direct\", \"True_Evasive\"],\n",
    "            columns=[\"Pred_Direct\", \"Pred_Evasive\"]\n",
    "        )\n",
    "        conf_matrices[name] = cm_df\n",
    "\n",
    "        results.append({\n",
    "            \"model\": name,\n",
    "            \"Precision_direct\": prec_dir,\n",
    "            \"Recall_direct\": rec_dir,\n",
    "            \"F1_direct\": f1_dir,\n",
    "            \"Precision_evasive\": prec_eva,\n",
    "            \"Recall_evasive\": rec_eva,\n",
    "            \"F1_evasive\": f1_eva,\n",
    "            \"AUPRC\": auprc,\n",
    "            **p_at\n",
    "        })\n",
    "\n",
    "    summary_df = pd.DataFrame(results).set_index(\"model\")\n",
    "    return summary_df, conf_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "157d9a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision_direct</th>\n",
       "      <th>Recall_direct</th>\n",
       "      <th>F1_direct</th>\n",
       "      <th>Precision_evasive</th>\n",
       "      <th>Recall_evasive</th>\n",
       "      <th>F1_evasive</th>\n",
       "      <th>AUPRC</th>\n",
       "      <th>P@10%</th>\n",
       "      <th>P@25%</th>\n",
       "      <th>P@50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.126316</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.149852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.160714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deberta</th>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.463158</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.177419</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.163164</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.196429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm_avg</th>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.389474</td>\n",
       "      <td>0.536232</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.174414</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.178571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blended_deberta</th>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.163116</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.178571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Precision_direct  Recall_direct  F1_direct  \\\n",
       "model                                                         \n",
       "baseline                 0.923077       0.126316   0.222222   \n",
       "deberta                  0.897959       0.463158   0.611111   \n",
       "llm_avg                  0.860465       0.389474   0.536232   \n",
       "blended_deberta          0.809524       0.178947   0.293103   \n",
       "\n",
       "                 Precision_evasive  Recall_evasive  F1_evasive     AUPRC  \\\n",
       "model                                                                      \n",
       "baseline                  0.153061          0.9375    0.263158  0.149852   \n",
       "deberta                   0.177419          0.6875    0.282051  0.163164   \n",
       "llm_avg                   0.147059          0.6250    0.238095  0.174414   \n",
       "blended_deberta           0.133333          0.7500    0.226415  0.163116   \n",
       "\n",
       "                    P@10%     P@25%     P@50%  \n",
       "model                                          \n",
       "baseline         0.000000  0.107143  0.160714  \n",
       "deberta          0.083333  0.142857  0.196429  \n",
       "llm_avg          0.166667  0.178571  0.178571  \n",
       "blended_deberta  0.083333  0.178571  0.178571  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate a metrics comparison table.\n",
    "models_cfg = {\n",
    "    \"baseline\": {\"score_col\": \"evasion_score_baseline\", \"pred_col\": \"pred_label_baseline\"},\n",
    "    \"deberta\":  {\"score_col\": \"evasion_score_deberta\",  \"pred_col\": \"pred_label_deberta\"},\n",
    "    \"llm_avg\":  {\"score_col\": \"evasion_score_llm_avg\",  \"pred_col\": \"pred_label_llm_avg\"},\n",
    "    \"blended_deberta\": {\"score_col\": \"evasion_score_blended_deberta\", \"pred_col\": \"pred_label_blended_deberta\"},\n",
    "}\n",
    "\n",
    "summary, conf_mats = evaluate_predictions(jpm_test_qa_preds, true_col=\"label\", models=models_cfg)\n",
    "\n",
    "display(summary)         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9503bcac",
   "metadata": {},
   "source": [
    "**Evaluation Results on Test Set**\n",
    "- **Baseline:** Extremely high recall (94%) at the cost of very low precision (15%), it is essentially flagging everything as evasive.\n",
    "- **DeBERTa:** Strikes a better balance with direct recall (46%) and evasive recall (69%). Precision on evasive is still low (18%) but an improvement on the baseline. Best overall F1 for both classes, AUPRC is higher (0.163) and ranking (P@K, thresholded) is improved though still modest.\n",
    "- **LLM average:** Slightly weaker DeBERTa on direct recall (39% bs 46%) and evasive recall (63% vs 69%), precision is also lower but interestingly P@25% and P@50% are the strongest meaning it gives more useful shortlists (thresholded)\n",
    "- **Blended DeBERTa:** Higher evasive recall (75%) with poorer direct recall (18%). F1 evasive is significantly lower than DeBERTa alone. P@K is on par with LLM average but doesn't justify the recall scarifice. \n",
    "\n",
    "**Overall:** DeBERTa is the strongest single model, giving the best balance of recall and F1.\n",
    "\n",
    "\n",
    "**Note:** P@K ranking in this instance is conditional on 'above-threshold-evasives' so the classification threshold is applied, then within that specific set of predicted evasives, the precision is computed at different cut-offs (e.g. 10%, 25%, 50%). It ranks only among predicted evasives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5877c74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert arrays to matrix.\n",
    "def to_numeric_matrix(cm):\n",
    "    if isinstance(cm, pd.DataFrame):\n",
    "        return cm.apply(pd.to_numeric, errors=\"coerce\").fillna(0).astype(int).values\n",
    "    return np.array(cm, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "414b6e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAAKyCAYAAADW2xhiAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAhU9JREFUeJzs3Xl8TPf+x/H3yL6QCAmJIrEvRYOKdLG7dqKtpfTWVmrppS1adAm3C7rcUi1VLVoXpXTRXqV22lpKE9RSLRGU1L6FRJbz+8PPNNMkbVRmzknyej4e83jMnPOdM5/MJO/55Mz3nLEZhmEIAAAAKOKKmV0AAAAAYAU0xgAAAIBojAEAAABJNMYAAACAJBpjAAAAQBKNMQAAACCJxhgAAACQRGMMAAAASKIxBgAAACTRGCMf9e3bVzabTTabTevXrze7nD+1fv16e619+/a1Ly9IPwMAFBRz5861Z+v48eNdfv9btX79eo0fP17jx49XfHy8yx8fruNudgEAAABWtn79ek2YMEGSFB4erjvuuMPcguA07DEGspg7d64Mw5BhGGrWrJnZ5QAATHTlyhWzS4CL0RjDKa5cuaKRI0cqNDRU3t7eaty4scPUhE8//VTt2rVTxYoVVbx4cXl4eKhs2bLq3LmzNm7c6LCtCxcuaNiwYapUqZK8vLzk6+urChUqqF27dlqwYIHD2ISEBD366KP2sSVKlFCTJk308ccf56nu3KZS3FgWHh6u77//Xq1bt5afn5/KlSunwYMH6/Llyw7bSUtL05QpU9SoUSMVL15cXl5eql69usaMGaOLFy/e3JMJAAXIp59+qjvuuEPe3t4KDw/Xiy++qIyMjBzH7ty5U71799Ztt90mT09PBQUFqW3btlqzZs2fPsY777yjGjVqyMvLS9WqVdP06dOzjTl58qRGjhypGjVqyMfHR35+frrzzjs1c+ZMGYZhH3f48GF7xjdr1kxffvmlGjZsKG9vbw0dOlQ2m82+t1iS+vXrZx8/d+5cSdK7776rli1b6rbbbpOfn588PT112223qWfPntq1a9ffeBZhGgPIJ3369DEkGZKMcuXK2a/fuHh4eBibNm0yDMMwRowYkW39jYubm5uxceNG+3ZjYmJyHdu7d2/7uG3bthnFixfPdeyYMWPsY9etW2df3qdPnxx/hnXr1tmX31jm4+NjeHl5Zdv2oEGD7GNTUlKMpk2b5lpHzZo1jbNnzzrhFQAAcy1ZssSw2WzZci/re0JsbKxhGIbx+eefGx4eHjnmpM1mM2bMmGHf7pw5c/70/UWSMXnyZPv4gwcPGqGhobnmcM+ePe1jExIS7MtLlixpFCtWzOH9IbdtSDLmzJljGIZhdOnSJdcx/v7+xoEDB1zy/OPWsccYTuHt7a1du3bp7NmzGjJkiKTre1FHjx4tSXrggQf07bff6rffftO1a9d04cIFzZgxQ5KUkZGhKVOm2Ld1Y89BdHS0Tp8+ratXr+rgwYOaN2+eWrZsaR/Xv39/Xbp0SYGBgVq9erVSUlJ05MgR3XvvvZKkyZMn68cff7yln+vq1avq2rWrTp06pc2bN8vLy0uS9OGHH9r3QLz11lvasGGDJGns2LE6c+aMkpOTNXnyZEnSvn379PLLL99SHQBgNYZhaOTIkfYsHD9+vC5cuKDvvvtOqampDmOvXr2qRx55RGlpafZP4lJTU/XTTz+pevXqMgxDTz75pE6fPp3tcU6fPq0vvvhCly5dsu+xvfF4586dkySNGDFCJ06ckLu7uz7++GNduXJFv/32m7p16yZJ+uijj/S///0v27bPnTunbt266ejRo7p48aLGjRsnwzAUGxtrHzNnzhz7lLsbB28PHTpU27dv1+nTp5WWlqYzZ87o2WeflSRdvnxZ77zzzt9/YuFaJjblKGSy/mc9c+ZM+/LLly8b7u7u9r0A58+fNxISEowBAwYYlSpVynEPbI0aNez3v+OOOwxJRokSJYzHHnvMmDFjhrFu3Trj8uXL9jE///zzn/5Xf+Py2muvGYbx9/cYFytWzGFvb4MGDezrTpw4YRiGYdx9991/Wcftt9+e308/AJhq//799owLDg42MjIy7OvGjh3rsMd41apVecrsJUuWGIbhuMf4wQcfdHjc6Oho+7ply5YZV69etb/n/NnlscceMwzDcY9xiRIlHN5bboiNjc22lzirnTt3Gj179jTKly9veHp6Znustm3b5uMzDWfirBRwiooVK9qv+/n5qXTp0kpKSpJhGDp8+LDatWunEydO5Hr/q1ev2q/Pnj1bffv21a5du/TWW2/Zl/v4+OjFF1/Uk08+qd9++y1PdeW09+FmlC1bViVLlrTf9vPzs19PSUmRpDzVcqt1AIDVZM21cuXKqVix3z+UzvqeIOUtJ/+4zdy2VbFiRW3evFnS9XnFZ86cUXp6+t/advXq1R1yPS8SExN11113KTk5OdcxWd/TYG1MpYBTJCYm2q8nJyfbA8hms+nw4cP2prh27do6dOiQMjMzcz1AITIyUjt37tTRo0e1cuVKvf3226pevbquXr2qUaNG6fjx4ypTpox9fI0aNewfc/3xcqtTGDw8PBxu22y2bGOy1rJ58+Yc6zh+/Pgt1QEAVlO6dGn79V9//VWZmZn221nfEyTHnGzTpk2OOZmZmalHH3002+P8cVtZb4eEhKhUqVJyd7++36948eJKTU3Ncft/PHhbknx9fXP82XLK+hs+++wze1PcokUL/frrrzIMQ8uWLcv1PrAuGmM4xWuvvaY9e/bo/PnzGj16tP2/96ioKHtgSZK7u7v8/PyUlJSkcePG5bitcePG6dNPP1V6erqaNGmi7t27q0qVKpKuz2k7duyYqlSpottvv12StH//fo0aNUonTpxQWlqaDh06pOnTp6tu3brZAtUZunbtar8+bNgw7dixQ6mpqTpz5oyWL1+ubt26aeLEiU6vAwBcqVq1ava9uadOndILL7ygixcvasuWLZo1a5bD2LvvvlvBwcGSpK+//lqvvfaazpw5o9TUVO3fv1+TJ0+25/wfffLJJ/rf//6ny5cv64MPPrDvLfbx8dE999wjb29vtW3bVpJ06dIl9e/fX4cPH1ZaWpqOHj2qDz74QHfffXe2MyD9mVKlStmv//jjjw57pLO+p3l6esrPz08HDx7Uiy++mOftw0JcN2sDhV1ez0px7tw5o2zZstnWV6tWzX69YsWK9u1Wrlw51zlit912m3H16lXDMK6flaJEiRJ/OqcsISHBMIy/P8c4a12GYTicfeLGtlNSUoxmzZr9aR03jsoGgMLk448/zvGsFMHBwdnyb9myZTnOx816uSEvZ6WYNGmSffyhQ4dyHffHjM86x7hp06Y5/lzbt2/P9T3l0KFDhq+v75++p+W2XVgPe4zhFO+++66eeOIJlS1bVl5eXmrUqJFWrlype+65R4GBgVq5cqVatmyp4sWLq1SpUhowYIAWLVqU47b+9a9/qU2bNrrtttvk7e0tDw8PlS9fXn369NHGjRvl7e0tSbrzzju1a9cuDR06VFWqVJGXl5f8/f1VtWpVdevWTXPnzlVYWJjTf3YvLy+tWrVK06ZNU3R0tEqUKGE/p2WTJk304osvqk+fPk6vAwBc7YEHHtDSpUtVt25deXp6qnz58nruuef00ksvZRvbqVMn7dixQw8//LAqVKggDw8PBQQEqGbNmnr44YdzfU945JFHNGPGDFWrVk2enp6qUqWK3n77bT399NP2MREREYqPj9dTTz2lWrVqydvbWz4+PqpUqZI6deqkGTNmqH79+nn+uRo0aKDp06eratWq8vT0dFgXERGh5cuXq3HjxvL19VVoaKhGjRqlN998M8/bh3XYDCPLWa4BAACAIoo9xgAAAIBojAEAAABJNMYAAACAJBpjAAAAQBKNMQAAACCJxhgAAACQRGMMAAAASJLc/3pIwTNhwgSzSwBgUbGxsWaXACci/wHkJK/ZXygbY0l6aOhTZpcAi/jv9Fc06bNTZpcBi6AvLvxe3xdhdgmwiJE1E8h/SMp79jOVAgAAABCNMQAAACCJxhgAAACQRGMMAAAASKIxBgAAACTRGAMAAACSaIwBAAAASTTGAAAAgCQaYwAAAEASjTEAAAAgicYYAAAAkERjDAAAAEiiMQYAAAAk0RgDAAAAkmiMAQAAAEk0xgAAAIAkGmMAAABAEo0xAAAAIInGGAAAAJBEYwwAAABIojEGAAAAJNEYAwAAAJJojAEAAABJNMYAAACAJBpjAAAAQBKNMQAAACCJxhgAAACQZIHG+MMPP1Rqamq25deuXdOHH35oQkUAAGcj+wFYkemNcb9+/XThwoVsyy9duqR+/fqZUBEAwNnIfgBWZHpjbBiGbDZbtuXHjh1TQECACRUBAJyN7AdgRe5mPXBkZKRsNptsNptatmwpd/ffS8nIyFBCQoLatm1rVnkAACcg+wFYmWmNcUxMjCQpPj5ebdq0kb+/v32dp6enwsPDdf/995tUHQDAGch+AFZmWmMcGxsrSQoPD1fPnj3l5eVlVikAABch+wFYmelzjGvVqqX4+Phsy7du3art27e7viAAgNOR/QCsyPTGeNiwYTp69Gi25b/++quGDRtmQkUAAGcj+wFYkemN8d69e1W/fv1syyMjI7V3714TKgIAOBvZD8CKTG+Mvby89Ntvv2VbfuLECYejlQEAhQfZD8CKTG+MW7durbFjxzqc6P38+fMaN26cWrdubWJlAABnIfsBWJHp/5a//vrratKkiSpWrKjIyEhJ10/jU6ZMGc2bN8/k6gAAzkD2A7Ai0xvjcuXKadeuXZo/f7527twpHx8f9evXTw8++KA8PDzMLg8A4ARkPwArMr0xliQ/Pz8NGjTI7DIAAC5E9gOwGtPnGEvSvHnzdM899ygsLEyJiYmSpDfeeEOff/65yZUBAJyF7AdgNaY3xjNmzNCTTz6pdu3a6dy5c8rIyJAklSxZUlOmTDG3OACAU5D9AKzI9MZ42rRpmjVrlp555hmHU/Q0bNhQu3fvNrEyAICzkP0ArMj0xjghIcF+RHJWXl5eSk5ONqEiAICzkf0ArMj0xjgiIkLx8fHZln/11VeqVauW6wsCADgd2Q/Aikw/K8Xo0aM1bNgwpaSkyDAMbdu2TQsXLtTEiRP13nvvmV0eAMAJyH4AVmR6Y9yvXz+lp6frqaee0pUrV9SrVy+VK1dOU6dOVc+ePc0uDwDgBGQ/ACsytTFOT0/X/Pnz1alTJw0cOFCnT59WZmamQkJCzCwLAOBEZD8AqzJ1jrG7u7uGDBmi1NRUSVLp0qUJRgAo5Mh+AFZl+sF3UVFRiouLM7sMAIALkf0ArMj0OcZDhw7VyJEjdezYMTVo0EB+fn4O6+vWrWtSZQAAZyH7AViR6Y1xjx49JEnDhw+3L7PZbDIMQzabzf5tSACAwoPsB2BFpjfGCQkJZpcAAHAxsh+AFZneGFesWNHsEgAALkb2A7AiUxrjZcuWqV27dvLw8NCyZcv+dGznzp1dVBUAwJnIfgBWZ0pjHBMTo6SkJIWEhCgmJibXccwzA4DCg+wHYHWmNMaZmZk5XkfeHT92RB/Pn6N9u3fqaGKCDMOQJH22Zqs8vbwkSddSU/XJRx8qfsc2/Xo0URcvnFdgYJCqVK+p3v0Hq1LV6mb+CMhnD3WK0oD771al8sHy9/HS8VPntXrzfr02+2v9evK8JOnlx2PUPKq6ypcNUoC/ty4mp2j3gV/1zqKN+mxNvKn1o/Aj+/Nf9XIB+nZyR3m6u0mSHn9vi2avPpBt3PM9IzUqpo79dvA//6vUNF6Dgu6hTlGa9e9/5rhu50/H1LjnJEnSA/+or+5tGyiqXiWFBBWXJH28coceHjPHZbUWFKbPMcbfc/jQL1r5xad/Ouby5Uv6cNbbDstOnUzSqZNJ+n7zJk18c5Zq1410ZplwkacfaaPxwzo5LKtSIURVKoSofZPbVf/+F5V89Zq6t22gcmVK2scEBfip6Z3V1PTOavrn07O15OsfXF06gFvwev8oe1OcmyqhxfWvDrVcVBGsqHvbBurUvJ7ZZRQIpn7BR2ZmpmbPnq2OHTvq9ttvV506ddS5c2d9+OGH9j2gyFnp4BD1ePgRTXj1LVWvVSfXcaHlymv4089r4Rdr9dH/1qt5mw6Srn8l6+J577uqXDjZg+3vlHT9b6rD4LcUcs8ofbXpR0lShdAgtYquKUma8dEG3d37FQXfPVLlW4zRe0u+sW+je7uGri8cRRLZnz+63x2hJrXL6nJK2p+Oe61flLw83P5yHAquxONn5BP5mMPlxt5iSVr//QGNfOVjdXtipolVFgymNcaGYahz58565JFH9Ouvv6pOnTqqXbu2EhMT1bdvX3Xt2tWs0gqEajVvV59Bj+nO6Hvk6emZ45gSAQF6Z95Ste10nwJKBqlEQKAeHT7avv74saOuKhdOlpF5vZk4efay1m7dr0vJKfbGWJJ8vDwkSa/PXa0f9h7R5SupOn3ust5ZtNE+Jj2dOZ1wPrI/fxT38dCLDzXQldR0vfXl3lzHdW1cUS3qhmlV/K+KO3TGhRXCSqYv3KDpCzdo10+/ml2K5Zk2lWLu3LnauHGj1qxZo+bNmzusW7t2rWJiYvThhx/q4YcfNqnCgs/d3SPbsmvXUu3XS4eUcWU5cKL3lnyj/zzdTSFB/moRVUPf/3hY7Ztc/yQhJTVNm3b8ku0+IUHFNaRnU0nXm+LZn3zn0ppRNJH9+ePZ7neobElfvbAoTr+evZLjGD8vd738z4ZKuZah0XO2adqj0S6uEq4SGhygY+smq7ifl44lndPna3fq5Xe/0uUrqX99ZzgwbY/xwoULNW7cuGzBKEktWrTQmDFjNH/+fBMqK9z++/479uv/6NDFxEqQn2Z8tEGjXlkiw5D+985jOvnNa2p7T239cuSkHnh8pv3gO0ka1a+1rsa9pcQ1EzXg/rt1NeWa+j3zgVZv3mfeD4Aig+y/dbdXKKmB/6iuX05c1NQv9uQ6bswD9VSulJ+mLPtRh3675MIK4WqeHu4qFegnTw93VSofrCf6tNLKWSPk8Rfzz5GdaY3xrl271LZt21zXt2vXTjt37vzL7aSmpurixYsOl/T09PwstdD4cNbb+vrL6wfstWrXSc3/0cHkipBferRtqIlPdJWbm+OfdKlAf9WvVeFP7+vj7an3Xvin2tzDwTlwvvzKfqno5v/r/aPk7lZMo+ds07X0nM8sUeO2AA1tV1MJv13S65/vdnGFcJVDR09pyL/nq3r75xUY9bjufehVHTj8mySpfq0K6ta2gckVFjymNcZnz55VmTK5f5RfpkwZnTt37i+3M3HiRAUEBDhcNm3alJ+lFgrvv/0fffTBLElSk5ZtNOLpWJMrQn6x2Wx6/elu8vBw0+lzlxXVY6JKRT+p/8xdpZIlfPXvf3VWzywH1r02Z5V8Ih9ThRZj9OzUzyRJXp4eenF4jDk/AIqU/Mp+qWjmf7PbQxVdI0TbDpzSyQtXVadiSZUv5WdfXy7IV7XKB2pklzrycC+mD9b+rGphAapTsaT8vH6fPXl7hZIKLeljxo+AfPRd/CHN/XSzjpw4q9Rr6dq+J1EvzVxuX3/n7eHmFVdAmdYYZ2RkyN099ynObm5uefrPf+zYsbpw4YLD5d57783PUgs0wzD0zpTJWrrwQ0lSq/adNfr5l+X2J889CpaQIH+VCrz+xrhlV4J2HfhVV1Kuad4XW+1jmjaqlu1+p85d1utzV+vcxevzE6tUCHZNwSjS8iv7paKZ/37e15+7RtWC9e3kTvp2cic90/0O+/rR99XVivFt7ePGP1jfPq5+5dL2cete6qARnWq7tHbkP5vN9qfrOcvLzTOtOzIMQ3379pXX/38ZxR+lpuZtwriXl1e2bfxZ6BYWaWlpunTxgiQpPf33U/CcO3dGHh6e8vHxlbePj6a98oJWfPGJJKlD1+4a+uTYv/xDQsFy7uJVXU25Jh9vTzWuG6G61crplyOn9HDnxvYxFy5dVYuoGqpfq7z+t2G3Dh8/I29PD/2zc2OVLOErSUr49bRZPwKKkPzKfqno5j9ww9Kpj2rd1p/0+dqdSjp9UXWqhumZR9vb12/ZeUiSVMLfWz5eHgou6W9f5+3prjKlrn/Zx6lzl5WZSRMtmdgY9+nT5y/HcFRy7vbtjteY4QOzLe/3wPU/iF79HlXr9p3tTbEk/e/Txfrfp4sdxi//Jt6pdcL5rqWla+biTXr84ZYqXdJfWxeNdVh/5eo1ffDZZjWoXVEvDO+iF4ZnP+gyIyNTL8z4n6tKRhFG9t+a/20/qhI9P3RY1qtpZb0z5G5JuX/znST97/l/6N5aZSXxzXeFRVhIoF4Zdb9eGXV/tnUbvj9g/9Km10Y/oH9m2VkiSZ2a17N/6Uf19s/ryImzzi+4ADCtMZ4zh68hBPLLuCmfKfH4GT3UKUrVI8rK29Ndp88na+vOQ5r03grtO5QkN7di+njlDjWoVUFlSpeQh7ubTp65pG27E/T2gvX6Lv6Q2T8GigCyH8g//57+pbq3bagGtSsoNDhANtn0y9GT+njlD3pz3lr2Av8NNqMQTkCZMGGCHhr6lNllwCL+O/0VTfrslNllwCKuxr1ldglwogkTJuj1fRFmlwGLGFkzgfyHpLxnv6lfCQ0AAABYBY0xAAAAIBpjAAAAQBKNMQAAACDJIo3xvHnzdPfddyssLEyJiYmSpClTpujzzz83uTIAgLOQ/QCsxvTGeMaMGXryySfVvn17nT9/XhkZGZKkwMBATZkyxdziAABOQfYDsCLTG+Np06Zp1qxZeuaZZ+Tm5mZf3rBhQ+3evdvEygAAzkL2A7Ai0xvjhIQERUZGZlvu5eWl5ORkEyoCADgb2Q/AikxvjCMiIhQfH59t+VdffaVatWq5viAAgNOR/QCsyLSvhL5h9OjRGjZsmFJSUmQYhrZt26aFCxdq4sSJeu+998wuDwDgBGQ/ACsyvTHu16+f0tPT9dRTT+nKlSvq1auXypUrp6lTp6pnz55mlwcAcAKyH4AVmd4YS9LAgQM1cOBAnT59WpmZmQoJCTG7JACAk5H9AKzGEo3xDaVLlza7BACAi5H9AKzC9MY4IiJCNpst1/WHDh1yYTUAAFcg+wFYkemN8eOPP+5wOy0tTXFxcVqxYoVGjx5tTlEAAKci+wFYkemN8YgRI3Jc/vbbb2v79u0urgYA4ApkPwArMv08xrlp166dli5danYZAAAXIvsBmMmyjfGSJUsUFBRkdhkAABci+wGYyfSpFJGRkQ4HYBiGoaSkJJ06dUrTp083sTIAgLOQ/QCsyPTGOCYmxuF2sWLFFBwcrGbNmqlGjRrmFAUAcCqyH4AVmdoYp6enKzw8XG3atFHZsmXNLAUA4CJkPwCrMnWOsbu7u4YMGaLU1FQzywAAuBDZD8CqTD/4LioqSnFxcWaXAQBwIbIfgBWZPsd46NChGjlypI4dO6YGDRrIz8/PYX3dunVNqgwA4CxkPwArMq0x7t+/v6ZMmaIePXpIkoYPH25fZ7PZZBiGbDabMjIyzCoRAJDPyH4AVmZaY/zBBx9o0qRJSkhIMKsEAICLkf0ArMy0xtgwDElSxYoVzSoBAOBiZD8AKzP14LusJ3cHABQNZD8AqzL14Ltq1ar9ZUCePXvWRdUAAFyB7AdgVaY2xhMmTFBAQICZJQAAXIzsB2BVpjbGPXv2VEhIiJklAABcjOwHYFWmzTFmjhkAFD1kPwArM60xvnFkMgCg6CD7AViZaVMpMjMzzXpoAIBJyH4AVmbq6doAAAAAq6AxBgAAAERjDAAAAEiiMQYAAAAk0RgDAAAAkmiMAQAAAEk0xgAAAICkPJ7HeNmyZXneYOfOnf92MQAA6yD7ARQ1eWqMY2Ji8rQxm82mjIyMW6kHAGARZD+AoiZPjTHfVAQARQ/ZD6CoYY4xAAAAoDzuMf6j5ORkbdiwQUeOHNG1a9cc1g0fPjxfCgMAWAvZD6Cwu+nGOC4uTu3bt9eVK1eUnJysoKAgnT59Wr6+vgoJCSEcAaAQIvsBFAU3PZXiiSeeUKdOnXT27Fn5+Phoy5YtSkxMVIMGDfTaa685o0YAgMnIfgBFwU03xvHx8Ro5cqTc3Nzk5uam1NRUlS9fXq+88orGjRvnjBoBACYj+wEUBTfdGHt4eMhms0mSypQpoyNHjkiSAgIC7NcBAIUL2Q+gKLjpOcaRkZHavn27qlWrpubNm+v555/X6dOnNW/ePNWpU8cZNQIATEb2AygKbnqP8csvv6zQ0FBJ0gsvvKBSpUppyJAhOnnypN599918LxAAYD6yH0BRcNN7jBs2bGi/HhwcrOXLl+drQQAA6yH7ARQFfMEHAAAAoL+xxzgiIsJ+AEZODh06dEsFAQCsh+wHUBTcdGP8+OOPO9xOS0tTXFycVqxYodGjR+dXXQAACyH7ARQFN90YjxgxIsflb7/9trZv337LBQEArIfsB1AU5Nsc43bt2mnp0qX5tTkAQAFA9gMoTPKtMV6yZImCgoLya3MAgAKA7AdQmPytL/jIegCGYRhKSkrSqVOnNH369HwtDgBgDWQ/gKLgphvjLl26OIRjsWLFFBwcrGbNmqlGjRr5Wtyt+O/0V8wuARYyJibY7BKAAq2gZL8kjayZYHYJsBDyHzfjphvj8ePHO6GM/Pf0M7FmlwCLmPzSBHUfOMrsMoACraBkv0T+43eTX5qgfw592uwyUIDc9BxjNzc3nTx5MtvyM2fOyM3NLV+KAgBYC9kPoCi46cbYMIwcl6empsrT0/OWCwIAWA/ZD6AoyPNUijfffFOSZLPZ9N5778nf39++LiMjQxs3brTcPDMAwK0h+wEUJXlujN944w1J1/cavPPOOw4fnXl6eio8PFzvvPNO/lcIADAN2Q+gKMlzY5yQcP0o3+bNm+uTTz5RyZIlnVYUAMAayH4ARclNn5Vi3bp1zqgDAGBhZD+AouCmD7574IEHNGnSpGzLX331VXXr1i1figIAWAvZD6AouOnGeMOGDerQoUO25W3bttXGjRvzpSgAgLWQ/QCKgptujC9fvpzjqXk8PDx08eLFfCkKAGAtZD+AouCmG+Pbb79dixYtyrb8o48+Uq1atfKlKACAtZD9AIqCmz747rnnntP999+vgwcPqkWLFpKkNWvWaMGCBVqyZEm+FwgAMB/ZD6AouOnGuHPnzvrss8/08ssva8mSJfLx8VG9evW0du1alShRwhk1AgBMRvYDKApuujGWpA4dOtgPwjh//rzmz5+vxx9/XDt37lRGRka+FggAsAayH0Bhd9NzjG9Yu3atHnroIYWFhemtt95S+/bttX379vysDQBgMWQ/gMLspvYYHzt2THPnztXs2bOVnJys7t27Ky0tTUuXLuXgCwAopMh+AEVFnvcYt2/fXrVq1dLevXs1bdo0HT9+XNOmTXNmbQAAk5H9AIqSPO8x/vrrrzV8+HANGTJEVatWdWZNAACLIPsBFCV53mO8adMmXbp0SQ0bNlRUVJTeeustnTp1ypm1AQBMRvYDKEry3BhHR0dr1qxZOnHihB599FF99NFHKleunDIzM7Vq1SpdunTJmXUCAExA9gMoSm76rBS+vr7q37+/vvnmG+3evVsjR47UpEmTFBISos6dOzujRgCAych+AEXB3z5dmyRVr15dr7zyio4dO6aFCxfmV00AAAsj+wEUVrfUGN/g5uammJgYLVu2LD82BwAoAMh+AIVNvjTGt+rgwYN69tln9eCDD+rkyZOSpBUrVmjPnj0mVwYAcBayH4DVmN4Yb9iwQXXq1NHWrVv1ySef6PLly5KkXbt2KTY21uTqAADOQPYDsCLTG+MxY8boxRdf1KpVq+Tp6Wlf3rx5c23evNnEygAAzkL2A7Ai0xvj3bt3q2vXrtmWBwcH68yZMyZUBABwNrIfgBWZ3hgHBgbqxIkT2ZbHxcWpXLlyJlQEAHA2sh+AFZneGPfq1UtPP/20kpKSZLPZlJmZqW+//VajRo3Sww8/bHZ5AAAnIPsBWJHpjfFLL72kChUqqFy5crp8+bJq1aqlJk2a6K677tKzzz5rdnkAACcg+wFYkbvZBXh4eGj+/Pn697//rbi4OGVmZioyMlJVq1Y1uzQAgJOQ/QCsyPTGeMOGDWratKkqV66sypUrm10OAMAFyH4AVmT6VIrWrVurQoUKGjNmjH788UezywEAuADZD8CKTG+Mjx8/rqeeekqbNm1S3bp1VbduXb3yyis6duyY2aUBAJyE7AdgRaY3xqVLl9Zjjz2mb7/9VgcPHlSPHj304YcfKjw8XC1atDC7PACAE5D9AKzI9MY4q4iICI0ZM0aTJk1SnTp1tGHDBrNLAgA4GdkPwCos0xh/++23Gjp0qEJDQ9WrVy/Vrl1bX375pdllAQCciOwHYCWmn5Vi3LhxWrhwoY4fP65WrVppypQpiomJka+vr9mlAQCchOwHYEWmN8br16/XqFGj1KNHD5UuXdrscgAALkD2A7Ai0xvj7777zuwSAAAuRvYDsCJTGuNly5apXbt28vDw0LJly/50bOfOnV1UFQDAmch+AFZnSmMcExOjpKQkhYSEKCYmJtdxNptNGRkZrisMAOA0ZD8AqzOlMc7MzMzxOgCg8CL7AVidZU7XltX58+fNLgEA4GJkPwCzmd4YT548WYsWLbLf7tatm4KCglSuXDnt3LnTxMoAAM5C9gOwItMb45kzZ6p8+fKSpFWrVmn16tVasWKF2rVrp9GjR5tcHQDAGch+AFZk+unaTpw4YQ/HL7/8Ut27d9c//vEPhYeHKyoqyuTqAADOQPYDsCLT9xiXLFlSR48elSStWLFCrVq1kiQZhsFRyQBQSJH9AKzI9D3G9913n3r16qWqVavqzJkzateunSQpPj5eVapUMbk6AIAzkP0ArMj0xviNN95QeHi4jh49qldeeUX+/v6Srn/MNnToUJOrAwA4A9kPwIpMb4w9PDw0atSobMsff/xx1xcDAHAJsh+AFZneGN+wd+9eHTlyRNeuXXNYzteCAkDhRfYDsBLTG+NDhw6pa9eu2r17t2w2mwzDkHT9K0ElcRAGABRCZD8AKzL9rBQjRoxQRESEfvvtN/n6+mrPnj3auHGjGjZsqPXr15tdHgDACch+AFZk+h7jzZs3a+3atQoODlaxYsVUrFgx3XPPPZo4caKGDx+uuLg4s0sEAOQzsh+AFZm+xzgjI8N+NHLp0qV1/PhxSVLFihX1008/mVkaAMBJyH4AVmT6HuPbb79du3btUqVKlRQVFaVXXnlFnp6eevfdd1WpUiWzywMAOAHZD8CKTG+Mn332WSUnJ0uSXnzxRXXs2FH33nuvSpUqpUWLFplcHQDAGch+AFZkemPcpk0b+/VKlSpp7969Onv2rEqWLGk/Ohl5dyQxUXPen6X4+DglHDpoP9J72w+75OXlZXJ1cJYTvx7RJws/0P4fd+rYkQT767545WZ5ev7+uj/z+EDt2bkjx230HzZSnR/o7ZJ6AbI//3z+6Sd6/tmxOa6rXr2GFn/yuYsrgisdP3ZEH8+fo72743U08ff8/3zNNnlmed/fsGaFNqxeob2743Xh/DlJUpOWbTR2wium1G1Vps8x/uCDD+x7DW4ICgoiGP+mX375WZ8s/ViHDv5i/+NA4ZeYcFCr/vepjiYe4nVHgUD2A/nj8KFftOKLT3Tk8J/n/4bVK7R50zp7U4ycmb7HeNSoURo6dKg6deqkhx56SG3btpW7u+llFVghISEaOGiw7qhfX+9Mf1u7d+00uyS4QKnSIer20ADVuP0OLfpgpg7s+/FPx/foM0gP9h3souqA7Mj+/BcWVk5frVprdhlwsVLBIer58EDVqnOH5s95Rz/t3Z3juHr171S9+ncqpGyY/j32cdcWWYCYvsf4xIkTWrRokdzc3NSzZ0+FhoZq6NCh+u6778wurUC6vU5dPTbiCd1zb1OmThQhVWvUVu8Bw9Qg6m55ePK6w/rIfiB/VK95u/oMekx3Rt/jMHXuj7p0660u3XqrUpVqLqyu4DH933N3d3d17NhRHTt21JUrV/Tpp59qwYIFat68uW677TYdPHjQ7BKBQud/n3ykTxbMlZubm8IrV1PH+3rqnhZt/vqOQD4h+/PfyZMn1eSuKCUnJ6tsaFm1bNVajw4ZJj8/f7NLAwoM0xvjrHx9fdWmTRudO3dOiYmJ2rdvn9klAYXS5UsXJUlpadL+PTu1f89OnT59UjHd/2lyZSiKyP78kZ6epgsXzkuSjh09qg/mzNa2rVs1b/5H8vD0NLc4oIAwfSqFJF25ckXz589X+/btFRYWpjfeeEMxMTH68cc/nycpSampqbp48aLDJT093QVVAwXP3U1bacJrM/ThZ2u04MuNGvzEOPvBTgvnzFBqaorJFaIouZXsl8j/G8pXqKDYCS9q+ddrtO2HXfrvwo9VMTxckrRv7x6t+Gq5uQUCBYjpjfGDDz6okJAQPfHEE4qIiND69et18OBBvfjii6pZs+Zf3n/ixIkKCAhwuGzatMkFlQMFT/uuPVSvQZRKBJSUr5+/2nZ+QPUaREmSUlNSdCSBj6/hGrea/RL5f0P9Bg113wPdVK7cbfLy8lKdunU1ZOi/7Os5CBvIO9OnUthsNi1atEht2rT5W0ckjx07Vk8++aTDsldffTW/ygMKjczMTBUr9uf/C3OqLLjKrWa/RP7f8Fd/27a/+LsH8DvTG+MFCxbc0v29vLyynX2hKJ/yJ+3aNV24cOH69bQ0+/IzZ07L08NTvr6+8vXzM6s8OElaWpouX7r+uqen//66nz97Rh6envL28dWJX49q7ow31PH+B1Wrbn0Vs9m0ac0K7dyxVZLk6+evChGVTakfRc+tZr9E/t8wfNhgRTW+Sy1atVJwcIgO/LRfM6ZPs6+/445IE6uDs6WlpenSxez5f+7cGXl4eMrHx1c+vr5KvnxJqampOp/lPMZp167p7JnTkqSAwJJyc3NzbfEWZFqCtG/fXgsXLlRAQIAk6aWXXtKwYcMUGBgoSTpz5ozuvfde7d2716wSC6T4+Dg90u/hbMvbtW4hSRo89DENGfavbOtRsO3fs1PPPTEo2/JBD3aUdP28xVH3NNeuH7Zp1w/bctxGvyFP/umpfoD8QPbnv5O//abXXpmo116ZmG1dwzsb6R9t25lQFVxl3+54PT38kWzL+z5w/XXv3W+wHhowRO9MfUWrv1rmMGbzpnXavGmdJGnux8tVJrSc8wu2ONM+X1m5cqVSU1PttydPnqyzZ8/ab6enp+unn34yozSgUAoNu019Hh2h2vUaKKh0sNzd3VW8RIDqN7pLE16bodYdYswuEUUA2Z//hv5rhNq176gKFSrK28dH3t7eqlatuoY//qRmvPs+ewGBm2DaHuM/fm0hX2ObP+5sFKWde3hTKWrq3NFQn6374S/Hde3ZR1179nFBRUDOyP7816x5CzVr3sLsMmCSuvXv1Fff/PUBliOfeUEjn3nBBRUVbMzIBwAAAGRiY2yz2bIdAc8R8QBQuJH9AKzM1KkUffv2tR9RnJKSosGDB8vv/8+YkHUOGgCgcCD7AViZaY1xnz6O8xwfeuihbGMefjj72RUAAAUX2Q/AykxrjOfMmWPWQwMATEL2A7AyDr4DAAAARGMMAAAASKIxBgAAACTRGAMAAACSaIwBAAAASRZpjOfNm6e7775bYWFhSkxMlCRNmTJFn3/+ucmVAQCchewHYDWmN8YzZszQk08+qfbt2+v8+fPKyMiQJAUGBmrKlCnmFgcAcAqyH4AVmd4YT5s2TbNmzdIzzzwjNzc3+/KGDRtq9+7dJlYGAHAWsh+AFZneGCckJCgyMjLbci8vLyUnJ5tQEQDA2ch+AFZkemMcERGh+Pj4bMu/+uor1apVy/UFAQCcjuwHYEWmfSX0DaNHj9awYcOUkpIiwzC0bds2LVy4UBMnTtR7771ndnkAACcg+wFYkemNcb9+/ZSenq6nnnpKV65cUa9evVSuXDlNnTpVPXv2NLs8AIATkP0ArMj0xliSBg4cqIEDB+r06dPKzMxUSEiI2SUBAJyM7AdgNZZojG8oXbq02SUAAFyM7AdgFaY3xhEREbLZbLmuP3TokAurAQC4AtkPwIpMb4wff/xxh9tpaWmKi4vTihUrNHr0aHOKAgA4FdkPwIpMb4xHjBiR4/K3335b27dvd3E1AABXIPsBWJHp5zHOTbt27bR06VKzywAAuBDZD8BMlm2MlyxZoqCgILPLAAC4ENkPwEymT6WIjIx0OADDMAwlJSXp1KlTmj59uomVAQCchewHYEWmN8YxMTEOt4sVK6bg4GA1a9ZMNWrUMKcoAIBTkf0ArMjUxjg9PV3h4eFq06aNypYta2YpAAAXIfsBWJWpc4zd3d01ZMgQpaammlkGAMCFyH4AVmX6wXdRUVGKi4szuwwAgAuR/QCsyPQ5xkOHDtXIkSN17NgxNWjQQH5+fg7r69ata1JlAABnIfsBWJFpjXH//v01ZcoU9ejRQ5I0fPhw+zqbzSbDMGSz2ZSRkWFWiQCAfEb2A7Ay0xrjDz74QJMmTVJCQoJZJQAAXIzsB2BlpjXGhmFIkipWrGhWCQAAFyP7AViZqQffZT25OwCgaCD7AViVqQffVatW7S8D8uzZsy6qBgDgCmQ/AKsytTGeMGGCAgICzCwBAOBiZD8AqzK1Me7Zs6dCQkLMLAEA4GJkPwCrMm2OMXPMAKDoIfsBWJlpjfGNI5MBAEUH2Q/AykybSpGZmWnWQwMATEL2A7AyU0/XBgAAAFgFjTEAAAAgGmMAAABAEo0xAAAAIInGGAAAAJBEYwwAAABIojEGAAAAJNEYAwAAAJJojAEAAABJNMYAAACAJBpjAAAAQBKNMQAAACCJxhgAAACQRGMMAAAASKIxBgAAACTRGAMAAACSaIwBAAAASTTGAAAAgCQaYwAAAEASjTEAAAAgSbIZhmGYXQTyX2pqqiZOnKixY8fKy8vL7HJgMn4fgKKDv3fcwO/CzaMxLqQuXryogIAAXbhwQSVKlDC7HJiM3weg6ODvHTfwu3DzmEoBAAAAiMYYAAAAkERjDAAAAEiiMS60vLy8FBsby2R7SOL3AShK+HvHDfwu3DwOvgMAAADEHmMAAABAEo0xAAAAIInGGAAAAJBEY1wgjR8/XnfccYfltgXnKgivVUGoESioyP6iqSC8VgWhxryiMc4nffv2lc1mk81mk4eHhypVqqRRo0YpOTnZ5bUcPnzYXovNZlPx4sVVu3ZtDRs2TD///LPD2FGjRmnNmjVOr8lms+mzzz5z+uO4mpVf96yXLVu2uKQGV/0+AVZh5Qwg+53Hyq872X9r3M0uoDBp27at5syZo7S0NG3atEmPPPKIkpOTNWPGjGxj09LS5OHh4dR6Vq9erdq1a+vKlSvavXu3pk6dqnr16umLL75Qy5YtJUn+/v7y9/fPdRvXrl2Tp6enU+ss6Kz6umdVqlQppz7mDX/1+wQURlbNALLfuaz6umdF9t889hjnIy8vL5UtW1bly5dXr1691Lt3b/t/yjc+Zpg9e7YqVaokLy8vGYahCxcuaNCgQQoJCVGJEiXUokUL7dy502G7kyZNUpkyZVS8eHENGDBAKSkpeaqnVKlSKlu2rCpVqqQuXbpo9erVioqK0oABA5SRkeFQ1w19+/ZVTEyMJk6cqLCwMFWrVk2S9Ouvv6pHjx4qWbKkSpUqpS5duujw4cMOjzd79mzVrl1bXl5eCg0N1WOPPSZJCg8PlyR17dpVNpvNfruwsOrrnvXi4eGhn376STabTfv373cY/5///Efh4eEyDEMZGRkaMGCAIiIi5OPjo+rVq2vq1KkO49evX69GjRrJz89PgYGBuvvuu5WYmOjw80rSypUr5e3trfPnzzvcf/jw4WratKn99nfffacmTZrIx8dH5cuX1/Dhw03Z6wL8XVbNALLfuaz6upP9t4bG2Il8fHyUlpZmv/3LL79o8eLFWrp0qeLj4yVJHTp0UFJSkpYvX64dO3aofv36atmypc6ePStJWrx4sWJjY/XSSy9p+/btCg0N1fTp0/9WPcWKFdOIESOUmJioHTt25DpuzZo12rdvn1atWqUvv/xSV65cUfPmzeXv76+NGzfqm2++kb+/v9q2batr165JkmbMmKFhw4Zp0KBB2r17t5YtW6YqVapIkr7//ntJ0pw5c3TixAn77cLKaq/7DdWrV1eDBg00f/58h+ULFixQr169ZLPZlJmZqdtuu02LFy/W3r179fzzz2vcuHFavHixJCk9PV0xMTFq2rSpdu3apc2bN2vQoEGy2WzZHq9Vq1YKDAzU0qVL7csyMjK0ePFi9e7dW5K0e/dutWnTRvfdd5927dqlRYsW6ZtvvrG/sQIFkdUygOx3Dau97jeQ/TfJQL7o06eP0aVLF/vtrVu3GqVKlTK6d+9uGIZhxMbGGh4eHsbJkyftY9asWWOUKFHCSElJcdhW5cqVjZkzZxqGYRjR0dHG4MGDHdZHRUUZ9erVy7WWhIQEQ5IRFxeXbd2+ffsMScaiRYvsdWXdVp8+fYwyZcoYqamp9mXvv/++Ub16dSMzM9O+LDU11fDx8TFWrlxpGIZhhIWFGc8880yuNUkyPv3001zXF1RWfN19fHwMPz8/h0t6erphGIbxn//8x6hUqZL9Pj/99JMhydizZ0+u2x06dKhx//33G4ZhGGfOnDEkGevXr89x7B9/n4YPH260aNHCfnvlypWGp6encfbsWcMwDOOf//ynMWjQIIdtbNq0yShWrJhx9erVXGsCrMKKGUD2O58VX3eyP38wxzgfffnll/L391d6errS0tLUpUsXTZs2zb6+YsWKCg4Ott/esWOHLl++nG0O0NWrV3Xw4EFJ0r59+zR48GCH9dHR0Vq3bt3fqtH4/y86zOm/vBvq1KnjMLdsx44d+uWXX1S8eHGHcSkpKTp48KBOnjyp48eP2+euFTVWe90XLVqkmjVrOixzc3OTJPXs2VOjR4/Wli1b1LhxY82fP1933HGHatWqZR/7zjvv6L333lNiYqKuXr2qa9eu2T8iCwoKUt++fdWmTRu1bt1arVq1Uvfu3RUaGppjLb1791Z0dLSOHz+usLAwzZ8/X+3bt1fJkiXtz8Uvv/zisCfDMAxlZmYqISEh288BWJHVMiAnZH/+s9rrTvbnDxrjfNS8eXPNmDFDHh4eCgsLyzbR3s/Pz+F2ZmamQkNDtX79+mzbCgwMdEqN+/btkyRFRETkOianOnP6GEaSgoODVaxY0Z6RY7XXvXz58vaPMv8oNDRUzZs314IFC9S4cWMtXLhQjz76qH394sWL9cQTT+j1119XdHS0ihcvrldffVVbt261j5kzZ46GDx+uFStWaNGiRXr22We1atUqNW7cONvjNWrUSJUrV9ZHH32kIUOG6NNPP9WcOXPs6zMzM/Xoo49q+PDh2e5boUKFW3kaAJexWgbkhOzPf1Z73cn+/EFjnI/8/Pxy/aXMSf369ZWUlCR3d/dcD0qoWbOmtmzZoocffti+7O+efiUzM1NvvvmmIiIiFBkZeVN1Llq0yH6wQE7Cw8O1Zs0aNW/ePMf1Hh4e9oM+Churv+5/1Lt3bz399NN68MEHdfDgQfXs2dO+btOmTbrrrrs0dOhQ+7IbezKyioyMVGRkpMaOHavo6Gh72OakV69emj9/vm677TYVK1ZMHTp0sK+rX7++9uzZc1PPH2A1Vs8Ast85rP66/xHZnzdF+989k7Vq1UrR0dGKiYnRypUrdfjwYX333Xd69tlntX37dknSiBEjNHv2bM2ePVsHDhxQbGys9uzZk6ftnzlzRklJSTp06JCWLVumVq1aadu2bXr//fftH6/kRe/evVW6dGl16dJFmzZtUkJCgjZs2KARI0bo2LFjkq4fkfr666/rzTff1M8//6wffvjB4SOlG+GZlJSkc+fO3cSzVPi46nXPesl6VPN9992nixcvasiQIWrevLnKlStnX1elShVt375dK1eu1IEDB/Tcc885HDCTkJCgsWPHavPmzUpMTNTXX3+tAwcO/OnHXr1799YPP/ygl156SQ888IC8vb3t655++mlt3rxZw4YNU3x8vH7++WctW7ZM//rXv/L8fAIFDdlfNJH9BSP7aYxNZLPZtHz5cjVp0kT9+/dXtWrV1LNnTx0+fFhlypSRJPXo0UPPP/+8nn76aTVo0ECJiYkaMmRInrbfqlUrhYaGqk6dOhozZoxq1qypXbt25fqffW58fX21ceNGVahQQffdd59q1qyp/v376+rVq/a9CH369NGUKVM0ffp01a5dWx07dnQ4ofzrr7+uVatWqXz58je1x6IwctXrnvWS9QT7JUqUUKdOnbRz5077EcI3DB48WPfdd5969OihqKgonTlzxmEPgq+vr/bv36/7779f1apV06BBg/TYY485fCT3R1WrVtWdd96pXbt2ZXu8unXrasOGDfr555917733KjIyUs8991yu89aAwoDsL5rI/t9ZOfttxo0Z+QAAAEARxh5jAAAAQDTGAAAAgCQaYwAAAEASjTEAAAAgicYYAAAAkERjDAAAAEiiMQYAAAAk0RgDAAAAkmiMUciMHz9ed9xxh/123759FRMT4/I6Dh8+LJvNpvj4eJc/NgAUNWQ/8guNMVyib9++stlsstls8vDwUKVKlTRq1CglJyc79XGnTp2quXPn5mksgQYA+YvsR0HjbnYBKDratm2rOXPmKC0tTZs2bdIjjzyi5ORkzZgxw2FcWlqaPDw88uUxAwIC8mU7AIC/h+xHQcIeY7iMl5eXypYtq/Lly6tXr17q3bu3PvvsM/tHYLNnz1alSpXk5eUlwzB04cIFDRo0SCEhISpRooRatGihnTt3Omxz0qRJKlOmjIoXL64BAwYoJSXFYf0fP07LzMzU5MmTVaVKFXl5ealChQp66aWXJEkRERGSpMjISNlsNjVr1sx+vzlz5qhmzZry9vZWjRo1NH36dIfH2bZtmyIjI+Xt7a2GDRsqLi4uH585ACi4yH4UJOwxhml8fHyUlpYmSfrll1+0ePFiLV26VG5ubpKkDh06KCgoSMuXL1dAQIBmzpypli1b6sCBAwoKCtLixYsVGxurt99+W/fee6/mzZunN998U5UqVcr1MceOHatZs2bpjTfe0D333KMTJ05o//79kq4HXKNGjbR69WrVrl1bnp6ekqRZs2YpNjZWb731liIjIxUXF6eBAwfKz89Pffr0UXJysjp27KgWLVrov//9rxISEjRixAgnP3sAUDCR/bA0A3CBPn36GF26dLHf3rp1q1GqVCmje/fuRmxsrOHh4WGcPHnSvn7NmjVGiRIljJSUFIftVK5c2Zg5c6ZhGIYRHR1tDB482GF9VFSUUa9evRwf9+LFi4aXl5cxa9asHGtMSEgwJBlxcXEOy8uXL28sWLDAYdkLL7xgREdHG4ZhGDNnzjSCgoKM5ORk+/oZM2bkuC0AKErIfhQ0TKWAy3z55Zfy9/eXt7e3oqOj1aRJE02bNk2SVLFiRQUHB9vH7tixQ5cvX1apUqXk7+9vvyQkJOjgwYOSpH379ik6OtrhMf54O6t9+/YpNTVVLVu2zHPNp06d0tGjRzVgwACHOl588UWHOurVqydfX9881QEARQnZj4KEqRRwmebNm2vGjBny8PBQWFiYw0EWfn5+DmMzMzMVGhqq9evXZ9tOYGDg33p8Hx+fm75PZmampOsfqUVFRTmsu/Gxn2EYf6seACgKyH4UJDTGcBk/Pz9VqVIlT2Pr16+vpKQkubu7Kzw8PMcxNWvW1JYtW/Twww/bl23ZsiXXbVatWlU+Pj5as2aNHnnkkWzrb8wry8jIsC8rU6aMypUrp0OHDql37945brdWrVqaN2+erl69ag/gP6sDAIoSsh8FCVMpYEmtWrVSdHS0YmJitHLlSh0+fFjfffednn32WW3fvl2SNGLECM2ePVuzZ8/WgQMHFBsbqz179uS6TW9vbz399NN66qmn9OGHH+rgwYPasmWL3n//fUlSSEiIfHx8tGLFCv3222+6cOGCpOsnjp84caKmTp2qAwcOaPfu3ZozZ47+85//SJJ69eqlYsWKacCAAdq7d6+WL1+u1157zcnPEAAUPmQ/zEZjDEuy2Wxavny5mjRpov79+6tatWrq2bOnDh8+rDJlykiSevTooeeff15PP/20GjRooMTERA0ZMuRPt/vcc89p5MiRev7551WzZk316NFDJ0+elCS5u7vrzTff1MyZMxUWFqYuXbpIkh555BG99957mjt3rurUqaOmTZtq7ty59lP8+Pv764svvtDevXsVGRmpZ555RpMnT3biswMAhRPZD7PZDCbJAAAAAOwxBgAAACQaYwAAAEASjTEAAAAgicYYAAAAkERjDAAAAEiiMQYAAAAk0RgDAAAAkmiMAQAAAEk0xgAAAIAkGmMAAABAEo0xAAAAIInGGAAAAJBEYwwAAABIojEGAAAAJNEYAwAAAJJojAEAAABJNMZwor59+8pms8lms2n9+vWSZL8dHh5uam0AUJDklKe5adasmX3s4cOHXVKfGbWMHz/evu25c+fe8vbWr19v317fvn1N28atiI+P1/jx4zV+/Pi//D1BztzNLgAAAAC3Lj4+XhMmTLDfbtasmXnFFFDsMQYAACjArly5YnYJhQaNMUw3d+5c+0dPsbGxmjRpkipUqCBfX1+1bt1aBw4c0IULF/Too4+qVKlSCg4OVo8ePXTy5MmbepyNGzeqS5cuqly5sgICAuTu7q7SpUurdevW+uyzz+zjli1bZq9n0KBBDtv49ttv7eseeOABh+V33323fHx8FBYWpqeeekpfffWVqR+pASicrly5opEjRyo0NFTe3t5q3Lhxnj42NwxDc+fOVZMmTRQYGChPT0+Fh4dr2LBhSkpKchibdQrE5s2b1adPH5UqVUqBgYFq166dDh486DA+JSXFXpOPj4+io6O1YcOGfKlFkt59911Vr15dXl5eql69ut555528PVm52LRpk+666y75+PgoNDRUI0eO/NPmMiEhQY8++qgqVaokLy8vlShRQk2aNNHHH3/8p4+zdOlS3XHHHfL29laFChX073//W5mZmQ5jLl++rAkTJqhu3bry8/OTj4+P6tSpo0mTJunatWsOY7NOR9y8ebOaNm0qPz8/tW/fXuHh4erXr5997IQJE+zjx48fL0n69NNP1a5dO1WsWFHFixeXh4eHypYtq86dO2vjxo03+SwWUgbgJH369DEkGZKMdevWGYZh2G9XrFjRPm7OnDn25cHBwfbrWcc2btw42/J//OMfN1XPG2+8kW0bWS8LFiwwDMMw0tPTjXLlyhmSjMDAQCMlJcW+jUcffdQ+fuXKlYZhGMaWLVsMLy+vbNsrX768/XqfPn1u6bkEULRlzdMb+ZT14uHhYWzatMkwDMNo2rSpfXlCQoJhGIaRmZlp9OzZM9f8Cw0NtY/94zZKliyZbXzNmjWN9PR0+/jOnTvnWFPWTP+7tbz++us5jsv6PMyZMyfPz+V3331neHp6/un2smb2tm3bjOLFi+da75gxY+xj161bZ18eFhaW4/ghQ4bYx585c8aoVatWrttu0qSJkZqaah9/Y7mvr6/h4+Njv920aVOjYsWKuW4nNjbWMAzDGDFiRK5j3NzcjI0bN+b5eSys2GMMS7l06ZJWrlypc+fOqVGjRpKkxMRE7d69Wxs2bNCJEydUvnx5SdLXX3+d456F3DRr1kxr1qxRUlKSUlNTlZycrC+++MK+/rXXXpMkubm5qX///pKk8+fP28dcu3ZNixcvliRFRESodevWkqSnnnpKqampkqQ+ffrozJkz2rVrl9zdmcIPIP95e3tr165dOnv2rIYMGSJJSktL0+jRo3O9zyeffKKPPvpI0vUD+U6cOKGUlBQtWLBAknTixIlc71+uXDnt379fx44dU82aNSVJ+/bt0/fffy9JWrdunZYtWyZJCgoK0qZNm3ThwgXFxsbq1KlTt1TLpUuXFBsba7/ve++9p0uXLul///ufTp8+ncdnzNGYMWPse2IfeeQRnT17Vj/++KN8fX1zHN+/f39dunRJgYGBWr16tVJSUnTkyBHde++9kqTJkyfrxx9/zHa/48eP6/3337fX6+XlJUl65513tH//fklSbGys9u7dK0l66623dPHiRZ0/f17Dhw+XdP2TzlmzZmXb9pUrV9S4cWMdOHBAycnJmj59ug4fPqw5c+bYx8TGxsowDBmGYd9j/MADD+jbb7/Vb7/9pmvXrunChQuaMWOGJCkjI0NTpky52aez8DG7M0fh9Xf2GPfo0cO+/KmnnrIv79Wrl3151j0NmzdvznM9p06dMh5//HGjRo0aDv9p37h4e3vbxyYmJhrFihUzJBmdOnUyDMMwlixZYh/70ksvGYZhGMnJyfZxNpvNOHfunH0bM2bMYI8xgHyRNU9nzpxpX3758mXD3d3dnkHnz5/PcY9x7969//QTM0mGv7+/fbtZt/H555/bl48cOdK+fOHChYZhGMaYMWPsy0aOHGkfm5mZ6bAX9u/UsmLFCvuyBg0aODwnDz744E3vMU5OTjbc3Nzsz9eFCxfs62bOnJkts3/++ee/rFWS8dprrxmG4bjHODo6Otd633zzTcMwjBz3/v/x0rFjR/s2si4/cuRItp8v6/vpjb3EWSUkJBgDBgwwKlWqlOMnnTVq1MjT81iYsUsLllKlShX7dR8fH/v1iIgI+/Ub/3VL1+e15UVmZqZatmypXbt25Tom67YqVKigNm3a6KuvvtKKFSt0+vRpzZs3T5Lk7u5u36N87tw5+3yxgIAABQYG2rfBKekAOEPFihXt1/38/FS6dGklJSXJMIxc96L+9ttvf7ndy5cvKzU11SFjJdn3Et94vBtuZGbWx7zxiZ50fT5s+fLl9euvv/7tWnLbtuT4POTVuXPnlJGRIel6ZpcoUeJPt5eXWiXl+Lz/cXtZb984RiYv289p28HBwdmej79y6dIl3XXXXTpx4kSuY65evXpT2yyMmEoBS8lt+sGtTkvYvXu3vSkuU6aMdu/erfT0dF28eDHX+wwcOFDS9Y8o3377bS1fvlyS1LlzZ5UtW1aSVLJkSbm5uUmSLly44LC9hISEW6oZAHKSmJhov56cnGxvnGw2m0qXLp3jfcqUKWO/vnDhQvtH7FkvmZmZ2ZpiSfLw8LBft9ls2dZnfcyjR4/arxuG4XD779SS27b/+DzkVcmSJVWs2PXW54+ZndP2stZao0aNHGs1DEMvv/xytvv+cXtZb4eEhDhs32az6fjx4zlu+7vvvsu27dymfeT0+tywdu1ae1Ncu3ZtHTp0SJmZmX+6w6goojFGkZC1sXZzc5O/v78uXLigJ598Mtf7dOrUSaGhoZKkF198UWlpaZLkcKYKX19f3XPPPZKuvwk89dRTOnfunHbv3q1XX33VGT8KgCLutdde0549e3T+/HmNHj1a6enpkqSoqCgFBATkeJ+uXbvar48dO1YbNmxQSkqKLly4oPXr16t///4aNmzY36rnH//4h/363Llz9e233+rSpUt6+eWXs+0tvtla7rrrLvn7+0uSduzYoffff1+XL1/WV199pU8++eSma/1jZo8aNUrnzp3T3r177ceZZFWlShXdfvvtkqT9+/dr1KhROnHihNLS0nTo0CFNnz5ddevWzbGp3rx5s+bOnZutXpvNZj9G5cZzYRiG+vTpo3379iktLU1JSUlasmSJ2rZta/+0Mi9KlSplv75v3z6Hs1pkfR90d3eXn5+fkpKSNG7cuDxvv0hw1ZwNFD1/Z45x1jlRsbGxOS7Pabt/JT093bj99tuzzaeqVq2aw+0/GjdunMP68PBwIyMjw2HM1q1bc5yrlXXuWN++ffP6tAFANvlxVopevXr96VzWrMdC5LQNw3DM5azzejt16pRte25ubkZQUNAt15LbWSmynvEiP85KkXV7fzwrRYkSJf603hs/W17OSjF48GD7ts+cOWPUrl37T7ed9WfL6T00q19//TXH96N169YZ586dM8qWLfun74O5bbcoYY8xigQ3Nzd98cUXiomJUcmSJVWiRAndf//9Wrt27Z/eb+DAgQ4fTT3yyCP2j+FuaNSokVavXq3o6Gh5eXmpTJkyeuKJJ/TSSy/Zx+T28SYA3Kx3331XTzzxhMqWLSsvLy81atRIK1eutO8JzYnNZtN///tfzZs3T82bN1fJkiXl7u6usmXLKioqSs8884xGjRr1t2tavHixnnzySZUpU8Ze0/Lly1WnTp1bruXJJ5/UO++8o6pVq8rDw0NVqlTRlClTNHTo0L9Va3R0tFatWqXGjRvLy8tLISEheuyxx/T+++/nOP7OO+/Url27NHToUFWpUkVeXl7y9/dX1apV1a1bN82dO1dhYWHZ7te6dWstWbJE9erVk6enp2677TZNmDBBb731ln1MUFCQtm7dqhdeeEGRkZHy8/OTl5eXKlasqNatW+v1119Xu3bt8vyzhYWFaf78+apTp47DcTqSFBgYqJUrV6ply5YqXry4SpUqpQEDBmjRokV53n5RYDMMwzC7CKCg++KLL9SqVSt7ECUmJqpbt2720xmtWrVKrVq1MrNEAADwF2iMgXxgs9nk5uam4OBgZWZm6tSpU7rxp9WvXz/Nnj3b5AoBAMBfYSoFCrysXymd28XZHnnkEVWrVk3Jyck6e/asgoOD1bZtWy1atIimGABcYP369X/5XnD48GGzy4TFcR5jIB/k9M1EAACgYGEqBQAAACCmUgAAAACSaIwBAAAASTTGAAAAgCQaYwAAAEBSIT0rxYQJE8wuAYBFxcbGml0CnIj8B5CTvGZ/oWyMJen7su3NLgEWcWfSck367JTZZcAi6IsLv24D//5XG6Nw+XjWa+Q/JOU9+5lKAQAAAIjGGAAAAJBEYwwAAABIojEGAAAAJNEYAwAAAJJojAEAAABJNMYAAACAJBpjAAAAQBKNMQAAACCJxhgAAACQRGMMAAAASKIxBgAAACTRGAMAAACSaIwBAAAASTTGAAAAgCQaYwAAAEASjTEAAAAgicYYAAAAkERjDAAAAEiiMQYAAAAk0RgDAAAAkmiMAQAAAEk0xgAAAIAkGmMAAABAEo0xAAAAIInGGAAAAJBEYwwAAABIskBj/OGHHyo1NTXb8mvXrunDDz80oSIAgLOR/QCsyPTGuF+/frpw4UK25ZcuXVK/fv1MqAgA4GxkPwArMr0xNgxDNpst2/Jjx44pICDAhIoAAM5G9gOwInezHjgyMlI2m002m00tW7aUu/vvpWRkZCghIUFt27Y1qzwAgBOQ/QCszLTGOCYmRpIUHx+vNm3ayN/f377O09NT4eHhuv/++02qDgDgDGQ/ACszrTGOjY2VJIWHh6tnz57y8vIyqxQAgIuQ/QCszPQ5xrVq1VJ8fHy25Vu3btX27dtdXxAAwOnIfgBWZHpjPGzYMB09ejTb8l9//VXDhg0zoSIAgLOR/QCsyPTGeO/evapfv3625ZGRkdq7d68JFQEAnI3sB2BFpjfGXl5e+u2337ItP3HihMPRygCAwoPsB2BFpjfGrVu31tixYx1O9H7+/HmNGzdOrVu3NrEyAICzkP0ArMj0f8tff/11NWnSRBUrVlRkZKSk66fxKVOmjObNm2dydQAAZyD7AViR6Y1xuXLltGvXLs2fP187d+6Uj4+P+vXrpwcffFAeHh5mlwcAcAKyH4AVmd4YS5Kfn58GDRpkdhkAABci+wFYjelzjCVp3rx5uueeexQWFqbExERJ0htvvKHPP//c5MoAAM5C9gOwGtMb4xkzZujJJ59Uu3btdO7cOWVkZEiSSpYsqSlTpphbHADAKch+AFZkemM8bdo0zZo1S88884zDKXoaNmyo3bt3m1gZAMBZyH4AVmR6Y5yQkGA/IjkrLy8vJScnm1ARAMDZyH4AVmR6YxwREaH4+Phsy7/66ivVqlXL9QUBAJyO7AdgRaaflWL06NEaNmyYUlJSZBiGtm3bpoULF2rixIl67733zC4PAOAEZD8AKzK9Me7Xr5/S09P11FNP6cqVK+rVq5fKlSunqVOnqmfPnmaXBwBwArIfgBWZ2hinp6dr/vz56tSpkwYOHKjTp08rMzNTISEhZpYFAHAish+AVZk6x9jd3V1DhgxRamqqJKl06dIEIwAUcmQ/AKsy/eC7qKgoxcXFmV0GAMCFyH4AVmT6HOOhQ4dq5MiROnbsmBo0aCA/Pz+H9XXr1jWpMgCAs5D9AKzI9Ma4R48ekqThw4fbl9lsNhmGIZvNZv82JABA4UH2A7Ai0xvjhIQEs0sAALgY2Q/AikxvjCtWrGh2CQAAFyP7AViRKY3xsmXL1K5dO3l4eGjZsmV/OrZz584uqgoA4ExkPwCrM6UxjomJUVJSkkJCQhQTE5PrOOaZ5a5hhQB1qVNGFUr6qIS3uzIyDf126Zq2HD6nj+NOKCU9U5LUslopPdG80p9uq+PM711RMpzooU5RmvXvf+a4budPx9S45yRJUkhQcT3Rp5XaN7ldYSGBSr2WrsO/ntbczzZr9iffKjPTcGXZKGLI/vxx4tcj+mThB/rpx506diRBhnH973bRys3y9PSSJK1dsUzTJo//0+18uu4HZ5cKJ7sa99afrh/4/Dz994utksj/vDKlMc7MzMzxOvKuRhl/Rd4WYL/t4SZVDPJRxSAfVS7tq/Ff/Zyn7VxN482nqHBzK6aVs0aoRqWy9mX+vl4qFeinBrUrqmrFED39+icmVojCjuzPH0cSDmr1/z69pW14e/vkUzWwsuSr188VTv7nnelzjPH3HDiZrBdX/qyfTiYrOTVdd9wWoDGtKsvTvZgaVgiUv5ebLqdmaM2BM1pz4IzDfWuU8dNrMbUkSet/PpPT5lFAJR4/oxodYnNc16BWBXsoxu07qi7D3laZ0iW0ds6TKu7nrb4x0QQjUAAElQ7RAw8NUI3b79DiD2bqwL4fs41p0bazWrR1nI6yf89OjX2snySpSat2LqkVzuUT+Vi2ZfGfPKvqEWV17uIVrfhmjyTy/2aY2hhnZmZq7ty5+uSTT3T48GHZbDZFRETogQce0D//+U/ZbDYzy7O0bYnns90+cu6qqgRfPxdoxp98JNK+1u/fMLV8z0mn1Afrycj4fQ/dmi37dOrcZZ06d1n7DyXpzjrh8vLk/2S4Btl/a6rWqK2qNWpLkj5dODfP91v5+RL79bZduud3WbCApndWU/WI6w3wf5dt0dWUNEnk/80w7ZvvDMNQ586d9cgjj+jXX39VnTp1VLt2bSUmJqpv377q2rWrWaUVOJ5uNjUOD1SFktc/Glt74LSupuX8MWVxLzfdXSlIkrQ36ZISzl51WZ1wvtDgAB1bN1kXtk3RnmWxevnxGPn7Xp9z+MO+o9r+42FJUsvGNRVc0l+3Vw1TzcqhkqS1W38yq2wUIWS/OS5eOK/vNqyWJNWoXU8RVaqZXBGcYVC3eyRd/+fz3Y+/sS8n//POtH8R5s6dq40bN2rNmjVq3ry5w7q1a9cqJiZGH374oR5++GGTKrS+QB93/ffhSIdlGw+e1dQNh3O9T6vqwfJyv/7/EHuLCx9PD3eVCrz+Z12pfLCe6NNKTe+spmZ9XldaeoY6DHlLi14fqGaNquvI2kn2+32+Jl7DXlxoVtkoQsh+c6xdsUzXrl2fb9q2SzeTq4EzlC1dQp2a1ZMkrdt2QL8c+f093jAM8j+PTNtjvHDhQo0bNy5bMEpSixYtNGbMGM2fP9+Eygq2JpWD9HiziFzXt6sVLEk6fzVN3xw656qy4GSHjp7SkH/PV/X2zysw6nHd+9CrOnD4N0lS/VoV1K1tA9lsNs1+sY+aNaqe7f4R5UurSoWQbMuB/Eb2u55hGPr6i6WSpBKBJXVX01YmVwRn6HffXfLwcJMkzfp4k8M68j/vTGuMd+3apbZt2+a6vl27dtq5c+dfbic1NVUXL150uKSnp+dnqZZ1/mq6Os78Xve/v0Njl+3XqcvXJEnNq5ZS5dK+2cbXv62EwgK8JUmr9p9WOqdmKTS+iz+kuZ9u1pETZ5V6LV3b9yTqpZnL7evvvD1cHZvWUYemdSRJn66OU2iT0are/nnt+eW46la7TUunDlZxP2+zfgQUEfmV/VLRzv+bEf/9Zp349agkqWW7LvLw9DS5IuS3YsVs6t/1bknSr7+d05cbdjusJ//zzrTG+OzZsypTpkyu68uUKaNz5/56j+bEiRMVEBDgcNm0adNf3q8wSU3P1O4Tl/TtobP2ZeUCsv+Ct/v/g+4yMg19tZdpFIXJXx2sZBiGqkf8/ve26KvtOn/pqo6cOKuV/3/UcqlAP9WtVs6pdQL5lf0S+Z9XK5ZdP+iuWLFiatv5AZOrgTN0aFJHt5UtKUl6/5NvHQ62k0T+3wTTGuOMjAy5u+c+xdnNzS1P//mPHTtWFy5ccLjce++9+VmqJf2rSbjqhBVXCW93ebjZVLOMv+6KKGlfn3Qx1WF8KT8PNaoYKEnacfSCTv7/3mUUDkunPqp/9W6uCqFB8vRwV4NaFfTMo+3t67fsPKTjpy7Yb/do11CBxX1UIbSk2txT2778/CUOxoRz5Vf2S0U3/9PS0nTu7GmdO3ta6elp9uXnz57RubOndfXqFfuy06d+0/bN1/9ZiGx0l0LKhrm8XjjfwG7Xf++vpaVrziffZVtP/uedaQffGYahvn37ysvLK8f1qampOS7/Iy8vr2zb+LPQLSza1AxWm5rBOa7bcvicDpxKdljWtmaw3Ipd36vIQXeFT1hIoF4Zdb9eGXV/tnUbvj+gJV//IB8vDz03uL3Cy5VW11aR6trK8cDNTTt+1p5fjruqZBRR+ZX9UtHN/5/27NRzTwzKtvzRBztKknr0GaSefQdLkr7+4hNlZl7/Iqd2nKKtUIq4rbRaNr4+d/iLdbuUdPpitjGfr4kn//PItATp06fPX47hqOTcfb47SbXLFldIcS/5ebrpalqGjpy7qo2/nNVX+045jC1mk/5R43oTnXQxRTuOXshpkyjA/j39S3Vv21ANaldQaHCAbLLpl6Mn9fHKH/TmvLXKzDSUfPWaWvR7Q+MGtVPru2oqNDhAmZmGEo+f0bJ1u/TK+yvN/jFQBJD9rpORka7Vy69/Q16Z0HKKbHSXyRXBGQY+cI+KFbs+AWDm4pynEpH/eWczbnzJeiEyYcIEfV+2/V8PRJFwZ9JyTfrs1F8PRJFwNe4ts0uAE02YMEHdBo4yuwxYxMezXiP/ISnv2W/aHGMAAADASmiMAQAAANEYAwAAAJJojAEAAABJNMYAAACAJIs0xvPmzdPdd9+tsLAwJSYmSpKmTJmizz//3OTKAADOQvYDsBrTG+MZM2boySefVPv27XX+/HllZFw/EXlgYKCmTJlibnEAAKcg+wFYkemN8bRp0zRr1iw988wzcnNzsy9v2LChdu/ebWJlAABnIfsBWJHpjXFCQoIiIyOzLffy8lJycnIO9wAAFHRkPwArMr0xjoiIUHx8fLblX331lWrVquX6ggAATkf2A7Aid7MLGD16tIYNG6aUlBQZhqFt27Zp4cKFmjhxot577z2zywMAOAHZD8CKTG+M+/Xrp/T0dD311FO6cuWKevXqpXLlymnq1Knq2bOn2eUBAJyA7AdgRaY3xpI0cOBADRw4UKdPn1ZmZqZCQkLMLgkA4GRkPwCrsURjfEPp0qXNLgEA4GJkPwCrML0xjoiIkM1my3X9oUOHXFgNAMAVyH4AVmR6Y/z444873E5LS1NcXJxWrFih0aNHm1MUAMCpyH4AVmR6YzxixIgcl7/99tvavn27i6sBALgC2Q/Aikw/j3Fu2rVrp6VLl5pdBgDAhch+AGaybGO8ZMkSBQUFmV0GAMCFyH4AZjJ9KkVkZKTDARiGYSgpKUmnTp3S9OnTTawMAOAsZD8AKzK9MY6JiXG4XaxYMQUHB6tZs2aqUaOGOUUBAJyK7AdgRaY2xunp6QoPD1ebNm1UtmxZM0sBALgI2Q/AqkydY+zu7q4hQ4YoNTXVzDIAAC5E9gOwKtMPvouKilJcXJzZZQAAXIjsB2BFps8xHjp0qEaOHKljx46pQYMG8vPzc1hft25dkyoDADgL2Q/AikxrjPv3768pU6aoR48ekqThw4fb19lsNhmGIZvNpoyMDLNKBADkM7IfgJWZ1hh/8MEHmjRpkhISEswqAQDgYmQ/ACszrTE2DEOSVLFiRbNKAAC4GNkPwMpMPfgu68ndAQBFA9kPwKpMPfiuWrVqfxmQZ8+edVE1AABXIPsBWJWpjfGECRMUEBBgZgkAABcj+wFYlamNcc+ePRUSEmJmCQAAFyP7AViVaXOMmWMGAEUP2Q/AykxrjG8cmQwAKDrIfgBWZtpUiszMTLMeGgBgErIfgJWZero2AAAAwCpojAEAAADRGAMAAACSaIwBAAAASTTGAAAAgCQaYwAAAEASjTEAAAAgKY/nMV62bFmeN9i5c+e/XQwAwDrIfgBFTZ4a45iYmDxtzGazKSMj41bqAQBYBNkPoKjJU2PMNxUBQNFD9gMoaphjDAAAACiPe4z/KDk5WRs2bNCRI0d07do1h3XDhw/Pl8IAANZC9gMo7G66MY6Li1P79u115coVJScnKygoSKdPn5avr69CQkIIRwAohMh+AEXBTU+leOKJJ9SpUyedPXtWPj4+2rJlixITE9WgQQO99tprzqgRAGAysh9AUXDTjXF8fLxGjhwpNzc3ubm5KTU1VeXLl9crr7yicePGOaNGAIDJyH4ARcFNN8YeHh6y2WySpDJlyujIkSOSpICAAPt1AEDhQvYDKApueo5xZGSktm/frmrVqql58+Z6/vnndfr0ac2bN0916tRxRo0AAJOR/QCKgpveY/zyyy8rNDRUkvTCCy+oVKlSGjJkiE6ePKl333033wsEAJiP7AdQFNz0HuOGDRvarwcHB2v58uX5WhAAwHrIfgBFAV/wAQAAAOhv7DGOiIiwH4CRk0OHDt1SQQAA6yH7ARQFN90YP/744w6309LSFBcXpxUrVmj06NH5VRcAwELIfgBFwU03xiNGjMhx+dtvv63t27ffckEAAOsh+wEUBfk2x7hdu3ZaunRpfm0OAFAAkP0ACpN8a4yXLFmioKCg/NocAKAAIPsBFCZ/6ws+sh6AYRiGkpKSdOrUKU2fPj1fiwMAWAPZD6AouOnGuEuXLg7hWKxYMQUHB6tZs2aqUaNGvhZ3K+5M4hyb+N2YmGCzSwAKtIKS/ZL08azXzC4BFkL+42bcdGM8fvx4J5SR/55+JtbsEmARk1+aoMFPjDO7DKBAKyjZL5H/+N3klyao/7/GmF0GCpCbnmPs5uamkydPZlt+5swZubm55UtRAABrIfsBFAU33RgbhpHj8tTUVHl6et5yQQAA6yH7ARQFeZ5K8eabb0qSbDab3nvvPfn7+9vXZWRkaOPGjZabZwYAuDVkP4CiJM+N8RtvvCHp+l6Dd955x+GjM09PT4WHh+udd97J/woBAKYh+wEUJXlujBMSEiRJzZs31yeffKKSJUs6rSgAgDWQ/QCKkps+K8W6deucUQcAwMLIfgBFwU0ffPfAAw9o0qRJ2Za/+uqr6tatW74UBQCwFrIfQFFw043xhg0b1KFDh2zL27Ztq40bN+ZLUQAAayH7ARQFN90YX758OcdT83h4eOjixYv5UhQAwFrIfgBFwU03xrfffrsWLVqUbflHH32kWrVq5UtRAABrIfsBFAU3ffDdc889p/vvv18HDx5UixYtJElr1qzRggULtGTJknwvEABgPrIfQFFw041x586d9dlnn+nll1/WkiVL5OPjo3r16mnt2rUqUaKEM2oEAJiM7AdQFNx0YyxJHTp0sB+Ecf78ec2fP1+PP/64du7cqYyMjHwtEABgDWQ/gMLupucY37B27Vo99NBDCgsL01tvvaX27dtr+/bt+VkbAMBiyH4AhdlN7TE+duyY5s6dq9mzZys5OVndu3dXWlqali5dysEXAFBIkf0Aioo87zFu3769atWqpb1792ratGk6fvy4pk2b5szaAAAmI/sBFCV53mP89ddfa/jw4RoyZIiqVq3qzJoAABZB9gMoSvK8x3jTpk26dOmSGjZsqKioKL311ls6deqUM2sDAJiM7AdQlOS5MY6OjtasWbN04sQJPfroo/roo49Urlw5ZWZmatWqVbp06ZIz6wQAmIDsB1CU3PRZKXx9fdW/f39988032r17t0aOHKlJkyYpJCREnTt3dkaNAACTkf0AioK/fbo2SapevbpeeeUVHTt2TAsXLsyvmgAAFkb2AyisbqkxvsHNzU0xMTFatmzZ37r/wYMH9eyzz+rBBx/UyZMnJUkrVqzQnj178qM8AIATkP0ACpt8aYxvxYYNG1SnTh1t3bpVn3zyiS5fvixJ2rVrl2JjY02uDgDgDGQ/ACsyvTEeM2aMXnzxRa1atUqenp725c2bN9fmzZtNrAwA4CxkPwArMr0x3r17t7p27ZpteXBwsM6cOWNCRQAAZyP7AViR6Y1xYGCgTpw4kW15XFycypUrZ0JFAABnI/sBWJHpjXGvXr309NNPKykpSTabTZmZmfr22281atQoPfzww2aXBwBwArIfgBWZ3hi/9NJLqlChgsqVK6fLly+rVq1aatKkie666y49++yzZpcHAHACsh+AFbmbXYCHh4fmz5+vf//734qLi1NmZqYiIyNVtWpVs0sDADgJ2Q/AikxvjDds2KCmTZuqcuXKqly5stnlAABcgOwHYEWmT6Vo3bq1KlSooDFjxujHH380uxwAgAuQ/QCsyPTG+Pjx43rqqae0adMm1a1bV3Xr1rV/1SgAoHAi+wFYkemNcenSpfXYY4/p22+/1cGDB9WjRw99+OGHCg8PV4sWLcwuDwDgBGQ/ACsyvTHOKiIiQmPGjNGkSZNUp04dbdiwweySAABORvYDsArLNMbffvuthg4dqtDQUPXq1Uu1a9fWl19+aXZZAAAnIvsBWInpZ6UYN26cFi5cqOPHj6tVq1aaMmWKYmJi5Ovra3ZpAAAnIfsBWJHpjfH69es1atQo9ejRQ6VLlza7HACAC5D9AKzI9Mb4u+++M7sEAICLkf0ArMiUxnjZsmVq166dPDw8tGzZsj8d27lzZxdVBQBwJrIfgNWZ0hjHxMQoKSlJISEhiomJyXWczWZTRkaG6woDADgN2Q/A6kxpjDMzM3O8DgAovMh+AFZnmdO1ZXX+/HmzSwAAuBjZD8BspjfGkydP1qJFi+y3u3XrpqCgIJUrV047d+40sTIAgLOQ/QCsyPTGeObMmSpfvrwkadWqVVq9erVWrFihdu3aafTo0SZXBwBwBrIfgBWZfrq2EydO2MPxyy+/VPfu3fWPf/xD4eHhioqKMrk6AIAzkP0ArMj0PcYlS5bU0aNHJUkrVqxQq1atJEmGYXBUMgAUUmQ/ACsyfY/xfffdp169eqlq1ao6c+aM2rVrJ0mKj49XlSpVTK4OAOAMZD8AKzK9MX7jjTcUHh6uo0eP6pVXXpG/v7+k6x+zDR061OTqAADOQPYDsCLTG2MPDw+NGjUq2/LHH3/c9cUAAFyC7AdgRaY3xjfs3btXR44c0bVr1xyW87WgAFB4kf0ArMT0xvjQoUPq2rWrdu/eLZvNJsMwJF3/SlBJHIQBAIUQ2Q/Aikw/K8WIESMUERGh3377Tb6+vtqzZ482btyohg0bav369WaXBwBwArIfgBWZvsd48+bNWrt2rYKDg1WsWDEVK1ZM99xzjyZOnKjhw4crLi7O7BIBAPmM7AdgRabvMc7IyLAfjVy6dGkdP35cklSxYkX99NNPZpYGAHASsh+AFZm+x/j222/Xrl27VKlSJUVFRemVV16Rp6en3n33XVWqVMns8gAATkD2A7Ai0xvjZ599VsnJyZKkF198UR07dtS9996rUqVKadGiRSZXBwBwBrIfgBWZ3hi3adPGfr1SpUrau3evzp49q5IlS9qPTsbN+e7bb/Th3Dna8+NupaRcVVBQKdWLjNQzz8YqIDDQ7PLgBMeOHtGCD97Xj7vilXj4kP0I/1Xf7JCXl5fD2M3fbtS82e/qlwM/qZhbMdW6va4GPPqYatepZ0bpKKLIfuc5+Msv6n5/jNLT0yRJzzw/Xt17PGhyVXCWX48e0Uf/na29u3fqSJb8X77+e3n+f/5fS03Vxws/UNz2rTp2JFEXLpxXYMkgVateSw8/MkSVq1Y380ewFNPnGH/wwQf2vQY3BAUFEYx/038/nKshgwZo83ff6OLFC7p27ZqSkk5o5VfLdeHCBbPLg5MkHPxZX36+VIcTDtpDMSerVy7XmCeG6cdd8UpJuaorycnavnWzRgzup/gftruwYhR1ZL/zvPziBHtTjMLv8KFf9NWyT5T4J/l/+fIlzZn5luJ3fK/Tp04q7do1nfotSd9uXKth/R/Ujzs52PUG0xvjUaNGKSQkRD179tSXX36p9PR0s0sqsA78tF9vvP6qJKl6jZqat2CRtu7Yqa9WrdVzsf+Wf/HiJlcIZykdHKJ/9h+kV6bMUK3b6+Y4JjUlRVNffVmGYahM2VAt+GS53v3gI/n7F9e1a9f0n0kvuLhqFGVkv3P878tl2v79Nvn4+JpdClykVHCIevUdqJf/87Zq1K6T67iwcuX15NhYLVm+XktXbFSrth0lSenp6Vrw4XuuKtfyTG+MT5w4oUWLFsnNzU09e/ZUaGiohg4dqu+++87s0gqcjxYuUHp6umw2m15/403VrXeHvL29FRZWTg9076GgoCCzS4ST1KxdRwOHDFfju++Vp6dnjmO2fLdJFy6clyR1ub+HbitfQTVq3a7mrdtKkg4nHNSBn/a5qmQUcWR//rt8+bL+8+or8vb21sN9+5ldDlykRq3b1f/Rf6lR9L3y9PTKcUyJgAC9t+BTte98vwJLBikgIFBDHn/Kvv74sSOuKtfyTG+M3d3d1bFjR82fP18nT57UlClTlJiYqObNm6ty5cpml1egbP9+qyQpKKiU5sx+Ty2b3qOoBvU0oO8/tTOej0mKuqxNb8XwiByvH9i/16U1oegi+/Pf29Om6PTpUxow8FGVK3eb2eXAQtzdPbLtNElLTbVfDw4u4+qSLMv0xjgrX19ftWnTRu3atVPVqlV1+PBhs0sqUH5LSpIknTlzWks/XqTTp08pJSVF27/fpoH9+2j/PvYGFmXnz52zX/f1889y3e/3MWfPurQmQCL788NP+/dr0cIFqlAxXH37P2J2OSgAPnhvuv16205dTazEWizRGF+5ckXz589X+/btFRYWpjfeeEMxMTH68ccfzS6tQElPz7Bf7/Fgb323bYeeH3993mhqaqref2+mWaXByrIerMGBT3Ahsj9/GIahl1+coIyMDI0Z92yu06mAG+bMfEtfffGpJOkf7TurZZsOJldkHaafru3BBx/UF198IV9fX3Xr1k3r16/XXXfdlef7p6amKjXLxwGSiuxBHIGBgTp9+pQkqVv3HvLz89f93brrlckvK+XqVR34ab/JFcJMgSVL2q8nX75kv37lypUcxwDOdKvZL5H/N2zdslnxcT+obr07VKpUae3ft08nThy3rz+ZlKSfD/ykqtU4JRekmdNe18cLPpAkNWvVViPHjje3IIsxvTG22WxatGiR2rRpI3f3my9n4sSJmjBhgsOypk2b5ld5BUqNmjX1zaZTua738vJ2YTWwmmrVa9qvH0k8bL+eeDjh9zE1armyJBRht5r9Evl/w41/bnftjFePB2KyrZ/17jv6aOF8fbOFUzIWZYZh6O03JuuzjxdIktp06KInx46Xm5ubyZVZi+lTKRYsWKAOHTr87WAcO3asLly44HC5995787nKgqFdh4726x8vXqQrycn6ZMnHSrl6VZJ0552NzCoNTpaWlqYzp0/rzOnTSkv7/fyl586e0ZnTp3XlyhU1vuteBQQESpI+X7pIx44e0f69P2rdqhWSpPCIyg7NM+BMt5r9EvkPSNfz/+yZ0zp75rTS/5D/Z8+c1tUrV2QYht6Y/G97U9z5vh4a9cy/aYpzYFpj3L59e4cvnHjppZd0/vx5++0zZ86oVq2/3nvl5eWlEiVKOFxuJWgLsvYdOqlx9PWPIhctnK/oRvU1IfZZSVJImTLq/8ggM8uDE/24K05d2zVT13bNtGf3Tvvy7p3/oa7tmumj/86Rl7e3RoweJ5vNpt+STqjXfe01qE9PXb58SR4eHnpyzHMm/gQoKvIr+yXy/4YWLVtp556fHC7/fnGiff0zz49nb3Ehtmd3vLp3bKHuHVto74+/53/v+9qqe8cWWrxgrn5LOq7lny+1r1v2ySK1vqueWkXXtV9wnWmN8cqVKx3mhk2ePFlnsxwRn56erp9++smM0gqsYsWKaepbMzRw0GCFlSsnd3cPlSpVWp1j7tN/F36sUqVLm10iTNaqTXtN+s9bur3uHfL29pGvn58aRkXrzZlzdUf9hmaXhyKA7AdgZab9a/3Hry38s6+xRd55e3vrsRFP6LERT5hdClwoskEjbfw+b0fyR9/TVNH3FL15mLAGst81unS9T1263md2GXCBO+rfqdWbd/3luLyMgQXmGAMAAABWYFpjbLPZZPvDOVP/eBsAULiQ/QCszNSpFH379pWX1/Xv9U5JSdHgwYPl9//fwvXHc1MCAAo+sh+AlZnWGPfp08fh9kMPPZRtzMMPP+yqcgAALkD2A7Ay0xrjOXPmmPXQAACTkP0ArIyD7wAAAADRGAMAAACSaIwBAAAASTTGAAAAgCQaYwAAAECSRRrjefPm6e6771ZYWJgSExMlSVOmTNHnn39ucmUAAGch+wFYjemN8YwZM/Tkk0+qffv2On/+vDIyMiRJgYGBmjJlirnFAQCcguwHYEWmN8bTpk3TrFmz9Mwzz8jNzc2+vGHDhtq9e7eJlQEAnIXsB2BFpjfGCQkJioyMzLbcy8tLycnJJlQEAHA2sh+AFZneGEdERCg+Pj7b8q+++kq1atVyfUEAAKcj+wFYkWlfCX3D6NGjNWzYMKWkpMgwDG3btk0LFy7UxIkT9d5775ldHgDACch+AFZkemPcr18/paen66mnntKVK1fUq1cvlStXTlOnTlXPnj3NLg8A4ARkPwArMr0xlqSBAwdq4MCBOn36tDIzMxUSEmJ2SQAAJyP7AViNJRrjG0qXLm12CQAAFyP7AViF6Y1xRESEbDZbrusPHTrkwmoAAK5A9gOwItMb48cff9zhdlpamuLi4rRixQqNHj3anKIAAE5F9gOwItMb4xEjRuS4/O2339b27dtdXA0AwBXIfgBWZPp5jHPTrl07LV261OwyAAAuRPYDMJNlG+MlS5YoKCjI7DIAAC5E9gMwk+lTKSIjIx0OwDAMQ0lJSTp16pSmT59uYmUAAGch+wFYkemNcUxMjMPtYsWKKTg4WM2aNVONGjXMKQoA4FRkPwArMrUxTk9PV3h4uNq0aaOyZcuaWQoAwEXIfgBWZeocY3d3dw0ZMkSpqalmlgEAcCGyH4BVmX7wXVRUlOLi4swuAwDgQmQ/ACsyfY7x0KFDNXLkSB07dkwNGjSQn5+fw/q6deuaVBkAwFnIfgBWZFpj3L9/f02ZMkU9evSQJA0fPty+zmazyTAM2Ww2ZWRkmFUiACCfkf0ArMy0xviDDz7QpEmTlJCQYFYJAAAXI/sBWJlpjbFhGJKkihUrmlUCAMDFyH4AVmbqwXdZT+4OACgayH4AVmXqwXfVqlX7y4A8e/asi6oBALgC2Q/AqkxtjCdMmKCAgAAzSwAAuBjZD8CqTG2Me/bsqZCQEDNLAAC4GNkPwKpMm2PMHDMAKHrIfgBWZlpjfOPIZABA0UH2A7Ay06ZSZGZmmvXQAACTkP0ArMzU07UBAAAAVkFjDAAAAIjGGAAAAJBEYwwAAABIojEGAAAAJNEYAwAAAJJojAEAAABJNMYAAACAJBpjAAAAQBKNMQAAACCJxhgAAACQRGMMAAAASKIxBgAAACTRGAMAAACSaIwBAAAASTTGAAAAgCQaYwAAAEASjTEAAAAgicYYAAAAkERjDAAAAEiiMQYAAAAkSTbDMAyzi0D+S01N1cSJEzV27Fh5eXmZXQ5Mxu8DUHTw944b+F24eTTGhdTFixcVEBCgCxcuqESJEmaXA5Px+wAUHfy94wZ+F24eUykAAAAA0RgDAAAAkmiMAQAAAEk0xoWWl5eXYmNjmWwPSfw+AEUJf++4gd+Fm8fBdwAAAIDYYwwAAABIojEGAAAAJNEYF0jjx4/XHXfcYbltwbkKwmtVEGoECiqyv2gqCK9VQagxr2iM80nfvn1ls9lks9nk4eGhSpUqadSoUUpOTnZ5LYcPH7bXYrPZVLx4cdWuXVvDhg3Tzz//7DB21KhRWrNmjdNrstls+uyzz5z+OK5m5dc962XLli0uqcFVv0+AVVg5A8h+57Hy60723xp3swsoTNq2bas5c+YoLS1NmzZt0iOPPKLk5GTNmDEj29i0tDR5eHg4tZ7Vq1erdu3aunLlinbv3q2pU6eqXr16+uKLL9SyZUtJkr+/v/z9/XPdxrVr1+Tp6enUOgs6q77uWZUqVcqpj3nDX/0+AYWRVTOA7Hcuq77uWZH9N489xvnIy8tLZcuWVfny5dWrVy/17t3b/p/yjY8ZZs+erUqVKsnLy0uGYejChQsaNGiQQkJCVKJECbVo0UI7d+502O6kSZNUpkwZFS9eXAMGDFBKSkqe6ilVqpTKli2rSpUqqUuXLlq9erWioqI0YMAAZWRkONR1Q9++fRUTE6OJEycqLCxM1apVkyT9+uuv6tGjh0qWLKlSpUqpS5cuOnz4sMPjzZ49W7Vr15aXl5dCQ0P12GOPSZLCw8MlSV27dpXNZrPfLiys+rpnvXh4eOinn36SzWbT/v37Hcb/5z//UXh4uAzDUEZGhgYMGKCIiAj5+PioevXqmjp1qsP49evXq1GjRvLz81NgYKDuvvtuJSYmOvy8krRy5Up5e3vr/PnzDvcfPny4mjZtar/93XffqUmTJvLx8VH58uU1fPhwU/a6AH+XVTOA7Hcuq77uZP+toTF2Ih8fH6Wlpdlv//LLL1q8eLGWLl2q+Ph4SVKHDh2UlJSk5cuXa8eOHapfv75atmyps2fPSpIWL16s2NhYvfTSS9q+fbtCQ0M1ffr0v1VPsWLFNGLECCUmJmrHjh25jluzZo327dunVatW6csvv9SVK1fUvHlz+fv7a+PGjfrmm2/k7++vtm3b6tq1a5KkGTNmaNiwYRo0aJB2796tZcuWqUqVKpKk77//XpI0Z84cnThxwn67sLLa635D9erV1aBBA82fP99h+YIFC9SrVy/ZbDZlZmbqtttu0+LFi7V37149//zzGjdunBYvXixJSk9PV0xMjJo2bapdu3Zp8+bNGjRokGw2W7bHa9WqlQIDA7V06VL7soyMDC1evFi9e/eWJO3evVtt2rTRfffdp127dmnRokX65ptv7G+sQEFktQwg+13Daq/7DWT/TTKQL/r06WN06dLFfnvr1q1GqVKljO7duxuGYRixsbGGh4eHcfLkSfuYNWvWGCVKlDBSUlIctlW5cmVj5syZhmEYRnR0tDF48GCH9VFRUUa9evVyrSUhIcGQZMTFxWVbt2/fPkOSsWjRIntdWbfVp08fo0yZMkZqaqp92fvvv29Ur17dyMzMtC9LTU01fHx8jJUrVxqGYRhhYWHGM888k2tNkoxPP/001/UFlRVfdx8fH8PPz8/hkp6ebhiGYfznP/8xKlWqZL/PTz/9ZEgy9uzZk+t2hw4datx///2GYRjGmTNnDEnG+vXrcxz7x9+n4cOHGy1atLDfXrlypeHp6WmcPXvWMAzD+Oc//2kMGjTIYRubNm0yihUrZly9ejXXmgCrsGIGkP3OZ8XXnezPH8wxzkdffvml/P39lZ6errS0NHXp0kXTpk2zr69YsaKCg4Ptt3fs2KHLly9nmwN09epVHTx4UJK0b98+DR482GF9dHS01q1b97dqNP7/+1xy+i/vhjp16jjMLduxY4d++eUXFS9e3GFcSkqKDh48qJMnT+r48eP2uWtFjdVe90WLFqlmzZoOy9zc3CRJPXv21OjRo7VlyxY1btxY8+fP1x133KFatWrZx77zzjt67733lJiYqKtXr+ratWv2j8iCgoLUt29ftWnTRq1bt1arVq3UvXt3hYaG5lhL7969FR0drePHjyssLEzz589X+/btVbJkSftz8csvvzjsyTAMQ5mZmUpISMj2cwBWZLUMyAnZn/+s9rqT/fmDxjgfNW/eXDNmzJCHh4fCwsKyTbT38/NzuJ2ZmanQ0FCtX78+27YCAwOdUuO+ffskSREREbmOyanOnD6GkaTg4GAVK1a0Z+RY7XUvX768/aPMPwoNDVXz5s21YMECNW7cWAsXLtSjjz5qX7948WI98cQTev311xUdHa3ixYvr1Vdf1datW+1j5syZo+HDh2vFihVatGiRnn32Wa1atUqNGzfO9niNGjVS5cqV9dFHH2nIkCH69NNPNWfOHPv6zMxMPfrooxo+fHi2+1aoUOFWngbAZayWATkh+/Of1V53sj9/0BjnIz8/v1x/KXNSv359JSUlyd3dPdeDEmrWrKktW7bo4Ycfti/7u6dfyczM1JtvvqmIiAhFRkbeVJ2LFi2yHyyQk/DwcK1Zs0bNmzfPcb2Hh4f9oI/Cxuqv+x/17t1bTz/9tB588EEdPHhQPXv2tK/btGmT7rrrLg0dOtS+7MaejKwiIyMVGRmpsWPHKjo62h62OenVq5fmz5+v2267TcWKFVOHDh3s6+rXr689e/bc1PMHWI3VM4Dsdw6rv+5/RPbnTdH+d89krVq1UnR0tGJiYrRy5UodPnxY3333nZ599llt375dkjRixAjNnj1bs2fP1oEDBxQbG6s9e/bkaftnzpxRUlKSDh06pGXLlqlVq1batm2b3n//ffvHK3nRu3dvlS5dWl26dNGmTZuUkJCgDRs2aMSIETp27Jik60ekvv7663rzzTf1888/64cffnD4SOlGeCYlJencuXM38SwVPq563bNesh7VfN999+nixYsaMmSImjdvrnLlytnXValSRdu3b9fKlSt14MABPffccw4HzCQkJGjs2LHavHmzEhMT9fXXX+vAgQN/+rFX79699cMPP+ill17SAw88IG9vb/u6p59+Wps3b9awYcMUHx+vn3/+WcuWLdO//vWvPD+fQEFD9hdNZH/ByH4aYxPZbDYtX75cTZo0Uf/+/VWtWjX17NlThw8fVpkyZSRJPXr00PPPP6+nn35aDRo0UGJiooYMGZKn7bdq1UqhoaGqU6eOxowZo5o1a2rXrl25/mefG19fX23cuFEVKlTQfffdp5o1a6p///66evWqfS9Cnz59NGXKFE2fPl21a9dWx44dHU4o//rrr2vVqlUqX778Te2xKIxc9bpnvWQ9wX6JEiXUqVMn7dy5036E8A2DBw/Wfffdpx49eigqKkpnzpxx2IPg6+ur/fv36/7771e1atU0aNAgPfbYYw4fyf1R1apVdeedd2rXrl3ZHq9u3brasGGDfv75Z917772KjIzUc889l+u8NaAwIPuLJrL/d1bOfptxY0Y+AAAAUISxxxgAAAAQjTEAAAAgicYYAAAAkERjDAAAAEiiMQYAAAAk0RgDAAAAkmiMAQAAAEk0xgAAAIAkGmMUMuPHj9cdd9xhv923b1/FxMS4vI7Dhw/LZrMpPj7e5Y8NAEUN2Y/8QmMMl+jbt69sNptsNps8PDxUqVIljRo1SsnJyU593KlTp2ru3Ll5GkugAUD+IvtR0LibXQCKjrZt22rOnDlKS0vTpk2b9Mgjjyg5OVkzZsxwGJeWliYPD498ecyAgIB82Q4A4O8h+1GQsMcYLuPl5aWyZcuqfPny6tWrl3r37q3PPvvM/hHY7NmzValSJXl5eckwDF24cEGDBg1SSEiISpQooRYtWmjnzp0O25w0aZLKlCmj4sWLa8CAAUpJSXFY/8eP0zIzMzV58mRVqVJFXl5eqlChgl566SVJUkREhCQpMjJSNptNzZo1s99vzpw5qlmzpry9vVWjRg1Nnz7d4XG2bdumyMhIeXt7q2HDhoqLi8vHZw4ACi6yHwUJe4xhGh8fH6WlpUmSfvnlFy1evFhLly6Vm5ubJKlDhw4KCgrS8uXLFRAQoJkzZ6ply5Y6cOCAgoKCtHjxYsXGxurtt9/Wvffeq3nz5unNN99UpUqVcn3MsWPHatasWXrjjTd0zz336MSJE9q/f7+k6wHXqFEjrV69WrVr15anp6ckadasWYqNjdVbb72lyMhIxcXFaeDAgfLz81OfPn2UnJysjh07qkWLFvrvf/+rhIQEjRgxwsnPHgAUTGQ/LM0AXKBPnz5Gly5d7Le3bt1qlCpVyujevbsRGxtreHh4GCdPnrSvX7NmjVGiRAkjJSXFYTuVK1c2Zs6caRiGYURHRxuDBw92WB8VFWXUq1cvx8e9ePGi4eXl9X/t3L9LI1sYxvFHUUhMClE0GBEtVIggohYyTUS01y6iYGHSWFkIplBjoSCCCGoRghqDgv+AErQQrCSFYiEmEIiJ2PijEhSxMHOLZcPNXXfxLqy7rt8PpMiZkzMvU7w8ZM6Mubq6+mqN6XTalGSenp7mjdfU1Jjb29t5YzMzM6ZhGKZpmmYoFDLLysrMx8fH3PFgMPjqWgDwmdD78dGwlQLvZnd3V3a7XRaLRYZhyO12a2VlRZJUW1urioqK3NyTkxM9PDyovLxcdrs990mn00qlUpKkRCIhwzDyzvHf7/+WSCT0/Pys7u7uN9d8d3enq6sreb3evDpmZ2fz6mhpaVFJScmb6gCAz4Tej4+ErRR4N11dXQoGgyouLpbT6cx7yMJms+XNzWazqqqq0uHh4TfrlJaW/tT5rVbr//5NNpuV9OWWWkdHR96xr7f9TNP8qXoA4DOg9+MjIRjj3dhsNtXX179pbltbm66vr1VUVKS6urpX57hcLsViMQ0NDeXGYrHYd9dsaGiQ1WrVwcGBfD7fN8e/7it7eXnJjTkcDlVXV+vi4kKDg4OvrtvU1KStrS09PT3lGvCP6gCAz4Tej4+ErRT4I/X09MgwDPX19Wl/f1+ZTEZHR0eanJzU8fGxJGl0dFThcFjhcFjJZFLT09M6Pz//7poWi0V+v1/j4+Pa3NxUKpVSLBbT+vq6JKmyslJWq1V7e3u6ubnR/f29pC8vjp+bm9PS0pKSyaTOzs60sbGhxcVFSdLAwIAKCwvl9XoVj8cVjUa1sLDwi68QAPx96P343QjG+CMVFBQoGo3K7XZreHhYjY2N6u/vVyaTkcPhkCR5PB4FAgH5/X61t7fr8vJSIyMjP1x3ampKY2NjCgQCcrlc8ng8ur29lSQVFRVpeXlZoVBITqdTvb29kiSfz6e1tTVFIhE1Nzers7NTkUgk94ofu92unZ0dxeNxtba2amJiQvPz87/w6gDA34nej9+twGSTDAAAAMA/xgAAAIBEMAYAAAAkEYwBAAAASQRjAAAAQBLBGAAAAJBEMAYAAAAkEYwBAAAASQRjAAAAQBLBGAAAAJBEMAYAAAAkEYwBAAAASQRjAAAAQJL0D85uhvQ6swkEAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x700 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate confusion matrices.\n",
    "models = [\"baseline\", \"deberta\", \"llm_avg\", \"blended_deberta\"]\n",
    "fig, axes = plt.subplots(2, 2, figsize=(8,7))\n",
    "for ax, name in zip(axes.ravel(), models):\n",
    "    M = to_numeric_matrix(conf_mats[name])\n",
    "    df_cm = pd.DataFrame(M,\n",
    "                         index=[\"True Direct\", \"True Evasive\"],\n",
    "                         columns=[\"Pred Direct\", \"Pred Evasive\"])\n",
    "    sns.heatmap(df_cm, ax=ax, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "                annot_kws={\"size\":11, \"weight\":\"bold\"},\n",
    "                linewidths=0.4, linecolor=\"grey\", square=True)\n",
    "    ax.set_title(name, fontsize=12, weight=\"bold\")\n",
    "    ax.set_ylabel(\"Actual\"); ax.set_xlabel(\"Predicted\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7026f02",
   "metadata": {},
   "source": [
    "**Confusion Matrix Results**\n",
    "* **Baseline:** Flags nearly everything as evasive (83 false positive vs 15 true positives)\n",
    "* **DeBERTa:** Much more balanced, correctly identifies 44 direct and 11 evasive, though still misclassifies over half of directs.\n",
    "* **LLM average:** Similar performance to DeBERTa but with slightly more direct misclassifications \n",
    "* **Blended DeBERTa:** Skews heavily back towards evasive predictions with 78 directs misclassified as evasive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b65c2ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeBERTa: {'P@10%': 0.08333333333333333, 'P@25%': 0.14285714285714285, 'P@50%': 0.19642857142857142}\n",
      "RoBERTa: {'P@10%': 0.16666666666666666, 'P@25%': 0.21428571428571427, 'P@50%': 0.17857142857142858}\n",
      "llm_avg: {'P@10%': 0.16666666666666666, 'P@25%': 0.17857142857142858, 'P@50%': 0.17857142857142858}\n",
      "Blended: {'P@10%': 0.08333333333333333, 'P@25%': 0.17857142857142858, 'P@50%': 0.17857142857142858}\n",
      "Baseline: {'P@10%': 0.0, 'P@25%': 0.10714285714285714, 'P@50%': 0.16071428571428573}\n"
     ]
    }
   ],
   "source": [
    "# Function to determine precision at K (threshold free)\n",
    "# 1) Ranks DeBERTa's evasion scores (highest to lowest)\n",
    "# 2) Looks at the to 10%, 25% or 50% of rows\n",
    "# 3) Reports what fraction are truly evasive.\n",
    "\n",
    "def precision_at_k(df, score_col, label_col='label', k_percents=(10, 25, 50)):\n",
    "    # Ground truth 1 = evasive\n",
    "    y_true = (df[label_col].astype(str).str.strip().str.lower() == 'evasive').astype(int).values\n",
    "    scores = df[score_col].astype(float).values\n",
    "\n",
    "    # Sort by score (descending)\n",
    "    order = np.argsort(-scores)\n",
    "    y_sorted = y_true[order]\n",
    "\n",
    "    n = len(y_true)\n",
    "    results = {}\n",
    "    for k in k_percents:\n",
    "        top_k = max(1, int(np.ceil(n * k / 100)))\n",
    "        results[f\"P@{k}%\"] = y_sorted[:top_k].mean()\n",
    "    return results\n",
    "\n",
    "# Precision at K.\n",
    "p_deberta = precision_at_k(jpm_test_qa_scores, score_col='evasion_score_deberta')\n",
    "print('DeBERTa:', p_deberta)\n",
    "\n",
    "p_roberta = precision_at_k(jpm_test_qa_scores, score_col='evasion_score_roberta')\n",
    "print('RoBERTa:', p_roberta)\n",
    "\n",
    "p_llm_avg = precision_at_k(jpm_test_qa_scores, score_col='evasion_score_llm_avg')\n",
    "print('llm_avg:', p_llm_avg)\n",
    "\n",
    "p_blended = precision_at_k(jpm_test_qa_scores, score_col='evasion_score_blended_deberta')\n",
    "print('Blended:', p_blended)\n",
    "\n",
    "p_baseline = precision_at_k(jpm_test_qa_scores, score_col='evasion_score_baseline')\n",
    "print('Baseline:', p_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22993c27",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "**Note:** This P@K is raw evasion score ranking (not thresholded) so is ordering of all the evasion scores (highest to lowest) and then measuring the precision at different cut-off points (as opposed to thresholded P@K above which ranks only among the predicted evasives)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-evasion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
